{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This note book requires the following packages to run\n",
    "* numpy\n",
    "* sklearn\n",
    "* tensorflow\n",
    "* matplotlib\n",
    "* scipy\n",
    "\n",
    "To reproduce the exact results within the reported run time, a graphic card with computute capability of at least 5.2 is required.\n",
    "\n",
    "Please put the training data and testing data in the same folder with this notebook and rename them to \"train.mat\" and \"test.mat\" respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73257, 32, 32, 3) (73257, 10)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import parmap\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit([1,2,3,4,5,6,7,8,9,10])\n",
    "train = sio.loadmat(\"train.mat\")\n",
    "test = sio.loadmat(\"test.mat\")\n",
    "label = train['y']\n",
    "img = train['X']\n",
    "img = np.rollaxis(img,3,0)\n",
    "\n",
    "label = np.ravel(label)\n",
    "# Process the label so that it can be read by tensorflow\n",
    "label = lb.transform(label)\n",
    "\n",
    "Xtest = test['X']\n",
    "Xtest = np.rollaxis(Xtest, 3,0)\n",
    "ytest = test['y']\n",
    "ytest = np.ravel(ytest)\n",
    "ytest = lb.transform(ytest)\n",
    "\n",
    "print img.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def process_(i, img):\n",
    "    currentImg = img[i,:,:,:]\n",
    "\n",
    "    # Grayscale image\n",
    "    grayscale = np.dot(currentImg[:,:,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "    return np.ravel(grayscale)\n",
    "\n",
    "num_img = img.shape[0]\n",
    "num_img_test = Xtest.shape[0]\n",
    "processed = parmap.map(process_, range(0,num_img), img)\n",
    "processed = np.array(processed)\n",
    "test_processed = parmap.map(process_, range(0,num_img_test), Xtest)\n",
    "test_processed = np.array(test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26032, 1024)\n",
      "(26032, 10)\n"
     ]
    }
   ],
   "source": [
    "# batch = tf.train.shuffle_batch([img, label], batch_size=100, capacity=50000, \n",
    "#                                num_threads=4, min_after_dequeue=10000)\n",
    "# batch[0].shape\n",
    "# batch[1].shape\n",
    "print test_processed.shape\n",
    "print ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to get batch of data\n",
    "class SVHN:\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit([1,2,3,4,5,6,7,8,9,10])\n",
    "    def __init__(self, data):\n",
    "#         self.data = sio.loadmat(filename)\n",
    "        self.img = data[0]\n",
    "        self.label = data[1]\n",
    "#         self.label = SVHN.lb.transform(np.ravel(self.label))\n",
    "        self.indx = np.arange(self.label.shape[0])\n",
    "#         self.state = np.random.RandomState(42)\n",
    "#         self.batchsize = batchsize\n",
    "#         self.num_batch = \n",
    "    def get_next_batch(self,batchsize):\n",
    "        np.random.shuffle(self.indx)\n",
    "        return self.img[self.indx[:batchsize],:], self.label[self.indx[:batchsize],:]\n",
    "mysvhn = SVHN([processed, label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1024) (100, 10)\n",
      "[0 0 0 0 0 0 0 1 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQnUId3V1dU2o/weTfrUiJveJtQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb9b46c9450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "batch = mysvhn.get_next_batch(100)\n",
    "print batch[0].shape, batch[1].shape\n",
    "plt.imshow(batch[0][3,:].reshape([32,32]),cmap='gray')\n",
    "print batch[1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #Test cell\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "# batch = mnist.train.next_batch(100)\n",
    "# print batch[0].shape\n",
    "# print batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "\n",
    "# Initialize weight with randomized number drawn from normal distribition\n",
    "def init_weight(shape, name):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.1), name=name)\n",
    "# Initialize bias with constant\n",
    "def init_bias(shape, name):\n",
    "    return tf.Variable(tf.constant(0.1, shape=shape), name=name)\n",
    "\n",
    "# 2D convolution\n",
    "def conv2d(x,w):\n",
    "    \"\"\"\n",
    "    X is input tensor, W * H * D * n\n",
    "    w is weight tensor, W' * H' * D * N\n",
    "    return out, W * H * N\n",
    "    padding='same'\n",
    "    stride=[1,1,1,1]\n",
    "    \"\"\"\n",
    "    return tf.nn.conv2d(x,w, strides=[1,1,1,1], padding='SAME',name=\"Convolution\");\n",
    "\n",
    "# Max pooling layer\n",
    "def max_pool_2x2(x):\n",
    "    \"\"\"\n",
    "    2 by 2 max pool\n",
    "    filter size: 2 by 2\n",
    "    stride: 2, 2\n",
    "    padding='same'\n",
    "    \"\"\"\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model(x, w, b, keep_prob):\n",
    "    \"\"\"\n",
    "    X is input tensor: 28 * 28 * 1 * n\n",
    "    w is list of tensors of weight, len(w)=4 for this architecture\n",
    "    b is list of bias, len(b)=4 correspondingly\n",
    "    \"\"\"\n",
    "    x = tf.reshape(x,[-1, 32, 32, 1])\n",
    "    \n",
    "    # 2 Layers network, each layer contains a convolution, reLU and Max pool operation\n",
    "    \n",
    "    # Layer 1\n",
    "    with tf.name_scope(\"Layer1\"):\n",
    "        with tf.name_scope(\"Convolutional_layer1\"):\n",
    "            h_conv1 = (conv2d(x, w[0]) + b[0])\n",
    "        with tf.name_scope(\"ReLU_layer1\"):\n",
    "            h_relu1 = tf.nn.relu(h_conv1)\n",
    "        with tf.name_scope(\"Max_pooling_layer1\"):\n",
    "            h_pool1 = max_pool_2x2(h_relu1)\n",
    "        \n",
    "    # Layer 2\n",
    "    with tf.name_scope(\"Layer2\"):\n",
    "        with tf.name_scope(\"Convolutional_layer2\"):\n",
    "            h_conv2 = conv2d(h_pool1, w[1]) + b[1]\n",
    "        with tf.name_scope(\"ReLU_layer2\"):\n",
    "            h_relu2 = tf.nn.relu(h_conv2)\n",
    "        with tf.name_scope(\"Max_pooling_layer2\"):\n",
    "            h_pool2 = max_pool_2x2(h_relu2)\n",
    "    \n",
    "    # Reshape h_pool2\n",
    "    h_pool2 = tf.reshape(h_pool2,[-1, 8*8*64])\n",
    "    \n",
    "    # Fully connected layer\n",
    "    with tf.name_scope(\"Fully_Connected_layer\"):\n",
    "        with tf.name_scope(\"Activation_layer\"):\n",
    "            h_fc1 = tf.nn.relu(tf.matmul(h_pool2, w[2]) + b[2])\n",
    "#         keep_prob = tf.placeholder(tf.float32)\n",
    "        with tf.name_scope(\"Dropout\"):\n",
    "            h_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "        with tf.name_scope(\"Read_out_layer\"):\n",
    "            y_conv = tf.matmul(h_drop, w[3]) + b[3]\n",
    "    return y_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Input images\n",
    "x = tf.placeholder(tf.float32, shape=[None,32*32], name=\"Input_images\")\n",
    "\n",
    "# Input labels\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10], name=\"Input_labels\")\n",
    "\n",
    "# Weights and bias for layer 1\n",
    "w_0 = init_weight([3,3,1,32],\"Layer1_weights\")\n",
    "b_0 = init_bias([32], \"Layer1_bias\")\n",
    "\n",
    "# Weights and bias for layer 2\n",
    "w_1 = init_weight([5,5,32,64], \"Layer2_weights\")\n",
    "b_1 = init_bias([64], \"Layer2_bias\")\n",
    "\n",
    "# Weights and bias for fully connected layer 1\n",
    "w_2 = init_weight([8*8*64, 1024], \"Fully_connected_layer_weight1\")\n",
    "b_2 = init_bias([1024],\"Fully_connected_layer_bias1\")\n",
    "\n",
    "# Weights and bias for fully connected layer 2\n",
    "w_3 = init_weight([1024, 10], \"Read_out_weight\")\n",
    "b_3 = init_bias([10], \"Read_out_bias\")\n",
    "\n",
    "# Add summary for later visualization and analysis\n",
    "tf.histogram_summary(\"w_0_summ\", w_0)\n",
    "tf.histogram_summary(\"w_1_summ\", w_1)\n",
    "tf.histogram_summary(\"w_2_summ\", w_2)\n",
    "tf.histogram_summary(\"w_3_summ\", w_3)\n",
    "\n",
    "tf.histogram_summary(\"b_0_summ\", b_0)\n",
    "tf.histogram_summary(\"b_1_summ\", b_1)\n",
    "tf.histogram_summary(\"b_2_summ\", b_2)\n",
    "tf.histogram_summary(\"b_3_summ\", b_3)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32, name=\"keeping_probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_h = model(x,[w_0,w_1,w_2,w_3],[b_0,b_1,b_2,b_3], keep_prob)\n",
    "\n",
    "# Cost function\n",
    "with tf.name_scope(\"Cost\"):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_h, y_))\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cost)\n",
    "    # Add summary of cost\n",
    "    tf.scalar_summary(\"Cost\", cost)\n",
    "\n",
    "# Accuracy function\n",
    "with tf.name_scope(\"Accuracy\"):\n",
    "    correct = tf.equal(tf.argmax(y_h,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    tf.scalar_summary(\"Accuracy\", accuracy)\n",
    "\n",
    "# with tf.InteractiveSession() as sess:\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "writer = tf.train.SummaryWriter(\"logs/\", sess.graph)\n",
    "merged = tf.merge_all_summaries()\n",
    "tf.global_variables_initializer().run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, training accuracy 0.0999999940395\n",
      "Step 100, training accuracy 0.139999985695\n",
      "Step 200, training accuracy 0.280000001192\n",
      "Step 300, training accuracy 0.289999991655\n",
      "Step 400, training accuracy 0.25\n",
      "Step 500, training accuracy 0.209999978542\n",
      "Step 600, training accuracy 0.179999992251\n",
      "Step 700, training accuracy 0.209999978542\n",
      "Step 800, training accuracy 0.239999979734\n",
      "Step 900, training accuracy 0.239999979734\n",
      "Step 1000, training accuracy 0.209999993443\n",
      "Step 1100, training accuracy 0.159999996424\n",
      "Step 1200, training accuracy 0.179999992251\n",
      "Step 1300, training accuracy 0.139999985695\n",
      "Step 1400, training accuracy 0.179999992251\n",
      "Step 1500, training accuracy 0.179999992251\n",
      "Step 1600, training accuracy 0.219999998808\n",
      "Step 1700, training accuracy 0.199999988079\n",
      "Step 1800, training accuracy 0.209999993443\n",
      "Step 1900, training accuracy 0.139999985695\n",
      "Step 2000, training accuracy 0.240000009537\n",
      "Step 2100, training accuracy 0.209999993443\n",
      "Step 2200, training accuracy 0.119999997318\n",
      "Step 2300, training accuracy 0.230000004172\n",
      "Step 2400, training accuracy 0.119999989867\n",
      "Step 2500, training accuracy 0.239999994636\n",
      "Step 2600, training accuracy 0.17999997735\n",
      "Step 2700, training accuracy 0.209999993443\n",
      "Step 2800, training accuracy 0.159999996424\n",
      "Step 2900, training accuracy 0.149999991059\n",
      "Step 3000, training accuracy 0.210000008345\n",
      "Step 3100, training accuracy 0.219999998808\n",
      "Step 3200, training accuracy 0.169999986887\n",
      "Step 3300, training accuracy 0.239999994636\n",
      "Step 3400, training accuracy 0.209999978542\n",
      "Step 3500, training accuracy 0.219999998808\n",
      "Step 3600, training accuracy 0.189999997616\n",
      "Step 3700, training accuracy 0.170000001788\n",
      "Step 3800, training accuracy 0.20000000298\n",
      "Step 3900, training accuracy 0.170000001788\n",
      "Step 4000, training accuracy 0.189999997616\n",
      "Step 4100, training accuracy 0.219999983907\n",
      "Step 4200, training accuracy 0.129999995232\n",
      "Step 4300, training accuracy 0.239999979734\n",
      "Step 4400, training accuracy 0.189999997616\n",
      "Step 4500, training accuracy 0.189999997616\n",
      "Step 4600, training accuracy 0.199999988079\n",
      "Step 4700, training accuracy 0.229999989271\n",
      "Step 4800, training accuracy 0.259999990463\n",
      "Step 4900, training accuracy 0.209999993443\n",
      "Step 5000, training accuracy 0.209999993443\n",
      "Step 5100, training accuracy 0.189999997616\n",
      "Step 5200, training accuracy 0.289999991655\n",
      "Step 5300, training accuracy 0.169999986887\n",
      "Step 5400, training accuracy 0.189999982715\n",
      "Step 5500, training accuracy 0.149999991059\n",
      "Step 5600, training accuracy 0.199999988079\n",
      "Step 5700, training accuracy 0.15000000596\n",
      "Step 5800, training accuracy 0.129999995232\n",
      "Step 5900, training accuracy 0.209999993443\n",
      "Step 6000, training accuracy 0.20000000298\n",
      "Step 6100, training accuracy 0.159999996424\n",
      "Step 6200, training accuracy 0.20000000298\n",
      "Step 6300, training accuracy 0.289999991655\n",
      "Step 6400, training accuracy 0.229999989271\n",
      "Step 6500, training accuracy 0.230000004172\n",
      "Step 6600, training accuracy 0.289999991655\n",
      "Step 6700, training accuracy 0.210000008345\n",
      "Step 6800, training accuracy 0.230000004172\n",
      "Step 6900, training accuracy 0.219999969006\n",
      "Step 7000, training accuracy 0.299999982119\n",
      "Step 7100, training accuracy 0.169999986887\n",
      "Step 7200, training accuracy 0.180000007153\n",
      "Step 7300, training accuracy 0.239999994636\n",
      "Step 7400, training accuracy 0.219999969006\n",
      "Step 7500, training accuracy 0.239999994636\n",
      "Step 7600, training accuracy 0.229999989271\n",
      "Step 7700, training accuracy 0.269999980927\n",
      "Step 7800, training accuracy 0.259999990463\n",
      "Step 7900, training accuracy 0.219999998808\n",
      "Step 8000, training accuracy 0.159999996424\n",
      "Step 8100, training accuracy 0.219999998808\n",
      "Step 8200, training accuracy 0.20000000298\n",
      "Step 8300, training accuracy 0.169999986887\n",
      "Step 8400, training accuracy 0.229999989271\n",
      "Step 8500, training accuracy 0.149999991059\n",
      "Step 8600, training accuracy 0.230000004172\n",
      "Step 8700, training accuracy 0.169999986887\n",
      "Step 8800, training accuracy 0.209999993443\n",
      "Step 8900, training accuracy 0.310000002384\n",
      "Step 9000, training accuracy 0.249999985099\n",
      "Step 9100, training accuracy 0.219999998808\n",
      "Step 9200, training accuracy 0.189999997616\n",
      "Step 9300, training accuracy 0.179999992251\n",
      "Step 9400, training accuracy 0.280000001192\n",
      "Step 9500, training accuracy 0.25\n",
      "Step 9600, training accuracy 0.179999992251\n",
      "Step 9700, training accuracy 0.259999990463\n",
      "Step 9800, training accuracy 0.219999998808\n",
      "Step 9900, training accuracy 0.170000001788\n",
      "Step 10000, training accuracy 0.219999998808\n",
      "Step 10100, training accuracy 0.249999985099\n",
      "Step 10200, training accuracy 0.289999991655\n",
      "Step 10300, training accuracy 0.189999997616\n",
      "Step 10400, training accuracy 0.239999979734\n",
      "Step 10500, training accuracy 0.289999991655\n",
      "Step 10600, training accuracy 0.210000008345\n",
      "Step 10700, training accuracy 0.230000004172\n",
      "Step 10800, training accuracy 0.280000001192\n",
      "Step 10900, training accuracy 0.179999992251\n",
      "Step 11000, training accuracy 0.239999994636\n",
      "Step 11100, training accuracy 0.240000009537\n",
      "Step 11200, training accuracy 0.249999985099\n",
      "Step 11300, training accuracy 0.319999992847\n",
      "Step 11400, training accuracy 0.319999963045\n",
      "Step 11500, training accuracy 0.289999991655\n",
      "Step 11600, training accuracy 0.189999997616\n",
      "Step 11700, training accuracy 0.25\n",
      "Step 11800, training accuracy 0.289999991655\n",
      "Step 11900, training accuracy 0.189999982715\n",
      "Step 12000, training accuracy 0.170000001788\n",
      "Step 12100, training accuracy 0.259999990463\n",
      "Step 12200, training accuracy 0.209999993443\n",
      "Step 12300, training accuracy 0.219999998808\n",
      "Step 12400, training accuracy 0.219999998808\n",
      "Step 12500, training accuracy 0.159999996424\n",
      "Step 12600, training accuracy 0.269999980927\n",
      "Step 12700, training accuracy 0.159999996424\n",
      "Step 12800, training accuracy 0.25\n",
      "Step 12900, training accuracy 0.25\n",
      "Step 13000, training accuracy 0.249999970198\n",
      "Step 13100, training accuracy 0.159999996424\n",
      "Step 13200, training accuracy 0.239999979734\n",
      "Step 13300, training accuracy 0.219999998808\n",
      "Step 13400, training accuracy 0.189999997616\n",
      "Step 13500, training accuracy 0.239999994636\n",
      "Step 13600, training accuracy 0.259999990463\n",
      "Step 13700, training accuracy 0.259999990463\n",
      "Step 13800, training accuracy 0.289999991655\n",
      "Step 13900, training accuracy 0.239999979734\n",
      "Step 14000, training accuracy 0.239999994636\n",
      "Step 14100, training accuracy 0.269999980927\n",
      "Step 14200, training accuracy 0.219999998808\n",
      "Step 14300, training accuracy 0.269999980927\n",
      "Step 14400, training accuracy 0.269999980927\n",
      "Step 14500, training accuracy 0.219999998808\n",
      "Step 14600, training accuracy 0.189999997616\n",
      "Step 14700, training accuracy 0.149999991059\n",
      "Step 14800, training accuracy 0.280000001192\n",
      "Step 14900, training accuracy 0.389999985695\n",
      "Step 15000, training accuracy 0.280000001192\n",
      "Step 15100, training accuracy 0.370000004768\n",
      "Step 15200, training accuracy 0.319999992847\n",
      "Step 15300, training accuracy 0.329999983311\n",
      "Step 15400, training accuracy 0.310000002384\n",
      "Step 15500, training accuracy 0.319999992847\n",
      "Step 15600, training accuracy 0.439999997616\n",
      "Step 15700, training accuracy 0.319999992847\n",
      "Step 15800, training accuracy 0.310000002384\n",
      "Step 15900, training accuracy 0.34999999404\n",
      "Step 16000, training accuracy 0.289999991655\n",
      "Step 16100, training accuracy 0.350000023842\n",
      "Step 16200, training accuracy 0.379999965429\n",
      "Step 16300, training accuracy 0.430000007153\n",
      "Step 16400, training accuracy 0.370000004768\n",
      "Step 16500, training accuracy 0.350000023842\n",
      "Step 16600, training accuracy 0.289999991655\n",
      "Step 16700, training accuracy 0.379999995232\n",
      "Step 16800, training accuracy 0.389999985695\n",
      "Step 16900, training accuracy 0.329999983311\n",
      "Step 17000, training accuracy 0.369999974966\n",
      "Step 17100, training accuracy 0.339999973774\n",
      "Step 17200, training accuracy 0.360000014305\n",
      "Step 17300, training accuracy 0.319999992847\n",
      "Step 17400, training accuracy 0.289999991655\n",
      "Step 17500, training accuracy 0.359999984503\n",
      "Step 17600, training accuracy 0.300000011921\n",
      "Step 17700, training accuracy 0.429999947548\n",
      "Step 17800, training accuracy 0.339999973774\n",
      "Step 17900, training accuracy 0.379999995232\n",
      "Step 18000, training accuracy 0.389999985695\n",
      "Step 18100, training accuracy 0.409999996424\n",
      "Step 18200, training accuracy 0.489999979734\n",
      "Step 18300, training accuracy 0.430000007153\n",
      "Step 18400, training accuracy 0.389999985695\n",
      "Step 18500, training accuracy 0.340000003576\n",
      "Step 18600, training accuracy 0.40000000596\n",
      "Step 18700, training accuracy 0.379999995232\n",
      "Step 18800, training accuracy 0.329999983311\n",
      "Step 18900, training accuracy 0.339999973774\n",
      "Step 19000, training accuracy 0.329999983311\n",
      "Step 19100, training accuracy 0.25\n",
      "Step 19200, training accuracy 0.479999959469\n",
      "Step 19300, training accuracy 0.329999983311\n",
      "Step 19400, training accuracy 0.339999973774\n",
      "Step 19500, training accuracy 0.280000001192\n",
      "Step 19600, training accuracy 0.300000011921\n",
      "Step 19700, training accuracy 0.430000007153\n",
      "Step 19800, training accuracy 0.310000002384\n",
      "Step 19900, training accuracy 0.349999964237\n",
      "Step 20000, training accuracy 0.280000001192\n",
      "Step 20100, training accuracy 0.340000003576\n",
      "Step 20200, training accuracy 0.399999976158\n",
      "Step 20300, training accuracy 0.329999983311\n",
      "Step 20400, training accuracy 0.310000002384\n",
      "Step 20500, training accuracy 0.370000004768\n",
      "Step 20600, training accuracy 0.369999974966\n",
      "Step 20700, training accuracy 0.289999991655\n",
      "Step 20800, training accuracy 0.289999991655\n",
      "Step 20900, training accuracy 0.289999991655\n",
      "Step 21000, training accuracy 0.370000004768\n",
      "Step 21100, training accuracy 0.299999982119\n",
      "Step 21200, training accuracy 0.359999984503\n",
      "Step 21300, training accuracy 0.299999982119\n",
      "Step 21400, training accuracy 0.300000011921\n",
      "Step 21500, training accuracy 0.310000002384\n",
      "Step 21600, training accuracy 0.42999997735\n",
      "Step 21700, training accuracy 0.329999983311\n",
      "Step 21800, training accuracy 0.329999983311\n",
      "Step 21900, training accuracy 0.34999999404\n",
      "Step 22000, training accuracy 0.329999983311\n",
      "Step 22100, training accuracy 0.389999985695\n",
      "Step 22200, training accuracy 0.329999983311\n",
      "Step 22300, training accuracy 0.369999974966\n",
      "Step 22400, training accuracy 0.449999988079\n",
      "Step 22500, training accuracy 0.289999991655\n",
      "Step 22600, training accuracy 0.349999964237\n",
      "Step 22700, training accuracy 0.329999983311\n",
      "Step 22800, training accuracy 0.310000002384\n",
      "Step 22900, training accuracy 0.369999974966\n",
      "Step 23000, training accuracy 0.329999983311\n",
      "Step 23100, training accuracy 0.389999985695\n",
      "Step 23200, training accuracy 0.34999999404\n",
      "Step 23300, training accuracy 0.230000019073\n",
      "Step 23400, training accuracy 0.349999964237\n",
      "Step 23500, training accuracy 0.300000011921\n",
      "Step 23600, training accuracy 0.310000002384\n",
      "Step 23700, training accuracy 0.449999988079\n",
      "Step 23800, training accuracy 0.319999992847\n",
      "Step 23900, training accuracy 0.449999988079\n",
      "Step 24000, training accuracy 0.379999995232\n",
      "Step 24100, training accuracy 0.399999976158\n",
      "Step 24200, training accuracy 0.389999985695\n",
      "Step 24300, training accuracy 0.329999983311\n",
      "Step 24400, training accuracy 0.360000014305\n",
      "Step 24500, training accuracy 0.370000004768\n",
      "Step 24600, training accuracy 0.339999973774\n",
      "Step 24700, training accuracy 0.399999976158\n",
      "Step 24800, training accuracy 0.389999985695\n",
      "Step 24900, training accuracy 0.439999938011\n",
      "Step 25000, training accuracy 0.34999999404\n",
      "Step 25100, training accuracy 0.42999997735\n",
      "Step 25200, training accuracy 0.389999985695\n",
      "Step 25300, training accuracy 0.459999978542\n",
      "Step 25400, training accuracy 0.389999985695\n",
      "Step 25500, training accuracy 0.439999997616\n",
      "Step 25600, training accuracy 0.340000003576\n",
      "Step 25700, training accuracy 0.460000008345\n",
      "Step 25800, training accuracy 0.359999984503\n",
      "Step 25900, training accuracy 0.5\n",
      "Step 26000, training accuracy 0.34999999404\n",
      "Step 26100, training accuracy 0.459999978542\n",
      "Step 26200, training accuracy 0.379999995232\n",
      "Step 26300, training accuracy 0.439999997616\n",
      "Step 26400, training accuracy 0.479999989271\n",
      "Step 26500, training accuracy 0.419999986887\n",
      "Step 26600, training accuracy 0.469999998808\n",
      "Step 26700, training accuracy 0.469999998808\n",
      "Step 26800, training accuracy 0.490000009537\n",
      "Step 26900, training accuracy 0.389999985695\n",
      "Step 27000, training accuracy 0.42999997735\n",
      "Step 27100, training accuracy 0.469999969006\n",
      "Step 27200, training accuracy 0.419999957085\n",
      "Step 27300, training accuracy 0.479999989271\n",
      "Step 27400, training accuracy 0.449999988079\n",
      "Step 27500, training accuracy 0.479999989271\n",
      "Step 27600, training accuracy 0.589999973774\n",
      "Step 27700, training accuracy 0.409999966621\n",
      "Step 27800, training accuracy 0.600000023842\n",
      "Step 27900, training accuracy 0.6099999547\n",
      "Step 28000, training accuracy 0.449999988079\n",
      "Step 28100, training accuracy 0.52999997139\n",
      "Step 28200, training accuracy 0.539999961853\n",
      "Step 28300, training accuracy 0.55999994278\n",
      "Step 28400, training accuracy 0.579999923706\n",
      "Step 28500, training accuracy 0.649999976158\n",
      "Step 28600, training accuracy 0.579999923706\n",
      "Step 28700, training accuracy 0.479999959469\n",
      "Step 28800, training accuracy 0.449999988079\n",
      "Step 28900, training accuracy 0.519999980927\n",
      "Step 29000, training accuracy 0.539999961853\n",
      "Step 29100, training accuracy 0.439999997616\n",
      "Step 29200, training accuracy 0.550000011921\n",
      "Step 29300, training accuracy 0.519999980927\n",
      "Step 29400, training accuracy 0.519999980927\n",
      "Step 29500, training accuracy 0.52999997139\n",
      "Step 29600, training accuracy 0.579999983311\n",
      "Step 29700, training accuracy 0.569999992847\n",
      "Step 29800, training accuracy 0.490000009537\n",
      "Step 29900, training accuracy 0.599999964237\n",
      "Step 30000, training accuracy 0.479999989271\n",
      "Step 30100, training accuracy 0.579999983311\n",
      "Step 30200, training accuracy 0.620000004768\n",
      "Step 30300, training accuracy 0.55999994278\n",
      "Step 30400, training accuracy 0.549999952316\n",
      "Step 30500, training accuracy 0.569999992847\n",
      "Step 30600, training accuracy 0.55999994278\n",
      "Step 30700, training accuracy 0.569999933243\n",
      "Step 30800, training accuracy 0.5\n",
      "Step 30900, training accuracy 0.549999952316\n",
      "Step 31000, training accuracy 0.599999964237\n",
      "Step 31100, training accuracy 0.539999961853\n",
      "Step 31200, training accuracy 0.659999966621\n",
      "Step 31300, training accuracy 0.579999923706\n",
      "Step 31400, training accuracy 0.579999983311\n",
      "Step 31500, training accuracy 0.649999976158\n",
      "Step 31600, training accuracy 0.679999947548\n",
      "Step 31700, training accuracy 0.659999966621\n",
      "Step 31800, training accuracy 0.589999973774\n",
      "Step 31900, training accuracy 0.610000014305\n",
      "Step 32000, training accuracy 0.679999947548\n",
      "Step 32100, training accuracy 0.579999983311\n",
      "Step 32200, training accuracy 0.560000002384\n",
      "Step 32300, training accuracy 0.469999998808\n",
      "Step 32400, training accuracy 0.649999976158\n",
      "Step 32500, training accuracy 0.600000023842\n",
      "Step 32600, training accuracy 0.629999995232\n",
      "Step 32700, training accuracy 0.629999995232\n",
      "Step 32800, training accuracy 0.550000011921\n",
      "Step 32900, training accuracy 0.599999964237\n",
      "Step 33000, training accuracy 0.589999973774\n",
      "Step 33100, training accuracy 0.639999985695\n",
      "Step 33200, training accuracy 0.579999983311\n",
      "Step 33300, training accuracy 0.589999973774\n",
      "Step 33400, training accuracy 0.589999973774\n",
      "Step 33500, training accuracy 0.629999995232\n",
      "Step 33600, training accuracy 0.659999966621\n",
      "Step 33700, training accuracy 0.549999952316\n",
      "Step 33800, training accuracy 0.629999995232\n",
      "Step 33900, training accuracy 0.639999985695\n",
      "Step 34000, training accuracy 0.629999995232\n",
      "Step 34100, training accuracy 0.569999992847\n",
      "Step 34200, training accuracy 0.669999957085\n",
      "Step 34300, training accuracy 0.699999988079\n",
      "Step 34400, training accuracy 0.699999988079\n",
      "Step 34500, training accuracy 0.519999980927\n",
      "Step 34600, training accuracy 0.619999945164\n",
      "Step 34700, training accuracy 0.600000023842\n",
      "Step 34800, training accuracy 0.610000014305\n",
      "Step 34900, training accuracy 0.709999978542\n",
      "Step 35000, training accuracy 0.75\n",
      "Step 35100, training accuracy 0.629999935627\n",
      "Step 35200, training accuracy 0.72000002861\n",
      "Step 35300, training accuracy 0.659999966621\n",
      "Step 35400, training accuracy 0.639999985695\n",
      "Step 35500, training accuracy 0.579999983311\n",
      "Step 35600, training accuracy 0.499999970198\n",
      "Step 35700, training accuracy 0.610000014305\n",
      "Step 35800, training accuracy 0.610000014305\n",
      "Step 35900, training accuracy 0.659999966621\n",
      "Step 36000, training accuracy 0.649999976158\n",
      "Step 36100, training accuracy 0.699999988079\n",
      "Step 36200, training accuracy 0.639999985695\n",
      "Step 36300, training accuracy 0.629999995232\n",
      "Step 36400, training accuracy 0.72000002861\n",
      "Step 36500, training accuracy 0.77999997139\n",
      "Step 36600, training accuracy 0.620000004768\n",
      "Step 36700, training accuracy 0.649999976158\n",
      "Step 36800, training accuracy 0.699999928474\n",
      "Step 36900, training accuracy 0.549999952316\n",
      "Step 37000, training accuracy 0.589999973774\n",
      "Step 37100, training accuracy 0.729999959469\n",
      "Step 37200, training accuracy 0.629999995232\n",
      "Step 37300, training accuracy 0.730000019073\n",
      "Step 37400, training accuracy 0.629999995232\n",
      "Step 37500, training accuracy 0.670000016689\n",
      "Step 37600, training accuracy 0.709999978542\n",
      "Step 37700, training accuracy 0.669999957085\n",
      "Step 37800, training accuracy 0.6099999547\n",
      "Step 37900, training accuracy 0.639999985695\n",
      "Step 38000, training accuracy 0.810000002384\n",
      "Step 38100, training accuracy 0.759999990463\n",
      "Step 38200, training accuracy 0.639999985695\n",
      "Step 38300, training accuracy 0.719999969006\n",
      "Step 38400, training accuracy 0.75\n",
      "Step 38500, training accuracy 0.649999976158\n",
      "Step 38600, training accuracy 0.679999947548\n",
      "Step 38700, training accuracy 0.599999964237\n",
      "Step 38800, training accuracy 0.670000016689\n",
      "Step 38900, training accuracy 0.709999978542\n",
      "Step 39000, training accuracy 0.660000026226\n",
      "Step 39100, training accuracy 0.699999988079\n",
      "Step 39200, training accuracy 0.689999997616\n",
      "Step 39300, training accuracy 0.669999957085\n",
      "Step 39400, training accuracy 0.710000038147\n",
      "Step 39500, training accuracy 0.689999997616\n",
      "Step 39600, training accuracy 0.680000007153\n",
      "Step 39700, training accuracy 0.770000040531\n",
      "Step 39800, training accuracy 0.669999957085\n",
      "Step 39900, training accuracy 0.699999928474\n",
      "Step 40000, training accuracy 0.699999988079\n",
      "Step 40100, training accuracy 0.709999978542\n",
      "Step 40200, training accuracy 0.669999957085\n",
      "Step 40300, training accuracy 0.679999947548\n",
      "Step 40400, training accuracy 0.689999997616\n",
      "Step 40500, training accuracy 0.719999969006\n",
      "Step 40600, training accuracy 0.689999938011\n",
      "Step 40700, training accuracy 0.679999947548\n",
      "Step 40800, training accuracy 0.729999959469\n",
      "Step 40900, training accuracy 0.670000016689\n",
      "Step 41000, training accuracy 0.729999959469\n",
      "Step 41100, training accuracy 0.740000009537\n",
      "Step 41200, training accuracy 0.699999988079\n",
      "Step 41300, training accuracy 0.669999957085\n",
      "Step 41400, training accuracy 0.620000004768\n",
      "Step 41500, training accuracy 0.759999990463\n",
      "Step 41600, training accuracy 0.719999909401\n",
      "Step 41700, training accuracy 0.689999997616\n",
      "Step 41800, training accuracy 0.710000038147\n",
      "Step 41900, training accuracy 0.730000019073\n",
      "Step 42000, training accuracy 0.710000038147\n",
      "Step 42100, training accuracy 0.769999980927\n",
      "Step 42200, training accuracy 0.759999990463\n",
      "Step 42300, training accuracy 0.730000019073\n",
      "Step 42400, training accuracy 0.699999988079\n",
      "Step 42500, training accuracy 0.709999978542\n",
      "Step 42600, training accuracy 0.659999966621\n",
      "Step 42700, training accuracy 0.759999990463\n",
      "Step 42800, training accuracy 0.740000009537\n",
      "Step 42900, training accuracy 0.759999990463\n",
      "Step 43000, training accuracy 0.699999988079\n",
      "Step 43100, training accuracy 0.759999990463\n",
      "Step 43200, training accuracy 0.759999990463\n",
      "Step 43300, training accuracy 0.730000019073\n",
      "Step 43400, training accuracy 0.759999990463\n",
      "Step 43500, training accuracy 0.759999990463\n",
      "Step 43600, training accuracy 0.739999949932\n",
      "Step 43700, training accuracy 0.730000019073\n",
      "Step 43800, training accuracy 0.789999961853\n",
      "Step 43900, training accuracy 0.789999961853\n",
      "Step 44000, training accuracy 0.789999961853\n",
      "Step 44100, training accuracy 0.729999959469\n",
      "Step 44200, training accuracy 0.739999949932\n",
      "Step 44300, training accuracy 0.689999997616\n",
      "Step 44400, training accuracy 0.789999961853\n",
      "Step 44500, training accuracy 0.750000059605\n",
      "Step 44600, training accuracy 0.689999938011\n",
      "Step 44700, training accuracy 0.740000009537\n",
      "Step 44800, training accuracy 0.840000033379\n",
      "Step 44900, training accuracy 0.75\n",
      "Step 45000, training accuracy 0.810000002384\n",
      "Step 45100, training accuracy 0.839999973774\n",
      "Step 45200, training accuracy 0.709999978542\n",
      "Step 45300, training accuracy 0.77999997139\n",
      "Step 45400, training accuracy 0.789999961853\n",
      "Step 45500, training accuracy 0.739999949932\n",
      "Step 45600, training accuracy 0.759999930859\n",
      "Step 45700, training accuracy 0.789999961853\n",
      "Step 45800, training accuracy 0.820000052452\n",
      "Step 45900, training accuracy 0.709999978542\n",
      "Step 46000, training accuracy 0.72000002861\n",
      "Step 46100, training accuracy 0.719999969006\n",
      "Step 46200, training accuracy 0.75\n",
      "Step 46300, training accuracy 0.820000052452\n",
      "Step 46400, training accuracy 0.75\n",
      "Step 46500, training accuracy 0.810000002384\n",
      "Step 46600, training accuracy 0.819999933243\n",
      "Step 46700, training accuracy 0.730000019073\n",
      "Step 46800, training accuracy 0.789999961853\n",
      "Step 46900, training accuracy 0.719999969006\n",
      "Step 47000, training accuracy 0.839999914169\n",
      "Step 47100, training accuracy 0.880000054836\n",
      "Step 47200, training accuracy 0.77999997139\n",
      "Step 47300, training accuracy 0.72000002861\n",
      "Step 47400, training accuracy 0.769999980927\n",
      "Step 47500, training accuracy 0.77999997139\n",
      "Step 47600, training accuracy 0.810000002384\n",
      "Step 47700, training accuracy 0.799999952316\n",
      "Step 47800, training accuracy 0.840000033379\n",
      "Step 47900, training accuracy 0.729999959469\n",
      "Step 48000, training accuracy 0.840000033379\n",
      "Step 48100, training accuracy 0.849999964237\n",
      "Step 48200, training accuracy 0.819999992847\n",
      "Step 48300, training accuracy 0.799999952316\n",
      "Step 48400, training accuracy 0.759999990463\n",
      "Step 48500, training accuracy 0.759999990463\n",
      "Step 48600, training accuracy 0.719999969006\n",
      "Step 48700, training accuracy 0.829999923706\n",
      "Step 48800, training accuracy 0.75\n",
      "Step 48900, training accuracy 0.789999961853\n",
      "Step 49000, training accuracy 0.840000033379\n",
      "Step 49100, training accuracy 0.870000004768\n",
      "Step 49200, training accuracy 0.770000040531\n",
      "Step 49300, training accuracy 0.77999997139\n",
      "Step 49400, training accuracy 0.789999961853\n",
      "Step 49500, training accuracy 0.789999961853\n",
      "Step 49600, training accuracy 0.80999994278\n",
      "Step 49700, training accuracy 0.870000004768\n",
      "Step 49800, training accuracy 0.75\n",
      "Step 49900, training accuracy 0.879999995232\n",
      "Step 50000, training accuracy 0.769999980927\n",
      "Step 50100, training accuracy 0.769999980927\n",
      "Step 50200, training accuracy 0.75\n",
      "Step 50300, training accuracy 0.819999992847\n",
      "Step 50400, training accuracy 0.839999973774\n",
      "Step 50500, training accuracy 0.80999994278\n",
      "Step 50600, training accuracy 0.799999952316\n",
      "Step 50700, training accuracy 0.77999997139\n",
      "Step 50800, training accuracy 0.769999980927\n",
      "Step 50900, training accuracy 0.840000033379\n",
      "Step 51000, training accuracy 0.740000009537\n",
      "Step 51100, training accuracy 0.769999980927\n",
      "Step 51200, training accuracy 0.819999992847\n",
      "Step 51300, training accuracy 0.75\n",
      "Step 51400, training accuracy 0.870000004768\n",
      "Step 51500, training accuracy 0.769999980927\n",
      "Step 51600, training accuracy 0.829999983311\n",
      "Step 51700, training accuracy 0.77999997139\n",
      "Step 51800, training accuracy 0.910000026226\n",
      "Step 51900, training accuracy 0.75\n",
      "Step 52000, training accuracy 0.860000014305\n",
      "Step 52100, training accuracy 0.819999992847\n",
      "Step 52200, training accuracy 0.75\n",
      "Step 52300, training accuracy 0.819999933243\n",
      "Step 52400, training accuracy 0.829999923706\n",
      "Step 52500, training accuracy 0.850000023842\n",
      "Step 52600, training accuracy 0.860000014305\n",
      "Step 52700, training accuracy 0.819999992847\n",
      "Step 52800, training accuracy 0.840000033379\n",
      "Step 52900, training accuracy 0.75\n",
      "Step 53000, training accuracy 0.75\n",
      "Step 53100, training accuracy 0.829999983311\n",
      "Step 53200, training accuracy 0.789999961853\n",
      "Step 53300, training accuracy 0.860000014305\n",
      "Step 53400, training accuracy 0.740000009537\n",
      "Step 53500, training accuracy 0.839999973774\n",
      "Step 53600, training accuracy 0.77999997139\n",
      "Step 53700, training accuracy 0.900000095367\n",
      "Step 53800, training accuracy 0.739999949932\n",
      "Step 53900, training accuracy 0.850000023842\n",
      "Step 54000, training accuracy 0.829999923706\n",
      "Step 54100, training accuracy 0.789999961853\n",
      "Step 54200, training accuracy 0.80999994278\n",
      "Step 54300, training accuracy 0.870000004768\n",
      "Step 54400, training accuracy 0.879999995232\n",
      "Step 54500, training accuracy 0.870000064373\n",
      "Step 54600, training accuracy 0.789999961853\n",
      "Step 54700, training accuracy 0.900000035763\n",
      "Step 54800, training accuracy 0.860000014305\n",
      "Step 54900, training accuracy 0.819999992847\n",
      "Step 55000, training accuracy 0.829999923706\n",
      "Step 55100, training accuracy 0.889999985695\n",
      "Step 55200, training accuracy 0.879999995232\n",
      "Step 55300, training accuracy 0.840000033379\n",
      "Step 55400, training accuracy 0.839999914169\n",
      "Step 55500, training accuracy 0.769999980927\n",
      "Step 55600, training accuracy 0.829999983311\n",
      "Step 55700, training accuracy 0.829999983311\n",
      "Step 55800, training accuracy 0.889999985695\n",
      "Step 55900, training accuracy 0.799999952316\n",
      "Step 56000, training accuracy 0.829999983311\n",
      "Step 56100, training accuracy 0.860000014305\n",
      "Step 56200, training accuracy 0.829999923706\n",
      "Step 56300, training accuracy 0.850000023842\n",
      "Step 56400, training accuracy 0.8599999547\n",
      "Step 56500, training accuracy 0.870000004768\n",
      "Step 56600, training accuracy 0.870000004768\n",
      "Step 56700, training accuracy 0.870000064373\n",
      "Step 56800, training accuracy 0.850000023842\n",
      "Step 56900, training accuracy 0.839999973774\n",
      "Step 57000, training accuracy 0.88999992609\n",
      "Step 57100, training accuracy 0.840000033379\n",
      "Step 57200, training accuracy 0.839999973774\n",
      "Step 57300, training accuracy 0.869999945164\n",
      "Step 57400, training accuracy 0.860000014305\n",
      "Step 57500, training accuracy 0.819999992847\n",
      "Step 57600, training accuracy 0.820000052452\n",
      "Step 57700, training accuracy 0.859999895096\n",
      "Step 57800, training accuracy 0.879999995232\n",
      "Step 57900, training accuracy 0.77999997139\n",
      "Step 58000, training accuracy 0.869999885559\n",
      "Step 58100, training accuracy 0.799999952316\n",
      "Step 58200, training accuracy 0.86000007391\n",
      "Step 58300, training accuracy 0.8900000453\n",
      "Step 58400, training accuracy 0.8599999547\n",
      "Step 58500, training accuracy 0.870000004768\n",
      "Step 58600, training accuracy 0.850000023842\n",
      "Step 58700, training accuracy 0.880000054836\n",
      "Step 58800, training accuracy 0.840000033379\n",
      "Step 58900, training accuracy 0.840000033379\n",
      "Step 59000, training accuracy 0.839999973774\n",
      "Step 59100, training accuracy 0.839999914169\n",
      "Step 59200, training accuracy 0.860000014305\n",
      "Step 59300, training accuracy 0.839999973774\n",
      "Step 59400, training accuracy 0.850000023842\n",
      "Step 59500, training accuracy 0.820000052452\n",
      "Step 59600, training accuracy 0.80999994278\n",
      "Step 59700, training accuracy 0.879999995232\n",
      "Step 59800, training accuracy 0.839999914169\n",
      "Step 59900, training accuracy 0.839999973774\n",
      "Step 60000, training accuracy 0.880000054836\n",
      "Step 60100, training accuracy 0.899999976158\n",
      "Step 60200, training accuracy 0.8599999547\n",
      "Step 60300, training accuracy 0.850000023842\n",
      "Step 60400, training accuracy 0.8599999547\n",
      "Step 60500, training accuracy 0.839999914169\n",
      "Step 60600, training accuracy 0.840000033379\n",
      "Step 60700, training accuracy 0.880000054836\n",
      "Step 60800, training accuracy 0.870000004768\n",
      "Step 60900, training accuracy 0.880000054836\n",
      "Step 61000, training accuracy 0.80999994278\n",
      "Step 61100, training accuracy 0.829999983311\n",
      "Step 61200, training accuracy 0.810000061989\n",
      "Step 61300, training accuracy 0.829999983311\n",
      "Step 61400, training accuracy 0.839999973774\n",
      "Step 61500, training accuracy 0.870000004768\n",
      "Step 61600, training accuracy 0.810000002384\n",
      "Step 61700, training accuracy 0.870000004768\n",
      "Step 61800, training accuracy 0.799999952316\n",
      "Step 61900, training accuracy 0.819999933243\n",
      "Step 62000, training accuracy 0.880000054836\n",
      "Step 62100, training accuracy 0.839999973774\n",
      "Step 62200, training accuracy 0.839999973774\n",
      "Step 62300, training accuracy 0.880000114441\n",
      "Step 62400, training accuracy 0.899999976158\n",
      "Step 62500, training accuracy 0.869999945164\n",
      "Step 62600, training accuracy 0.870000004768\n",
      "Step 62700, training accuracy 0.879999995232\n",
      "Step 62800, training accuracy 0.769999980927\n",
      "Step 62900, training accuracy 0.819999933243\n",
      "Step 63000, training accuracy 0.900000035763\n",
      "Step 63100, training accuracy 0.899999976158\n",
      "Step 63200, training accuracy 0.850000023842\n",
      "Step 63300, training accuracy 0.850000023842\n",
      "Step 63400, training accuracy 0.839999973774\n",
      "Step 63500, training accuracy 0.829999923706\n",
      "Step 63600, training accuracy 0.77999997139\n",
      "Step 63700, training accuracy 0.870000004768\n",
      "Step 63800, training accuracy 0.80999994278\n",
      "Step 63900, training accuracy 0.860000014305\n",
      "Step 64000, training accuracy 0.850000023842\n",
      "Step 64100, training accuracy 0.80999994278\n",
      "Step 64200, training accuracy 0.919999957085\n",
      "Step 64300, training accuracy 0.850000023842\n",
      "Step 64400, training accuracy 0.879999995232\n",
      "Step 64500, training accuracy 0.829999923706\n",
      "Step 64600, training accuracy 0.889999985695\n",
      "Step 64700, training accuracy 0.889999985695\n",
      "Step 64800, training accuracy 0.850000023842\n",
      "Step 64900, training accuracy 0.950000047684\n",
      "Step 65000, training accuracy 0.870000004768\n",
      "Step 65100, training accuracy 0.909999966621\n",
      "Step 65200, training accuracy 0.829999983311\n",
      "Step 65300, training accuracy 0.849999964237\n",
      "Step 65400, training accuracy 0.849999964237\n",
      "Step 65500, training accuracy 0.879999995232\n",
      "Step 65600, training accuracy 0.870000004768\n",
      "Step 65700, training accuracy 0.829999923706\n",
      "Step 65800, training accuracy 0.829999983311\n",
      "Step 65900, training accuracy 0.860000014305\n",
      "Step 66000, training accuracy 0.850000023842\n",
      "Step 66100, training accuracy 0.860000014305\n",
      "Step 66200, training accuracy 0.879999995232\n",
      "Step 66300, training accuracy 0.8599999547\n",
      "Step 66400, training accuracy 0.890000104904\n",
      "Step 66500, training accuracy 0.850000023842\n",
      "Step 66600, training accuracy 0.860000014305\n",
      "Step 66700, training accuracy 0.870000004768\n",
      "Step 66800, training accuracy 0.8900000453\n",
      "Step 66900, training accuracy 0.879999935627\n",
      "Step 67000, training accuracy 0.900000035763\n",
      "Step 67100, training accuracy 0.910000085831\n",
      "Step 67200, training accuracy 0.900000035763\n",
      "Step 67300, training accuracy 0.879999995232\n",
      "Step 67400, training accuracy 0.860000014305\n",
      "Step 67500, training accuracy 0.8900000453\n",
      "Step 67600, training accuracy 0.900000035763\n",
      "Step 67700, training accuracy 0.889999985695\n",
      "Step 67800, training accuracy 0.870000064373\n",
      "Step 67900, training accuracy 0.870000004768\n",
      "Step 68000, training accuracy 0.899999976158\n",
      "Step 68100, training accuracy 0.850000023842\n",
      "Step 68200, training accuracy 0.889999985695\n",
      "Step 68300, training accuracy 0.910000026226\n",
      "Step 68400, training accuracy 0.889999985695\n",
      "Step 68500, training accuracy 0.94000005722\n",
      "Step 68600, training accuracy 0.880000054836\n",
      "Step 68700, training accuracy 0.930000007153\n",
      "Step 68800, training accuracy 0.899999976158\n",
      "Step 68900, training accuracy 0.919999957085\n",
      "Step 69000, training accuracy 0.870000004768\n",
      "Step 69100, training accuracy 0.900000035763\n",
      "Step 69200, training accuracy 0.920000076294\n",
      "Step 69300, training accuracy 0.849999964237\n",
      "Step 69400, training accuracy 0.870000004768\n",
      "Step 69500, training accuracy 0.870000004768\n",
      "Step 69600, training accuracy 0.910000026226\n",
      "Step 69700, training accuracy 0.950000047684\n",
      "Step 69800, training accuracy 0.910000026226\n",
      "Step 69900, training accuracy 0.930000007153\n",
      "Step 70000, training accuracy 0.859999895096\n",
      "Step 70100, training accuracy 0.870000004768\n",
      "Step 70200, training accuracy 0.879999995232\n",
      "Step 70300, training accuracy 0.939999938011\n",
      "Step 70400, training accuracy 0.899999976158\n",
      "Step 70500, training accuracy 0.910000026226\n",
      "Step 70600, training accuracy 0.939999997616\n",
      "Step 70700, training accuracy 0.910000085831\n",
      "Step 70800, training accuracy 0.910000026226\n",
      "Step 70900, training accuracy 0.829999923706\n",
      "Step 71000, training accuracy 0.900000035763\n",
      "Step 71100, training accuracy 0.900000035763\n",
      "Step 71200, training accuracy 0.949999988079\n",
      "Step 71300, training accuracy 0.840000033379\n",
      "Step 71400, training accuracy 0.930000007153\n",
      "Step 71500, training accuracy 0.870000004768\n",
      "Step 71600, training accuracy 0.870000004768\n",
      "Step 71700, training accuracy 0.899999976158\n",
      "Step 71800, training accuracy 0.839999973774\n",
      "Step 71900, training accuracy 0.879999935627\n",
      "Step 72000, training accuracy 0.910000026226\n",
      "Step 72100, training accuracy 0.920000076294\n",
      "Step 72200, training accuracy 0.870000004768\n",
      "Step 72300, training accuracy 0.850000023842\n",
      "Step 72400, training accuracy 0.899999976158\n",
      "Step 72500, training accuracy 0.929999947548\n",
      "Step 72600, training accuracy 0.860000014305\n",
      "Step 72700, training accuracy 0.879999995232\n",
      "Step 72800, training accuracy 0.879999995232\n",
      "Step 72900, training accuracy 0.900000095367\n",
      "Step 73000, training accuracy 0.909999966621\n",
      "Step 73100, training accuracy 0.889999985695\n",
      "Step 73200, training accuracy 0.80999994278\n",
      "Step 73300, training accuracy 0.920000016689\n",
      "Step 73400, training accuracy 0.889999985695\n",
      "Step 73500, training accuracy 0.8900000453\n",
      "Step 73600, training accuracy 0.939999997616\n",
      "Step 73700, training accuracy 0.920000016689\n",
      "Step 73800, training accuracy 0.870000004768\n",
      "Step 73900, training accuracy 0.850000023842\n",
      "Step 74000, training accuracy 0.94000005722\n",
      "Step 74100, training accuracy 0.839999973774\n",
      "Step 74200, training accuracy 0.889999985695\n",
      "Step 74300, training accuracy 0.910000026226\n",
      "Step 74400, training accuracy 0.879999995232\n",
      "Step 74500, training accuracy 0.900000035763\n",
      "Step 74600, training accuracy 0.870000004768\n",
      "Step 74700, training accuracy 0.920000016689\n",
      "Step 74800, training accuracy 0.880000054836\n",
      "Step 74900, training accuracy 0.919999957085\n",
      "Step 75000, training accuracy 0.889999985695\n",
      "Step 75100, training accuracy 0.900000035763\n",
      "Step 75200, training accuracy 0.920000016689\n",
      "Step 75300, training accuracy 0.889999985695\n",
      "Step 75400, training accuracy 0.850000023842\n",
      "Step 75500, training accuracy 0.919999957085\n",
      "Step 75600, training accuracy 0.910000026226\n",
      "Step 75700, training accuracy 0.910000026226\n",
      "Step 75800, training accuracy 0.919999957085\n",
      "Step 75900, training accuracy 0.880000054836\n",
      "Step 76000, training accuracy 0.889999985695\n",
      "Step 76100, training accuracy 0.870000004768\n",
      "Step 76200, training accuracy 0.909999966621\n",
      "Step 76300, training accuracy 0.879999995232\n",
      "Step 76400, training accuracy 0.899999976158\n",
      "Step 76500, training accuracy 0.8599999547\n",
      "Step 76600, training accuracy 0.870000004768\n",
      "Step 76700, training accuracy 0.860000014305\n",
      "Step 76800, training accuracy 0.910000026226\n",
      "Step 76900, training accuracy 0.889999985695\n",
      "Step 77000, training accuracy 0.879999935627\n",
      "Step 77100, training accuracy 0.8900000453\n",
      "Step 77200, training accuracy 0.900000095367\n",
      "Step 77300, training accuracy 0.870000004768\n",
      "Step 77400, training accuracy 0.910000026226\n",
      "Step 77500, training accuracy 0.909999966621\n",
      "Step 77600, training accuracy 0.899999976158\n",
      "Step 77700, training accuracy 0.839999973774\n",
      "Step 77800, training accuracy 0.920000016689\n",
      "Step 77900, training accuracy 0.910000026226\n",
      "Step 78000, training accuracy 0.939999997616\n",
      "Step 78100, training accuracy 0.870000004768\n",
      "Step 78200, training accuracy 0.930000007153\n",
      "Step 78300, training accuracy 0.900000095367\n",
      "Step 78400, training accuracy 0.88999992609\n",
      "Step 78500, training accuracy 0.920000016689\n",
      "Step 78600, training accuracy 0.849999964237\n",
      "Step 78700, training accuracy 0.919999957085\n",
      "Step 78800, training accuracy 0.930000066757\n",
      "Step 78900, training accuracy 0.880000054836\n",
      "Step 79000, training accuracy 0.910000085831\n",
      "Step 79100, training accuracy 0.930000007153\n",
      "Step 79200, training accuracy 0.8900000453\n",
      "Step 79300, training accuracy 0.900000035763\n",
      "Step 79400, training accuracy 0.930000007153\n",
      "Step 79500, training accuracy 0.920000016689\n",
      "Step 79600, training accuracy 0.919999957085\n",
      "Step 79700, training accuracy 0.939999997616\n",
      "Step 79800, training accuracy 0.879999995232\n",
      "Step 79900, training accuracy 0.879999995232\n",
      "Step 80000, training accuracy 0.850000023842\n",
      "Step 80100, training accuracy 0.900000035763\n",
      "Step 80200, training accuracy 0.920000076294\n",
      "Step 80300, training accuracy 0.870000004768\n",
      "Step 80400, training accuracy 0.899999976158\n",
      "Step 80500, training accuracy 0.950000047684\n",
      "Step 80600, training accuracy 0.949999988079\n",
      "Step 80700, training accuracy 0.879999995232\n",
      "Step 80800, training accuracy 0.870000004768\n",
      "Step 80900, training accuracy 0.879999995232\n",
      "Step 81000, training accuracy 0.860000014305\n",
      "Step 81100, training accuracy 0.950000047684\n",
      "Step 81200, training accuracy 0.909999966621\n",
      "Step 81300, training accuracy 0.839999973774\n",
      "Step 81400, training accuracy 0.920000076294\n",
      "Step 81500, training accuracy 0.930000066757\n",
      "Step 81600, training accuracy 0.94000005722\n",
      "Step 81700, training accuracy 0.879999995232\n",
      "Step 81800, training accuracy 0.8900000453\n",
      "Step 81900, training accuracy 0.910000085831\n",
      "Step 82000, training accuracy 0.869999945164\n",
      "Step 82100, training accuracy 0.930000007153\n",
      "Step 82200, training accuracy 0.909999966621\n",
      "Step 82300, training accuracy 0.920000016689\n",
      "Step 82400, training accuracy 0.910000085831\n",
      "Step 82500, training accuracy 0.920000016689\n",
      "Step 82600, training accuracy 0.910000085831\n",
      "Step 82700, training accuracy 0.960000038147\n",
      "Step 82800, training accuracy 0.870000004768\n",
      "Step 82900, training accuracy 0.920000076294\n",
      "Step 83000, training accuracy 0.930000066757\n",
      "Step 83100, training accuracy 0.930000066757\n",
      "Step 83200, training accuracy 0.930000066757\n",
      "Step 83300, training accuracy 0.899999976158\n",
      "Step 83400, training accuracy 0.930000007153\n",
      "Step 83500, training accuracy 0.920000016689\n",
      "Step 83600, training accuracy 0.8900000453\n",
      "Step 83700, training accuracy 0.900000035763\n",
      "Step 83800, training accuracy 0.929999947548\n",
      "Step 83900, training accuracy 0.949999988079\n",
      "Step 84000, training accuracy 0.910000026226\n",
      "Step 84100, training accuracy 0.920000016689\n",
      "Step 84200, training accuracy 0.930000007153\n",
      "Step 84300, training accuracy 0.920000076294\n",
      "Step 84400, training accuracy 0.860000014305\n",
      "Step 84500, training accuracy 0.900000035763\n",
      "Step 84600, training accuracy 0.930000066757\n",
      "Step 84700, training accuracy 0.880000054836\n",
      "Step 84800, training accuracy 0.920000016689\n",
      "Step 84900, training accuracy 0.920000076294\n",
      "Step 85000, training accuracy 0.949999988079\n",
      "Step 85100, training accuracy 0.94000005722\n",
      "Step 85200, training accuracy 0.930000066757\n",
      "Step 85300, training accuracy 0.900000035763\n",
      "Step 85400, training accuracy 0.94000005722\n",
      "Step 85500, training accuracy 0.930000007153\n",
      "Step 85600, training accuracy 0.879999995232\n",
      "Step 85700, training accuracy 0.909999966621\n",
      "Step 85800, training accuracy 0.920000016689\n",
      "Step 85900, training accuracy 0.900000035763\n",
      "Step 86000, training accuracy 0.97000002861\n",
      "Step 86100, training accuracy 0.930000007153\n",
      "Step 86200, training accuracy 0.910000026226\n",
      "Step 86300, training accuracy 0.910000026226\n",
      "Step 86400, training accuracy 0.939999997616\n",
      "Step 86500, training accuracy 0.899999976158\n",
      "Step 86600, training accuracy 0.900000035763\n",
      "Step 86700, training accuracy 0.930000007153\n",
      "Step 86800, training accuracy 0.97000002861\n",
      "Step 86900, training accuracy 0.960000038147\n",
      "Step 87000, training accuracy 0.860000014305\n",
      "Step 87100, training accuracy 0.919999957085\n",
      "Step 87200, training accuracy 0.94000005722\n",
      "Step 87300, training accuracy 0.900000035763\n",
      "Step 87400, training accuracy 0.920000016689\n",
      "Step 87500, training accuracy 0.930000066757\n",
      "Step 87600, training accuracy 0.930000007153\n",
      "Step 87700, training accuracy 0.94000005722\n",
      "Step 87800, training accuracy 0.920000016689\n",
      "Step 87900, training accuracy 0.869999945164\n",
      "Step 88000, training accuracy 0.899999976158\n",
      "Step 88100, training accuracy 0.920000076294\n",
      "Step 88200, training accuracy 0.920000016689\n",
      "Step 88300, training accuracy 0.920000016689\n",
      "Step 88400, training accuracy 0.959999978542\n",
      "Step 88500, training accuracy 0.920000016689\n",
      "Step 88600, training accuracy 0.920000016689\n",
      "Step 88700, training accuracy 0.880000054836\n",
      "Step 88800, training accuracy 0.879999995232\n",
      "Step 88900, training accuracy 0.930000007153\n",
      "Step 89000, training accuracy 0.930000007153\n",
      "Step 89100, training accuracy 0.910000026226\n",
      "Step 89200, training accuracy 0.930000007153\n",
      "Step 89300, training accuracy 0.929999947548\n",
      "Step 89400, training accuracy 0.8599999547\n",
      "Step 89500, training accuracy 0.920000076294\n",
      "Step 89600, training accuracy 0.94000005722\n",
      "Step 89700, training accuracy 0.930000066757\n",
      "Step 89800, training accuracy 0.899999976158\n",
      "Step 89900, training accuracy 0.900000035763\n",
      "Step 90000, training accuracy 0.910000026226\n",
      "Step 90100, training accuracy 0.930000066757\n",
      "Step 90200, training accuracy 0.960000038147\n",
      "Step 90300, training accuracy 0.920000076294\n",
      "Step 90400, training accuracy 0.930000066757\n",
      "Step 90500, training accuracy 0.919999957085\n",
      "Step 90600, training accuracy 0.930000007153\n",
      "Step 90700, training accuracy 0.980000019073\n",
      "Step 90800, training accuracy 0.930000066757\n",
      "Step 90900, training accuracy 0.94000005722\n",
      "Step 91000, training accuracy 0.910000085831\n",
      "Step 91100, training accuracy 0.950000047684\n",
      "Step 91200, training accuracy 0.950000047684\n",
      "Step 91300, training accuracy 0.94000005722\n",
      "Step 91400, training accuracy 0.930000066757\n",
      "Step 91500, training accuracy 0.94000005722\n",
      "Step 91600, training accuracy 0.900000035763\n",
      "Step 91700, training accuracy 0.939999997616\n",
      "Step 91800, training accuracy 0.939999997616\n",
      "Step 91900, training accuracy 0.899999976158\n",
      "Step 92000, training accuracy 0.920000016689\n",
      "Step 92100, training accuracy 0.930000066757\n",
      "Step 92200, training accuracy 0.929999947548\n",
      "Step 92300, training accuracy 0.969999969006\n",
      "Step 92400, training accuracy 0.920000016689\n",
      "Step 92500, training accuracy 0.930000066757\n",
      "Step 92600, training accuracy 0.910000085831\n",
      "Step 92700, training accuracy 0.94000005722\n",
      "Step 92800, training accuracy 0.889999985695\n",
      "Step 92900, training accuracy 0.919999957085\n",
      "Step 93000, training accuracy 0.960000038147\n",
      "Step 93100, training accuracy 0.960000038147\n",
      "Step 93200, training accuracy 0.930000007153\n",
      "Step 93300, training accuracy 0.949999988079\n",
      "Step 93400, training accuracy 0.920000016689\n",
      "Step 93500, training accuracy 0.930000007153\n",
      "Step 93600, training accuracy 0.949999988079\n",
      "Step 93700, training accuracy 0.930000007153\n",
      "Step 93800, training accuracy 0.909999966621\n",
      "Step 93900, training accuracy 0.930000066757\n",
      "Step 94000, training accuracy 0.920000016689\n",
      "Step 94100, training accuracy 0.920000016689\n",
      "Step 94200, training accuracy 0.950000047684\n",
      "Step 94300, training accuracy 0.920000016689\n",
      "Step 94400, training accuracy 0.910000026226\n",
      "Step 94500, training accuracy 0.920000076294\n",
      "Step 94600, training accuracy 0.920000076294\n",
      "Step 94700, training accuracy 0.899999976158\n",
      "Step 94800, training accuracy 0.930000007153\n",
      "Step 94900, training accuracy 0.910000026226\n",
      "Step 95000, training accuracy 0.949999988079\n",
      "Step 95100, training accuracy 0.929999947548\n",
      "Step 95200, training accuracy 0.949999988079\n",
      "Step 95300, training accuracy 0.900000035763\n",
      "Step 95400, training accuracy 0.899999976158\n",
      "Step 95500, training accuracy 0.960000038147\n",
      "Step 95600, training accuracy 0.920000016689\n",
      "Step 95700, training accuracy 0.980000019073\n",
      "Step 95800, training accuracy 0.94000005722\n",
      "Step 95900, training accuracy 0.910000026226\n",
      "Step 96000, training accuracy 0.959999978542\n",
      "Step 96100, training accuracy 0.949999988079\n",
      "Step 96200, training accuracy 0.920000076294\n",
      "Step 96300, training accuracy 0.94000005722\n",
      "Step 96400, training accuracy 0.989999949932\n",
      "Step 96500, training accuracy 0.949999988079\n",
      "Step 96600, training accuracy 0.8900000453\n",
      "Step 96700, training accuracy 0.920000076294\n",
      "Step 96800, training accuracy 0.930000066757\n",
      "Step 96900, training accuracy 0.949999988079\n",
      "Step 97000, training accuracy 0.910000026226\n",
      "Step 97100, training accuracy 0.959999978542\n",
      "Step 97200, training accuracy 0.94000005722\n",
      "Step 97300, training accuracy 0.980000019073\n",
      "Step 97400, training accuracy 0.94000005722\n",
      "Step 97500, training accuracy 0.910000026226\n",
      "Step 97600, training accuracy 0.94000005722\n",
      "Step 97700, training accuracy 0.939999997616\n",
      "Step 97800, training accuracy 0.920000016689\n",
      "Step 97900, training accuracy 0.920000016689\n",
      "Step 98000, training accuracy 0.939999997616\n",
      "Step 98100, training accuracy 0.930000066757\n",
      "Step 98200, training accuracy 0.939999997616\n",
      "Step 98300, training accuracy 0.949999988079\n",
      "Step 98400, training accuracy 0.910000026226\n",
      "Step 98500, training accuracy 0.8900000453\n",
      "Step 98600, training accuracy 0.910000026226\n",
      "Step 98700, training accuracy 0.94000005722\n",
      "Step 98800, training accuracy 0.959999978542\n",
      "Step 98900, training accuracy 0.989999949932\n",
      "Step 99000, training accuracy 0.929999947548\n",
      "Step 99100, training accuracy 0.980000019073\n",
      "Step 99200, training accuracy 0.980000019073\n",
      "Step 99300, training accuracy 0.920000076294\n",
      "Step 99400, training accuracy 0.959999978542\n",
      "Step 99500, training accuracy 0.960000038147\n",
      "Step 99600, training accuracy 0.930000066757\n",
      "Step 99700, training accuracy 0.950000047684\n",
      "Step 99800, training accuracy 0.920000076294\n",
      "Step 99900, training accuracy 0.939999997616\n",
      "Step 100000, training accuracy 0.939999997616\n",
      "Step 100100, training accuracy 0.899999976158\n",
      "Step 100200, training accuracy 0.94000005722\n",
      "Step 100300, training accuracy 0.889999985695\n",
      "Step 100400, training accuracy 0.969999969006\n",
      "Step 100500, training accuracy 0.860000014305\n",
      "Step 100600, training accuracy 0.889999985695\n",
      "Step 100700, training accuracy 0.900000095367\n",
      "Step 100800, training accuracy 0.920000076294\n",
      "Step 100900, training accuracy 0.989999949932\n",
      "Step 101000, training accuracy 0.949999988079\n",
      "Step 101100, training accuracy 0.949999988079\n",
      "Step 101200, training accuracy 0.900000035763\n",
      "Step 101300, training accuracy 0.969999969006\n",
      "Step 101400, training accuracy 0.930000007153\n",
      "Step 101500, training accuracy 0.920000016689\n",
      "Step 101600, training accuracy 0.949999988079\n",
      "Step 101700, training accuracy 0.97000002861\n",
      "Step 101800, training accuracy 0.930000066757\n",
      "Step 101900, training accuracy 0.910000026226\n",
      "Step 102000, training accuracy 0.960000038147\n",
      "Step 102100, training accuracy 0.930000007153\n",
      "Step 102200, training accuracy 0.909999966621\n",
      "Step 102300, training accuracy 0.949999988079\n",
      "Step 102400, training accuracy 0.969999969006\n",
      "Step 102500, training accuracy 0.930000007153\n",
      "Step 102600, training accuracy 0.960000038147\n",
      "Step 102700, training accuracy 0.8900000453\n",
      "Step 102800, training accuracy 0.959999978542\n",
      "Step 102900, training accuracy 0.949999988079\n",
      "Step 103000, training accuracy 0.939999997616\n",
      "Step 103100, training accuracy 0.930000066757\n",
      "Step 103200, training accuracy 0.899999976158\n",
      "Step 103300, training accuracy 0.930000066757\n",
      "Step 103400, training accuracy 0.930000007153\n",
      "Step 103500, training accuracy 0.97000002861\n",
      "Step 103600, training accuracy 0.920000016689\n",
      "Step 103700, training accuracy 0.919999957085\n",
      "Step 103800, training accuracy 0.960000038147\n",
      "Step 103900, training accuracy 0.950000047684\n",
      "Step 104000, training accuracy 0.94000005722\n",
      "Step 104100, training accuracy 0.949999988079\n",
      "Step 104200, training accuracy 0.959999978542\n",
      "Step 104300, training accuracy 0.950000047684\n",
      "Step 104400, training accuracy 0.990000009537\n",
      "Step 104500, training accuracy 0.920000016689\n",
      "Step 104600, training accuracy 0.959999978542\n",
      "Step 104700, training accuracy 0.930000007153\n",
      "Step 104800, training accuracy 0.930000007153\n",
      "Step 104900, training accuracy 0.97000002861\n",
      "Step 105000, training accuracy 0.939999997616\n",
      "Step 105100, training accuracy 0.900000035763\n",
      "Step 105200, training accuracy 0.939999997616\n",
      "Step 105300, training accuracy 0.939999997616\n",
      "Step 105400, training accuracy 0.989999949932\n",
      "Step 105500, training accuracy 0.960000038147\n",
      "Step 105600, training accuracy 0.930000066757\n",
      "Step 105700, training accuracy 0.899999976158\n",
      "Step 105800, training accuracy 0.990000009537\n",
      "Step 105900, training accuracy 0.960000038147\n",
      "Step 106000, training accuracy 0.97000002861\n",
      "Step 106100, training accuracy 0.980000019073\n",
      "Step 106200, training accuracy 0.939999997616\n",
      "Step 106300, training accuracy 0.959999978542\n",
      "Step 106400, training accuracy 0.930000066757\n",
      "Step 106500, training accuracy 0.930000066757\n",
      "Step 106600, training accuracy 0.939999997616\n",
      "Step 106700, training accuracy 0.920000016689\n",
      "Step 106800, training accuracy 0.960000038147\n",
      "Step 106900, training accuracy 0.939999997616\n",
      "Step 107000, training accuracy 0.910000026226\n",
      "Step 107100, training accuracy 0.959999978542\n",
      "Step 107200, training accuracy 0.980000019073\n",
      "Step 107300, training accuracy 0.929999947548\n",
      "Step 107400, training accuracy 0.910000026226\n",
      "Step 107500, training accuracy 0.959999978542\n",
      "Step 107600, training accuracy 0.949999988079\n",
      "Step 107700, training accuracy 0.949999988079\n",
      "Step 107800, training accuracy 0.930000007153\n",
      "Step 107900, training accuracy 0.909999966621\n",
      "Step 108000, training accuracy 0.980000019073\n",
      "Step 108100, training accuracy 0.959999978542\n",
      "Step 108200, training accuracy 0.959999978542\n",
      "Step 108300, training accuracy 0.980000019073\n",
      "Step 108400, training accuracy 0.939999997616\n",
      "Step 108500, training accuracy 0.949999988079\n",
      "Step 108600, training accuracy 0.960000038147\n",
      "Step 108700, training accuracy 0.900000035763\n",
      "Step 108800, training accuracy 0.949999988079\n",
      "Step 108900, training accuracy 0.959999978542\n",
      "Step 109000, training accuracy 0.939999997616\n",
      "Step 109100, training accuracy 0.930000007153\n",
      "Step 109200, training accuracy 0.930000007153\n",
      "Step 109300, training accuracy 0.939999997616\n",
      "Step 109400, training accuracy 0.969999969006\n",
      "Step 109500, training accuracy 0.920000016689\n",
      "Step 109600, training accuracy 0.94000005722\n",
      "Step 109700, training accuracy 0.929999947548\n",
      "Step 109800, training accuracy 0.960000038147\n",
      "Step 109900, training accuracy 0.97000002861\n",
      "Step 110000, training accuracy 0.930000007153\n",
      "Step 110100, training accuracy 0.960000038147\n",
      "Step 110200, training accuracy 0.950000047684\n",
      "Step 110300, training accuracy 0.949999988079\n",
      "Step 110400, training accuracy 0.929999947548\n",
      "Step 110500, training accuracy 0.979999959469\n",
      "Step 110600, training accuracy 0.94000005722\n",
      "Step 110700, training accuracy 0.960000038147\n",
      "Step 110800, training accuracy 0.939999997616\n",
      "Step 110900, training accuracy 0.959999978542\n",
      "Step 111000, training accuracy 0.959999978542\n",
      "Step 111100, training accuracy 0.929999947548\n",
      "Step 111200, training accuracy 0.960000038147\n",
      "Step 111300, training accuracy 0.990000009537\n",
      "Step 111400, training accuracy 0.910000026226\n",
      "Step 111500, training accuracy 0.969999969006\n",
      "Step 111600, training accuracy 0.960000038147\n",
      "Step 111700, training accuracy 0.959999978542\n",
      "Step 111800, training accuracy 0.960000038147\n",
      "Step 111900, training accuracy 0.960000038147\n",
      "Step 112000, training accuracy 0.959999978542\n",
      "Step 112100, training accuracy 0.959999978542\n",
      "Step 112200, training accuracy 0.959999978542\n",
      "Step 112300, training accuracy 0.920000016689\n",
      "Step 112400, training accuracy 0.939999997616\n",
      "Step 112500, training accuracy 0.97000002861\n",
      "Step 112600, training accuracy 0.949999988079\n",
      "Step 112700, training accuracy 0.979999959469\n",
      "Step 112800, training accuracy 0.999999940395\n",
      "Step 112900, training accuracy 0.959999978542\n",
      "Step 113000, training accuracy 0.939999997616\n",
      "Step 113100, training accuracy 0.969999969006\n",
      "Step 113200, training accuracy 0.939999997616\n",
      "Step 113300, training accuracy 0.94000005722\n",
      "Step 113400, training accuracy 0.939999997616\n",
      "Step 113500, training accuracy 0.930000007153\n",
      "Step 113600, training accuracy 0.920000016689\n",
      "Step 113700, training accuracy 0.979999959469\n",
      "Step 113800, training accuracy 0.960000038147\n",
      "Step 113900, training accuracy 0.930000007153\n",
      "Step 114000, training accuracy 0.960000038147\n",
      "Step 114100, training accuracy 0.910000026226\n",
      "Step 114200, training accuracy 0.930000007153\n",
      "Step 114300, training accuracy 0.969999969006\n",
      "Step 114400, training accuracy 0.939999997616\n",
      "Step 114500, training accuracy 0.950000047684\n",
      "Step 114600, training accuracy 0.980000019073\n",
      "Step 114700, training accuracy 0.949999928474\n",
      "Step 114800, training accuracy 0.939999938011\n",
      "Step 114900, training accuracy 0.959999978542\n",
      "Step 115000, training accuracy 0.8900000453\n",
      "Step 115100, training accuracy 0.8900000453\n",
      "Step 115200, training accuracy 0.939999997616\n",
      "Step 115300, training accuracy 0.930000007153\n",
      "Step 115400, training accuracy 0.949999928474\n",
      "Step 115500, training accuracy 0.94000005722\n",
      "Step 115600, training accuracy 0.930000007153\n",
      "Step 115700, training accuracy 0.97000002861\n",
      "Step 115800, training accuracy 0.939999938011\n",
      "Step 115900, training accuracy 0.930000066757\n",
      "Step 116000, training accuracy 0.949999988079\n",
      "Step 116100, training accuracy 0.920000076294\n",
      "Step 116200, training accuracy 0.97000002861\n",
      "Step 116300, training accuracy 0.959999978542\n",
      "Step 116400, training accuracy 0.909999966621\n",
      "Step 116500, training accuracy 0.969999969006\n",
      "Step 116600, training accuracy 0.899999976158\n",
      "Step 116700, training accuracy 0.980000019073\n",
      "Step 116800, training accuracy 0.959999978542\n",
      "Step 116900, training accuracy 0.949999928474\n",
      "Step 117000, training accuracy 0.980000019073\n",
      "Step 117100, training accuracy 0.920000076294\n",
      "Step 117200, training accuracy 0.999999940395\n",
      "Step 117300, training accuracy 0.930000007153\n",
      "Step 117400, training accuracy 0.960000038147\n",
      "Step 117500, training accuracy 1.0\n",
      "Step 117600, training accuracy 0.959999978542\n",
      "Step 117700, training accuracy 0.969999969006\n",
      "Step 117800, training accuracy 0.920000016689\n",
      "Step 117900, training accuracy 0.990000009537\n",
      "Step 118000, training accuracy 0.969999969006\n",
      "Step 118100, training accuracy 0.949999988079\n",
      "Step 118200, training accuracy 0.899999976158\n",
      "Step 118300, training accuracy 0.950000047684\n",
      "Step 118400, training accuracy 0.919999957085\n",
      "Step 118500, training accuracy 0.939999997616\n",
      "Step 118600, training accuracy 0.939999997616\n",
      "Step 118700, training accuracy 0.980000019073\n",
      "Step 118800, training accuracy 0.969999969006\n",
      "Step 118900, training accuracy 0.97000002861\n",
      "Step 119000, training accuracy 0.930000007153\n",
      "Step 119100, training accuracy 0.950000047684\n",
      "Step 119200, training accuracy 0.950000047684\n",
      "Step 119300, training accuracy 0.94000005722\n",
      "Step 119400, training accuracy 0.959999978542\n",
      "Step 119500, training accuracy 0.980000019073\n",
      "Step 119600, training accuracy 0.920000076294\n",
      "Step 119700, training accuracy 0.959999978542\n",
      "Step 119800, training accuracy 0.939999938011\n",
      "Step 119900, training accuracy 0.960000038147\n",
      "Step 120000, training accuracy 0.960000038147\n",
      "Step 120100, training accuracy 0.949999988079\n",
      "Step 120200, training accuracy 0.930000007153\n",
      "Step 120300, training accuracy 0.969999969006\n",
      "Step 120400, training accuracy 0.94000005722\n",
      "Step 120500, training accuracy 0.969999909401\n",
      "Step 120600, training accuracy 0.959999978542\n",
      "Step 120700, training accuracy 0.94000005722\n",
      "Step 120800, training accuracy 0.999999940395\n",
      "Step 120900, training accuracy 0.910000026226\n",
      "Step 121000, training accuracy 0.930000007153\n",
      "Step 121100, training accuracy 0.979999959469\n",
      "Step 121200, training accuracy 0.97000002861\n",
      "Step 121300, training accuracy 0.959999978542\n",
      "Step 121400, training accuracy 0.969999969006\n",
      "Step 121500, training accuracy 0.949999988079\n",
      "Step 121600, training accuracy 0.939999997616\n",
      "Step 121700, training accuracy 0.979999959469\n",
      "Step 121800, training accuracy 0.960000038147\n",
      "Step 121900, training accuracy 0.969999969006\n",
      "Step 122000, training accuracy 0.930000066757\n",
      "Step 122100, training accuracy 0.930000066757\n",
      "Step 122200, training accuracy 0.949999928474\n",
      "Step 122300, training accuracy 0.939999997616\n",
      "Step 122400, training accuracy 0.969999969006\n",
      "Step 122500, training accuracy 0.969999969006\n",
      "Step 122600, training accuracy 0.969999969006\n",
      "Step 122700, training accuracy 0.939999997616\n",
      "Step 122800, training accuracy 0.969999969006\n",
      "Step 122900, training accuracy 0.930000007153\n",
      "Step 123000, training accuracy 0.950000047684\n",
      "Step 123100, training accuracy 0.990000009537\n",
      "Step 123200, training accuracy 0.959999978542\n",
      "Step 123300, training accuracy 0.949999988079\n",
      "Step 123400, training accuracy 0.989999949932\n",
      "Step 123500, training accuracy 0.999999940395\n",
      "Step 123600, training accuracy 0.94000005722\n",
      "Step 123700, training accuracy 0.960000038147\n",
      "Step 123800, training accuracy 0.949999988079\n",
      "Step 123900, training accuracy 0.959999978542\n",
      "Step 124000, training accuracy 0.97000002861\n",
      "Step 124100, training accuracy 0.920000016689\n",
      "Step 124200, training accuracy 0.97000002861\n",
      "Step 124300, training accuracy 0.960000038147\n",
      "Step 124400, training accuracy 0.959999978542\n",
      "Step 124500, training accuracy 0.990000009537\n",
      "Step 124600, training accuracy 0.950000047684\n",
      "Step 124700, training accuracy 0.950000047684\n",
      "Step 124800, training accuracy 0.959999978542\n",
      "Step 124900, training accuracy 0.97000002861\n",
      "Step 125000, training accuracy 0.939999938011\n",
      "Step 125100, training accuracy 0.939999997616\n",
      "Step 125200, training accuracy 0.960000038147\n",
      "Step 125300, training accuracy 0.969999969006\n",
      "Step 125400, training accuracy 0.929999947548\n",
      "Step 125500, training accuracy 0.939999997616\n",
      "Step 125600, training accuracy 0.960000038147\n",
      "Step 125700, training accuracy 0.960000038147\n",
      "Step 125800, training accuracy 0.969999969006\n",
      "Step 125900, training accuracy 0.949999988079\n",
      "Step 126000, training accuracy 0.97000002861\n",
      "Step 126100, training accuracy 0.989999949932\n",
      "Step 126200, training accuracy 0.959999978542\n",
      "Step 126300, training accuracy 0.960000038147\n",
      "Step 126400, training accuracy 0.969999969006\n",
      "Step 126500, training accuracy 0.929999947548\n",
      "Step 126600, training accuracy 0.97000002861\n",
      "Step 126700, training accuracy 0.879999995232\n",
      "Step 126800, training accuracy 0.969999969006\n",
      "Step 126900, training accuracy 0.979999959469\n",
      "Step 127000, training accuracy 0.980000019073\n",
      "Step 127100, training accuracy 0.969999969006\n",
      "Step 127200, training accuracy 0.960000038147\n",
      "Step 127300, training accuracy 0.94000005722\n",
      "Step 127400, training accuracy 0.959999978542\n",
      "Step 127500, training accuracy 0.969999969006\n",
      "Step 127600, training accuracy 0.939999997616\n",
      "Step 127700, training accuracy 0.979999959469\n",
      "Step 127800, training accuracy 0.980000019073\n",
      "Step 127900, training accuracy 0.950000047684\n",
      "Step 128000, training accuracy 0.97000002861\n",
      "Step 128100, training accuracy 0.939999997616\n",
      "Step 128200, training accuracy 0.959999978542\n",
      "Step 128300, training accuracy 0.950000047684\n",
      "Step 128400, training accuracy 0.950000047684\n",
      "Step 128500, training accuracy 0.969999969006\n",
      "Step 128600, training accuracy 0.990000009537\n",
      "Step 128700, training accuracy 0.97000002861\n",
      "Step 128800, training accuracy 0.989999949932\n",
      "Step 128900, training accuracy 0.97000002861\n",
      "Step 129000, training accuracy 0.989999949932\n",
      "Step 129100, training accuracy 0.960000038147\n",
      "Step 129200, training accuracy 0.950000047684\n",
      "Step 129300, training accuracy 0.97000002861\n",
      "Step 129400, training accuracy 0.939999997616\n",
      "Step 129500, training accuracy 0.979999959469\n",
      "Step 129600, training accuracy 0.999999940395\n",
      "Step 129700, training accuracy 0.959999978542\n",
      "Step 129800, training accuracy 0.959999978542\n",
      "Step 129900, training accuracy 0.980000019073\n",
      "Step 130000, training accuracy 0.969999969006\n",
      "Step 130100, training accuracy 0.949999988079\n",
      "Step 130200, training accuracy 0.97000002861\n",
      "Step 130300, training accuracy 0.930000007153\n",
      "Step 130400, training accuracy 0.97000002861\n",
      "Step 130500, training accuracy 0.94000005722\n",
      "Step 130600, training accuracy 0.959999978542\n",
      "Step 130700, training accuracy 0.989999949932\n",
      "Step 130800, training accuracy 0.980000019073\n",
      "Step 130900, training accuracy 0.949999988079\n",
      "Step 131000, training accuracy 0.930000007153\n",
      "Step 131100, training accuracy 0.960000038147\n",
      "Step 131200, training accuracy 0.960000038147\n",
      "Step 131300, training accuracy 0.980000019073\n",
      "Step 131400, training accuracy 0.960000038147\n",
      "Step 131500, training accuracy 0.969999969006\n",
      "Step 131600, training accuracy 0.97000002861\n",
      "Step 131700, training accuracy 0.990000009537\n",
      "Step 131800, training accuracy 0.989999949932\n",
      "Step 131900, training accuracy 0.889999985695\n",
      "Step 132000, training accuracy 0.950000047684\n",
      "Step 132100, training accuracy 0.989999949932\n",
      "Step 132200, training accuracy 0.94000005722\n",
      "Step 132300, training accuracy 0.989999949932\n",
      "Step 132400, training accuracy 0.980000019073\n",
      "Step 132500, training accuracy 0.920000016689\n",
      "Step 132600, training accuracy 0.959999978542\n",
      "Step 132700, training accuracy 0.949999988079\n",
      "Step 132800, training accuracy 0.960000038147\n",
      "Step 132900, training accuracy 0.969999969006\n",
      "Step 133000, training accuracy 0.97000002861\n",
      "Step 133100, training accuracy 0.949999988079\n",
      "Step 133200, training accuracy 0.979999959469\n",
      "Step 133300, training accuracy 0.960000038147\n",
      "Step 133400, training accuracy 0.939999997616\n",
      "Step 133500, training accuracy 0.949999928474\n",
      "Step 133600, training accuracy 0.939999997616\n",
      "Step 133700, training accuracy 0.959999978542\n",
      "Step 133800, training accuracy 0.969999969006\n",
      "Step 133900, training accuracy 0.980000019073\n",
      "Step 134000, training accuracy 0.920000016689\n",
      "Step 134100, training accuracy 0.959999978542\n",
      "Step 134200, training accuracy 0.959999978542\n",
      "Step 134300, training accuracy 0.969999969006\n",
      "Step 134400, training accuracy 0.990000009537\n",
      "Step 134500, training accuracy 0.990000009537\n",
      "Step 134600, training accuracy 0.94000005722\n",
      "Step 134700, training accuracy 0.910000026226\n",
      "Step 134800, training accuracy 0.920000016689\n",
      "Step 134900, training accuracy 0.960000038147\n",
      "Step 135000, training accuracy 0.969999969006\n",
      "Step 135100, training accuracy 0.97000002861\n",
      "Step 135200, training accuracy 0.97000002861\n",
      "Step 135300, training accuracy 0.97000002861\n",
      "Step 135400, training accuracy 0.949999988079\n",
      "Step 135500, training accuracy 0.959999978542\n",
      "Step 135600, training accuracy 0.989999949932\n",
      "Step 135700, training accuracy 0.979999959469\n",
      "Step 135800, training accuracy 0.969999969006\n",
      "Step 135900, training accuracy 0.969999969006\n",
      "Step 136000, training accuracy 0.989999949932\n",
      "Step 136100, training accuracy 0.979999959469\n",
      "Step 136200, training accuracy 0.959999978542\n",
      "Step 136300, training accuracy 0.97000002861\n",
      "Step 136400, training accuracy 0.980000019073\n",
      "Step 136500, training accuracy 0.959999978542\n",
      "Step 136600, training accuracy 0.979999959469\n",
      "Step 136700, training accuracy 1.0\n",
      "Step 136800, training accuracy 0.960000038147\n",
      "Step 136900, training accuracy 0.980000019073\n",
      "Step 137000, training accuracy 0.939999997616\n",
      "Step 137100, training accuracy 0.989999949932\n",
      "Step 137200, training accuracy 0.989999949932\n",
      "Step 137300, training accuracy 0.979999959469\n",
      "Step 137400, training accuracy 0.94000005722\n",
      "Step 137500, training accuracy 0.999999940395\n",
      "Step 137600, training accuracy 0.980000019073\n",
      "Step 137700, training accuracy 0.959999978542\n",
      "Step 137800, training accuracy 0.94000005722\n",
      "Step 137900, training accuracy 0.979999959469\n",
      "Step 138000, training accuracy 0.959999978542\n",
      "Step 138100, training accuracy 0.930000007153\n",
      "Step 138200, training accuracy 0.999999940395\n",
      "Step 138300, training accuracy 0.969999969006\n",
      "Step 138400, training accuracy 0.959999978542\n",
      "Step 138500, training accuracy 0.979999959469\n",
      "Step 138600, training accuracy 0.990000009537\n",
      "Step 138700, training accuracy 0.960000038147\n",
      "Step 138800, training accuracy 0.979999959469\n",
      "Step 138900, training accuracy 0.969999969006\n",
      "Step 139000, training accuracy 0.979999959469\n",
      "Step 139100, training accuracy 0.990000009537\n",
      "Step 139200, training accuracy 0.97000002861\n",
      "Step 139300, training accuracy 0.990000009537\n",
      "Step 139400, training accuracy 0.959999978542\n",
      "Step 139500, training accuracy 0.979999959469\n",
      "Step 139600, training accuracy 0.97000002861\n",
      "Step 139700, training accuracy 0.979999959469\n",
      "Step 139800, training accuracy 0.94000005722\n",
      "Step 139900, training accuracy 0.959999978542\n",
      "Step 140000, training accuracy 0.960000038147\n",
      "Step 140100, training accuracy 0.979999959469\n",
      "Step 140200, training accuracy 0.979999959469\n",
      "Step 140300, training accuracy 0.989999949932\n",
      "Step 140400, training accuracy 0.980000019073\n",
      "Step 140500, training accuracy 1.0\n",
      "Step 140600, training accuracy 0.959999978542\n",
      "Step 140700, training accuracy 1.0\n",
      "Step 140800, training accuracy 0.989999949932\n",
      "Step 140900, training accuracy 0.959999978542\n",
      "Step 141000, training accuracy 0.979999959469\n",
      "Step 141100, training accuracy 0.979999959469\n",
      "Step 141200, training accuracy 0.979999959469\n",
      "Step 141300, training accuracy 0.980000019073\n",
      "Step 141400, training accuracy 0.969999969006\n",
      "Step 141500, training accuracy 0.969999969006\n",
      "Step 141600, training accuracy 0.959999978542\n",
      "Step 141700, training accuracy 0.969999969006\n",
      "Step 141800, training accuracy 0.97000002861\n",
      "Step 141900, training accuracy 0.94000005722\n",
      "Step 142000, training accuracy 0.989999949932\n",
      "Step 142100, training accuracy 0.990000009537\n",
      "Step 142200, training accuracy 0.960000038147\n",
      "Step 142300, training accuracy 0.939999997616\n",
      "Step 142400, training accuracy 0.969999969006\n",
      "Step 142500, training accuracy 0.989999949932\n",
      "Step 142600, training accuracy 0.979999959469\n",
      "Step 142700, training accuracy 0.979999959469\n",
      "Step 142800, training accuracy 0.979999959469\n",
      "Step 142900, training accuracy 0.989999949932\n",
      "Step 143000, training accuracy 0.989999949932\n",
      "Step 143100, training accuracy 0.989999949932\n",
      "Step 143200, training accuracy 0.969999969006\n",
      "Step 143300, training accuracy 0.949999928474\n",
      "Step 143400, training accuracy 0.979999959469\n",
      "Step 143500, training accuracy 0.949999988079\n",
      "Step 143600, training accuracy 0.980000019073\n",
      "Step 143700, training accuracy 0.979999959469\n",
      "Step 143800, training accuracy 0.990000009537\n",
      "Step 143900, training accuracy 0.94000005722\n",
      "Step 144000, training accuracy 0.979999959469\n",
      "Step 144100, training accuracy 0.980000019073\n",
      "Step 144200, training accuracy 0.979999959469\n",
      "Step 144300, training accuracy 0.980000019073\n",
      "Step 144400, training accuracy 0.990000009537\n",
      "Step 144500, training accuracy 0.969999969006\n",
      "Step 144600, training accuracy 0.980000019073\n",
      "Step 144700, training accuracy 0.97000002861\n",
      "Step 144800, training accuracy 0.990000009537\n",
      "Step 144900, training accuracy 0.959999978542\n",
      "Step 145000, training accuracy 0.960000038147\n",
      "Step 145100, training accuracy 0.949999988079\n",
      "Step 145200, training accuracy 0.959999978542\n",
      "Step 145300, training accuracy 0.989999949932\n",
      "Step 145400, training accuracy 0.979999959469\n",
      "Step 145500, training accuracy 0.979999959469\n",
      "Step 145600, training accuracy 0.950000047684\n",
      "Step 145700, training accuracy 0.969999969006\n",
      "Step 145800, training accuracy 0.999999940395\n",
      "Step 145900, training accuracy 0.97000002861\n",
      "Step 146000, training accuracy 0.989999949932\n",
      "Step 146100, training accuracy 0.97000002861\n",
      "Step 146200, training accuracy 0.969999969006\n",
      "Step 146300, training accuracy 0.999999940395\n",
      "Step 146400, training accuracy 0.990000009537\n",
      "Step 146500, training accuracy 1.0\n",
      "Step 146600, training accuracy 0.97000002861\n",
      "Step 146700, training accuracy 0.999999940395\n",
      "Step 146800, training accuracy 1.0\n",
      "Step 146900, training accuracy 0.990000009537\n",
      "Step 147000, training accuracy 0.969999969006\n",
      "Step 147100, training accuracy 0.990000009537\n",
      "Step 147200, training accuracy 0.980000019073\n",
      "Step 147300, training accuracy 0.949999988079\n",
      "Step 147400, training accuracy 0.979999959469\n",
      "Step 147500, training accuracy 0.980000019073\n",
      "Step 147600, training accuracy 0.97000002861\n",
      "Step 147700, training accuracy 0.979999959469\n",
      "Step 147800, training accuracy 0.97000002861\n",
      "Step 147900, training accuracy 0.969999969006\n",
      "Step 148000, training accuracy 0.969999969006\n",
      "Step 148100, training accuracy 0.989999949932\n",
      "Step 148200, training accuracy 0.990000009537\n",
      "Step 148300, training accuracy 0.990000009537\n",
      "Step 148400, training accuracy 0.990000009537\n",
      "Step 148500, training accuracy 0.989999949932\n",
      "Step 148600, training accuracy 0.989999949932\n",
      "Step 148700, training accuracy 1.0\n",
      "Step 148800, training accuracy 0.980000019073\n",
      "Step 148900, training accuracy 0.989999949932\n",
      "Step 149000, training accuracy 0.990000009537\n",
      "Step 149100, training accuracy 1.0\n",
      "Step 149200, training accuracy 0.979999959469\n",
      "Step 149300, training accuracy 0.949999988079\n",
      "Step 149400, training accuracy 0.969999969006\n",
      "Step 149500, training accuracy 0.969999969006\n",
      "Step 149600, training accuracy 0.999999940395\n",
      "Step 149700, training accuracy 1.0\n",
      "Step 149800, training accuracy 0.969999969006\n",
      "Step 149900, training accuracy 0.980000019073\n",
      "Step 150000, training accuracy 0.989999949932\n",
      "Step 150100, training accuracy 0.980000019073\n",
      "Step 150200, training accuracy 0.999999940395\n",
      "Step 150300, training accuracy 0.990000009537\n",
      "Step 150400, training accuracy 0.960000038147\n",
      "Step 150500, training accuracy 0.97000002861\n",
      "Step 150600, training accuracy 0.999999940395\n",
      "Step 150700, training accuracy 0.990000009537\n",
      "Step 150800, training accuracy 0.97000002861\n",
      "Step 150900, training accuracy 0.969999969006\n",
      "Step 151000, training accuracy 0.990000009537\n",
      "Step 151100, training accuracy 0.959999978542\n",
      "Step 151200, training accuracy 0.990000009537\n",
      "Step 151300, training accuracy 0.980000019073\n",
      "Step 151400, training accuracy 0.969999969006\n",
      "Step 151500, training accuracy 0.959999978542\n",
      "Step 151600, training accuracy 0.990000009537\n",
      "Step 151700, training accuracy 0.989999949932\n",
      "Step 151800, training accuracy 0.989999949932\n",
      "Step 151900, training accuracy 0.999999940395\n",
      "Step 152000, training accuracy 0.979999959469\n",
      "Step 152100, training accuracy 0.990000009537\n",
      "Step 152200, training accuracy 0.979999959469\n",
      "Step 152300, training accuracy 0.989999949932\n",
      "Step 152400, training accuracy 0.959999978542\n",
      "Step 152500, training accuracy 0.999999940395\n",
      "Step 152600, training accuracy 0.990000009537\n",
      "Step 152700, training accuracy 0.97000002861\n",
      "Step 152800, training accuracy 0.980000019073\n",
      "Step 152900, training accuracy 0.979999959469\n",
      "Step 153000, training accuracy 0.980000019073\n",
      "Step 153100, training accuracy 0.990000009537\n",
      "Step 153200, training accuracy 0.979999959469\n",
      "Step 153300, training accuracy 0.989999949932\n",
      "Step 153400, training accuracy 0.969999969006\n",
      "Step 153500, training accuracy 0.979999959469\n",
      "Step 153600, training accuracy 0.980000019073\n",
      "Step 153700, training accuracy 0.949999988079\n",
      "Step 153800, training accuracy 0.999999940395\n",
      "Step 153900, training accuracy 0.939999997616\n",
      "Step 154000, training accuracy 0.979999959469\n",
      "Step 154100, training accuracy 0.990000009537\n",
      "Step 154200, training accuracy 0.989999949932\n",
      "Step 154300, training accuracy 0.990000009537\n",
      "Step 154400, training accuracy 0.990000009537\n",
      "Step 154500, training accuracy 0.990000009537\n",
      "Step 154600, training accuracy 0.989999949932\n",
      "Step 154700, training accuracy 0.979999959469\n",
      "Step 154800, training accuracy 0.980000019073\n",
      "Step 154900, training accuracy 0.979999959469\n",
      "Step 155000, training accuracy 0.979999959469\n",
      "Step 155100, training accuracy 0.990000009537\n",
      "Step 155200, training accuracy 0.990000009537\n",
      "Step 155300, training accuracy 1.0\n",
      "Step 155400, training accuracy 0.990000009537\n",
      "Step 155500, training accuracy 0.989999949932\n",
      "Step 155600, training accuracy 0.980000019073\n",
      "Step 155700, training accuracy 0.979999959469\n",
      "Step 155800, training accuracy 0.97000002861\n",
      "Step 155900, training accuracy 0.979999959469\n",
      "Step 156000, training accuracy 0.97000002861\n",
      "Step 156100, training accuracy 0.969999969006\n",
      "Step 156200, training accuracy 0.999999940395\n",
      "Step 156300, training accuracy 0.960000038147\n",
      "Step 156400, training accuracy 0.980000019073\n",
      "Step 156500, training accuracy 0.969999969006\n",
      "Step 156600, training accuracy 0.999999940395\n",
      "Step 156700, training accuracy 0.980000019073\n",
      "Step 156800, training accuracy 0.950000047684\n",
      "Step 156900, training accuracy 0.960000038147\n",
      "Step 157000, training accuracy 0.979999959469\n",
      "Step 157100, training accuracy 0.980000019073\n",
      "Step 157200, training accuracy 0.989999949932\n",
      "Step 157300, training accuracy 0.979999959469\n",
      "Step 157400, training accuracy 0.980000019073\n",
      "Step 157500, training accuracy 0.990000009537\n",
      "Step 157600, training accuracy 0.969999969006\n",
      "Step 157700, training accuracy 0.969999969006\n",
      "Step 157800, training accuracy 0.980000019073\n",
      "Step 157900, training accuracy 0.999999940395\n",
      "Step 158000, training accuracy 1.0\n",
      "Step 158100, training accuracy 0.999999940395\n",
      "Step 158200, training accuracy 0.97000002861\n",
      "Step 158300, training accuracy 0.989999949932\n",
      "Step 158400, training accuracy 1.0\n",
      "Step 158500, training accuracy 0.979999959469\n",
      "Step 158600, training accuracy 0.989999949932\n",
      "Step 158700, training accuracy 0.990000009537\n",
      "Step 158800, training accuracy 0.979999959469\n",
      "Step 158900, training accuracy 0.979999959469\n",
      "Step 159000, training accuracy 0.980000019073\n",
      "Step 159100, training accuracy 0.989999949932\n",
      "Step 159200, training accuracy 0.960000038147\n",
      "Step 159300, training accuracy 0.969999969006\n",
      "Step 159400, training accuracy 0.990000009537\n",
      "Step 159500, training accuracy 0.980000019073\n",
      "Step 159600, training accuracy 0.999999940395\n",
      "Step 159700, training accuracy 0.97000002861\n",
      "Step 159800, training accuracy 0.990000009537\n",
      "Step 159900, training accuracy 0.959999978542\n",
      "Step 160000, training accuracy 0.979999959469\n",
      "Step 160100, training accuracy 0.999999940395\n",
      "Step 160200, training accuracy 0.969999969006\n",
      "Step 160300, training accuracy 0.989999949932\n",
      "Step 160400, training accuracy 0.990000009537\n",
      "Step 160500, training accuracy 0.969999969006\n",
      "Step 160600, training accuracy 0.969999969006\n",
      "Step 160700, training accuracy 0.979999959469\n",
      "Step 160800, training accuracy 0.999999940395\n",
      "Step 160900, training accuracy 0.980000019073\n",
      "Step 161000, training accuracy 0.990000009537\n",
      "Step 161100, training accuracy 0.980000019073\n",
      "Step 161200, training accuracy 0.999999940395\n",
      "Step 161300, training accuracy 0.97000002861\n",
      "Step 161400, training accuracy 0.999999940395\n",
      "Step 161500, training accuracy 0.990000009537\n",
      "Step 161600, training accuracy 0.989999949932\n",
      "Step 161700, training accuracy 0.989999949932\n",
      "Step 161800, training accuracy 0.969999969006\n",
      "Step 161900, training accuracy 0.990000009537\n",
      "Step 162000, training accuracy 0.990000009537\n",
      "Step 162100, training accuracy 0.990000009537\n",
      "Step 162200, training accuracy 0.969999969006\n",
      "Step 162300, training accuracy 0.979999959469\n",
      "Step 162400, training accuracy 0.989999949932\n",
      "Step 162500, training accuracy 0.989999949932\n",
      "Step 162600, training accuracy 0.990000009537\n",
      "Step 162700, training accuracy 0.980000019073\n",
      "Step 162800, training accuracy 0.990000009537\n",
      "Step 162900, training accuracy 1.0\n",
      "Step 163000, training accuracy 0.980000019073\n",
      "Step 163100, training accuracy 0.989999949932\n",
      "Step 163200, training accuracy 0.969999969006\n",
      "Step 163300, training accuracy 0.990000009537\n",
      "Step 163400, training accuracy 0.999999940395\n",
      "Step 163500, training accuracy 0.97000002861\n",
      "Step 163600, training accuracy 0.990000009537\n",
      "Step 163700, training accuracy 0.950000047684\n",
      "Step 163800, training accuracy 0.999999940395\n",
      "Step 163900, training accuracy 1.0\n",
      "Step 164000, training accuracy 0.990000009537\n",
      "Step 164100, training accuracy 0.979999959469\n",
      "Step 164200, training accuracy 0.990000009537\n",
      "Step 164300, training accuracy 0.950000047684\n",
      "Step 164400, training accuracy 0.97000002861\n",
      "Step 164500, training accuracy 0.989999949932\n",
      "Step 164600, training accuracy 0.989999949932\n",
      "Step 164700, training accuracy 1.0\n",
      "Step 164800, training accuracy 0.989999949932\n",
      "Step 164900, training accuracy 1.0\n",
      "Step 165000, training accuracy 0.990000009537\n",
      "Step 165100, training accuracy 0.999999940395\n",
      "Step 165200, training accuracy 0.969999969006\n",
      "Step 165300, training accuracy 0.980000019073\n",
      "Step 165400, training accuracy 0.990000009537\n",
      "Step 165500, training accuracy 0.960000038147\n",
      "Step 165600, training accuracy 0.959999978542\n",
      "Step 165700, training accuracy 0.980000019073\n",
      "Step 165800, training accuracy 0.990000009537\n",
      "Step 165900, training accuracy 0.97000002861\n",
      "Step 166000, training accuracy 0.980000019073\n",
      "Step 166100, training accuracy 0.989999949932\n",
      "Step 166200, training accuracy 1.0\n",
      "Step 166300, training accuracy 0.97000002861\n",
      "Step 166400, training accuracy 0.990000009537\n",
      "Step 166500, training accuracy 0.979999959469\n",
      "Step 166600, training accuracy 0.989999949932\n",
      "Step 166700, training accuracy 0.990000009537\n",
      "Step 166800, training accuracy 0.990000009537\n",
      "Step 166900, training accuracy 0.969999969006\n",
      "Step 167000, training accuracy 0.990000009537\n",
      "Step 167100, training accuracy 0.969999969006\n",
      "Step 167200, training accuracy 0.979999959469\n",
      "Step 167300, training accuracy 0.980000019073\n",
      "Step 167400, training accuracy 0.990000009537\n",
      "Step 167500, training accuracy 0.979999959469\n",
      "Step 167600, training accuracy 0.990000009537\n",
      "Step 167700, training accuracy 0.989999949932\n",
      "Step 167800, training accuracy 0.980000019073\n",
      "Step 167900, training accuracy 0.97000002861\n",
      "Step 168000, training accuracy 0.979999959469\n",
      "Step 168100, training accuracy 0.980000019073\n",
      "Step 168200, training accuracy 1.0\n",
      "Step 168300, training accuracy 0.97000002861\n",
      "Step 168400, training accuracy 0.990000009537\n",
      "Step 168500, training accuracy 0.980000019073\n",
      "Step 168600, training accuracy 1.0\n",
      "Step 168700, training accuracy 0.979999959469\n",
      "Step 168800, training accuracy 0.989999949932\n",
      "Step 168900, training accuracy 0.980000019073\n",
      "Step 169000, training accuracy 0.989999949932\n",
      "Step 169100, training accuracy 1.0\n",
      "Step 169200, training accuracy 0.989999949932\n",
      "Step 169300, training accuracy 0.999999940395\n",
      "Step 169400, training accuracy 0.990000009537\n",
      "Step 169500, training accuracy 0.989999949932\n",
      "Step 169600, training accuracy 0.97000002861\n",
      "Step 169700, training accuracy 0.990000009537\n",
      "Step 169800, training accuracy 0.969999969006\n",
      "Step 169900, training accuracy 0.990000009537\n",
      "Step 170000, training accuracy 1.0\n",
      "Step 170100, training accuracy 0.979999959469\n",
      "Step 170200, training accuracy 0.990000009537\n",
      "Step 170300, training accuracy 1.0\n",
      "Step 170400, training accuracy 0.969999969006\n",
      "Step 170500, training accuracy 0.980000019073\n",
      "Step 170600, training accuracy 0.999999940395\n",
      "Step 170700, training accuracy 1.0\n",
      "Step 170800, training accuracy 0.989999949932\n",
      "Step 170900, training accuracy 0.980000019073\n",
      "Step 171000, training accuracy 0.969999969006\n",
      "Step 171100, training accuracy 0.990000009537\n",
      "Step 171200, training accuracy 0.979999959469\n",
      "Step 171300, training accuracy 0.980000019073\n",
      "Step 171400, training accuracy 0.990000009537\n",
      "Step 171500, training accuracy 0.979999959469\n",
      "Step 171600, training accuracy 0.959999978542\n",
      "Step 171700, training accuracy 0.990000009537\n",
      "Step 171800, training accuracy 0.97000002861\n",
      "Step 171900, training accuracy 0.999999940395\n",
      "Step 172000, training accuracy 0.980000019073\n",
      "Step 172100, training accuracy 0.999999940395\n",
      "Step 172200, training accuracy 0.980000019073\n",
      "Step 172300, training accuracy 0.990000009537\n",
      "Step 172400, training accuracy 0.999999940395\n",
      "Step 172500, training accuracy 0.989999949932\n",
      "Step 172600, training accuracy 0.990000009537\n",
      "Step 172700, training accuracy 0.959999918938\n",
      "Step 172800, training accuracy 0.989999949932\n",
      "Step 172900, training accuracy 0.990000009537\n",
      "Step 173000, training accuracy 0.999999940395\n",
      "Step 173100, training accuracy 0.980000019073\n",
      "Step 173200, training accuracy 0.989999949932\n",
      "Step 173300, training accuracy 0.990000009537\n",
      "Step 173400, training accuracy 0.989999949932\n",
      "Step 173500, training accuracy 1.0\n",
      "Step 173600, training accuracy 0.979999959469\n",
      "Step 173700, training accuracy 0.990000009537\n",
      "Step 173800, training accuracy 0.969999969006\n",
      "Step 173900, training accuracy 1.0\n",
      "Step 174000, training accuracy 0.999999940395\n",
      "Step 174100, training accuracy 0.980000019073\n",
      "Step 174200, training accuracy 0.999999940395\n",
      "Step 174300, training accuracy 0.999999940395\n",
      "Step 174400, training accuracy 1.0\n",
      "Step 174500, training accuracy 0.989999949932\n",
      "Step 174600, training accuracy 0.990000009537\n",
      "Step 174700, training accuracy 0.999999940395\n",
      "Step 174800, training accuracy 1.0\n",
      "Step 174900, training accuracy 1.0\n",
      "Step 175000, training accuracy 0.980000019073\n",
      "Step 175100, training accuracy 0.989999949932\n",
      "Step 175200, training accuracy 0.979999959469\n",
      "Step 175300, training accuracy 0.959999978542\n",
      "Step 175400, training accuracy 0.990000009537\n",
      "Step 175500, training accuracy 0.999999940395\n",
      "Step 175600, training accuracy 0.989999949932\n",
      "Step 175700, training accuracy 0.989999949932\n",
      "Step 175800, training accuracy 1.0\n",
      "Step 175900, training accuracy 0.990000009537\n",
      "Step 176000, training accuracy 0.979999959469\n",
      "Step 176100, training accuracy 0.999999940395\n",
      "Step 176200, training accuracy 0.969999969006\n",
      "Step 176300, training accuracy 0.979999959469\n",
      "Step 176400, training accuracy 0.989999949932\n",
      "Step 176500, training accuracy 1.0\n",
      "Step 176600, training accuracy 0.989999949932\n",
      "Step 176700, training accuracy 0.999999940395\n",
      "Step 176800, training accuracy 0.990000009537\n",
      "Step 176900, training accuracy 0.979999959469\n",
      "Step 177000, training accuracy 0.980000019073\n",
      "Step 177100, training accuracy 0.97000002861\n",
      "Step 177200, training accuracy 0.980000019073\n",
      "Step 177300, training accuracy 0.989999949932\n",
      "Step 177400, training accuracy 0.969999969006\n",
      "Step 177500, training accuracy 0.999999940395\n",
      "Step 177600, training accuracy 0.97000002861\n",
      "Step 177700, training accuracy 0.990000009537\n",
      "Step 177800, training accuracy 0.979999959469\n",
      "Step 177900, training accuracy 0.97000002861\n",
      "Step 178000, training accuracy 0.990000009537\n",
      "Step 178100, training accuracy 0.980000019073\n",
      "Step 178200, training accuracy 0.999999940395\n",
      "Step 178300, training accuracy 0.990000009537\n",
      "Step 178400, training accuracy 0.989999949932\n",
      "Step 178500, training accuracy 1.0\n",
      "Step 178600, training accuracy 0.980000019073\n",
      "Step 178700, training accuracy 0.979999959469\n",
      "Step 178800, training accuracy 0.989999949932\n",
      "Step 178900, training accuracy 0.969999969006\n",
      "Step 179000, training accuracy 0.979999959469\n",
      "Step 179100, training accuracy 0.980000019073\n",
      "Step 179200, training accuracy 0.989999949932\n",
      "Step 179300, training accuracy 0.999999940395\n",
      "Step 179400, training accuracy 0.990000009537\n",
      "Step 179500, training accuracy 0.989999949932\n",
      "Step 179600, training accuracy 0.999999940395\n",
      "Step 179700, training accuracy 0.979999959469\n",
      "Step 179800, training accuracy 0.979999959469\n",
      "Step 179900, training accuracy 0.980000019073\n",
      "Step 180000, training accuracy 0.979999959469\n",
      "Step 180100, training accuracy 0.990000009537\n",
      "Step 180200, training accuracy 0.97000002861\n",
      "Step 180300, training accuracy 0.999999940395\n",
      "Step 180400, training accuracy 0.990000009537\n",
      "Step 180500, training accuracy 0.959999978542\n",
      "Step 180600, training accuracy 0.999999940395\n",
      "Step 180700, training accuracy 1.0\n",
      "Step 180800, training accuracy 0.969999969006\n",
      "Step 180900, training accuracy 1.0\n",
      "Step 181000, training accuracy 1.0\n",
      "Step 181100, training accuracy 0.97000002861\n",
      "Step 181200, training accuracy 1.0\n",
      "Step 181300, training accuracy 0.979999959469\n",
      "Step 181400, training accuracy 0.999999940395\n",
      "Step 181500, training accuracy 0.97000002861\n",
      "Step 181600, training accuracy 0.989999949932\n",
      "Step 181700, training accuracy 1.0\n",
      "Step 181800, training accuracy 0.980000019073\n",
      "Step 181900, training accuracy 1.0\n",
      "Step 182000, training accuracy 0.980000019073\n",
      "Step 182100, training accuracy 0.990000009537\n",
      "Step 182200, training accuracy 1.0\n",
      "Step 182300, training accuracy 0.990000009537\n",
      "Step 182400, training accuracy 0.97000002861\n",
      "Step 182500, training accuracy 0.990000009537\n",
      "Step 182600, training accuracy 0.989999949932\n",
      "Step 182700, training accuracy 0.939999997616\n",
      "Step 182800, training accuracy 1.0\n",
      "Step 182900, training accuracy 0.999999940395\n",
      "Step 183000, training accuracy 1.0\n",
      "Step 183100, training accuracy 0.979999959469\n",
      "Step 183200, training accuracy 1.0\n",
      "Step 183300, training accuracy 0.999999940395\n",
      "Step 183400, training accuracy 0.989999949932\n",
      "Step 183500, training accuracy 1.0\n",
      "Step 183600, training accuracy 0.969999969006\n",
      "Step 183700, training accuracy 1.0\n",
      "Step 183800, training accuracy 0.989999949932\n",
      "Step 183900, training accuracy 1.0\n",
      "Step 184000, training accuracy 0.990000009537\n",
      "Step 184100, training accuracy 0.979999959469\n",
      "Step 184200, training accuracy 0.989999949932\n",
      "Step 184300, training accuracy 0.990000009537\n",
      "Step 184400, training accuracy 0.980000019073\n",
      "Step 184500, training accuracy 0.980000019073\n",
      "Step 184600, training accuracy 0.989999949932\n",
      "Step 184700, training accuracy 0.989999949932\n",
      "Step 184800, training accuracy 0.990000009537\n",
      "Step 184900, training accuracy 0.999999940395\n",
      "Step 185000, training accuracy 0.960000038147\n",
      "Step 185100, training accuracy 0.999999940395\n",
      "Step 185200, training accuracy 0.990000009537\n",
      "Step 185300, training accuracy 0.989999949932\n",
      "Step 185400, training accuracy 0.989999949932\n",
      "Step 185500, training accuracy 0.999999940395\n",
      "Step 185600, training accuracy 1.0\n",
      "Step 185700, training accuracy 0.990000009537\n",
      "Step 185800, training accuracy 0.969999969006\n",
      "Step 185900, training accuracy 0.979999959469\n",
      "Step 186000, training accuracy 0.990000009537\n",
      "Step 186100, training accuracy 1.0\n",
      "Step 186200, training accuracy 0.990000009537\n",
      "Step 186300, training accuracy 0.999999940395\n",
      "Step 186400, training accuracy 0.969999969006\n",
      "Step 186500, training accuracy 0.980000019073\n",
      "Step 186600, training accuracy 1.0\n",
      "Step 186700, training accuracy 0.97000002861\n",
      "Step 186800, training accuracy 0.990000009537\n",
      "Step 186900, training accuracy 0.999999940395\n",
      "Step 187000, training accuracy 0.999999940395\n",
      "Step 187100, training accuracy 1.0\n",
      "Step 187200, training accuracy 1.0\n",
      "Step 187300, training accuracy 0.979999959469\n",
      "Step 187400, training accuracy 0.979999959469\n",
      "Step 187500, training accuracy 0.979999959469\n",
      "Step 187600, training accuracy 0.980000019073\n",
      "Step 187700, training accuracy 1.0\n",
      "Step 187800, training accuracy 1.0\n",
      "Step 187900, training accuracy 1.0\n",
      "Step 188000, training accuracy 0.999999940395\n",
      "Step 188100, training accuracy 1.0\n",
      "Step 188200, training accuracy 0.999999940395\n",
      "Step 188300, training accuracy 0.989999949932\n",
      "Step 188400, training accuracy 0.979999959469\n",
      "Step 188500, training accuracy 0.969999969006\n",
      "Step 188600, training accuracy 1.0\n",
      "Step 188700, training accuracy 0.999999940395\n",
      "Step 188800, training accuracy 0.999999940395\n",
      "Step 188900, training accuracy 0.999999940395\n",
      "Step 189000, training accuracy 0.999999940395\n",
      "Step 189100, training accuracy 0.969999969006\n",
      "Step 189200, training accuracy 0.990000009537\n",
      "Step 189300, training accuracy 0.979999959469\n",
      "Step 189400, training accuracy 0.999999940395\n",
      "Step 189500, training accuracy 0.989999949932\n",
      "Step 189600, training accuracy 1.0\n",
      "Step 189700, training accuracy 0.980000019073\n",
      "Step 189800, training accuracy 0.979999959469\n",
      "Step 189900, training accuracy 0.990000009537\n",
      "Step 190000, training accuracy 1.0\n",
      "Step 190100, training accuracy 0.969999969006\n",
      "Step 190200, training accuracy 0.980000019073\n",
      "Step 190300, training accuracy 0.990000009537\n",
      "Step 190400, training accuracy 0.990000009537\n",
      "Step 190500, training accuracy 0.989999949932\n",
      "Step 190600, training accuracy 0.990000009537\n",
      "Step 190700, training accuracy 0.990000009537\n",
      "Step 190800, training accuracy 1.0\n",
      "Step 190900, training accuracy 0.989999949932\n",
      "Step 191000, training accuracy 0.980000019073\n",
      "Step 191100, training accuracy 0.979999959469\n",
      "Step 191200, training accuracy 0.969999969006\n",
      "Step 191300, training accuracy 0.999999940395\n",
      "Step 191400, training accuracy 0.990000009537\n",
      "Step 191500, training accuracy 1.0\n",
      "Step 191600, training accuracy 1.0\n",
      "Step 191700, training accuracy 1.0\n",
      "Step 191800, training accuracy 1.0\n",
      "Step 191900, training accuracy 0.989999949932\n",
      "Step 192000, training accuracy 1.0\n",
      "Step 192100, training accuracy 0.999999940395\n",
      "Step 192200, training accuracy 0.999999940395\n",
      "Step 192300, training accuracy 0.989999949932\n",
      "Step 192400, training accuracy 0.989999949932\n",
      "Step 192500, training accuracy 1.0\n",
      "Step 192600, training accuracy 1.0\n",
      "Step 192700, training accuracy 0.989999949932\n",
      "Step 192800, training accuracy 0.980000019073\n",
      "Step 192900, training accuracy 0.979999959469\n",
      "Step 193000, training accuracy 0.980000019073\n",
      "Step 193100, training accuracy 0.999999940395\n",
      "Step 193200, training accuracy 0.999999940395\n",
      "Step 193300, training accuracy 0.990000009537\n",
      "Step 193400, training accuracy 0.989999949932\n",
      "Step 193500, training accuracy 0.999999940395\n",
      "Step 193600, training accuracy 0.989999949932\n",
      "Step 193700, training accuracy 0.999999940395\n",
      "Step 193800, training accuracy 0.989999949932\n",
      "Step 193900, training accuracy 1.0\n",
      "Step 194000, training accuracy 1.0\n",
      "Step 194100, training accuracy 1.0\n",
      "Step 194200, training accuracy 0.97000002861\n",
      "Step 194300, training accuracy 0.999999940395\n",
      "Step 194400, training accuracy 0.990000009537\n",
      "Step 194500, training accuracy 0.980000019073\n",
      "Step 194600, training accuracy 0.989999949932\n",
      "Step 194700, training accuracy 0.999999940395\n",
      "Step 194800, training accuracy 0.989999949932\n",
      "Step 194900, training accuracy 0.950000047684\n",
      "Step 195000, training accuracy 0.999999940395\n",
      "Step 195100, training accuracy 0.97000002861\n",
      "Step 195200, training accuracy 0.989999949932\n",
      "Step 195300, training accuracy 0.969999969006\n",
      "Step 195400, training accuracy 0.980000019073\n",
      "Step 195500, training accuracy 0.989999949932\n",
      "Step 195600, training accuracy 0.999999940395\n",
      "Step 195700, training accuracy 1.0\n",
      "Step 195800, training accuracy 0.989999949932\n",
      "Step 195900, training accuracy 1.0\n",
      "Step 196000, training accuracy 0.999999940395\n",
      "Step 196100, training accuracy 0.990000009537\n",
      "Step 196200, training accuracy 0.989999949932\n",
      "Step 196300, training accuracy 1.0\n",
      "Step 196400, training accuracy 0.989999949932\n",
      "Step 196500, training accuracy 0.989999949932\n",
      "Step 196600, training accuracy 0.990000009537\n",
      "Step 196700, training accuracy 0.989999949932\n",
      "Step 196800, training accuracy 0.999999940395\n",
      "Step 196900, training accuracy 0.979999959469\n",
      "Step 197000, training accuracy 0.989999949932\n",
      "Step 197100, training accuracy 1.0\n",
      "Step 197200, training accuracy 1.0\n",
      "Step 197300, training accuracy 1.0\n",
      "Step 197400, training accuracy 0.979999959469\n",
      "Step 197500, training accuracy 0.989999949932\n",
      "Step 197600, training accuracy 0.990000009537\n",
      "Step 197700, training accuracy 0.999999940395\n",
      "Step 197800, training accuracy 0.989999949932\n",
      "Step 197900, training accuracy 0.97000002861\n",
      "Step 198000, training accuracy 0.989999949932\n",
      "Step 198100, training accuracy 1.0\n",
      "Step 198200, training accuracy 0.990000009537\n",
      "Step 198300, training accuracy 0.999999940395\n",
      "Step 198400, training accuracy 0.989999949932\n",
      "Step 198500, training accuracy 0.989999949932\n",
      "Step 198600, training accuracy 0.990000009537\n",
      "Step 198700, training accuracy 1.0\n",
      "Step 198800, training accuracy 1.0\n",
      "Step 198900, training accuracy 0.979999959469\n",
      "Step 199000, training accuracy 0.990000009537\n",
      "Step 199100, training accuracy 0.999999940395\n",
      "Step 199200, training accuracy 0.990000009537\n",
      "Step 199300, training accuracy 0.980000019073\n",
      "Step 199400, training accuracy 0.999999940395\n",
      "Step 199500, training accuracy 0.980000019073\n",
      "Step 199600, training accuracy 0.989999949932\n",
      "Step 199700, training accuracy 0.999999940395\n",
      "Step 199800, training accuracy 1.0\n",
      "Step 199900, training accuracy 1.0\n",
      "Step 200000, training accuracy 0.989999949932\n",
      "Step 200100, training accuracy 0.989999949932\n",
      "Step 200200, training accuracy 0.999999940395\n",
      "Step 200300, training accuracy 0.979999959469\n",
      "Step 200400, training accuracy 0.999999940395\n",
      "Step 200500, training accuracy 0.989999949932\n",
      "Step 200600, training accuracy 0.999999940395\n",
      "Step 200700, training accuracy 1.0\n",
      "Step 200800, training accuracy 1.0\n",
      "Step 200900, training accuracy 0.990000009537\n",
      "Step 201000, training accuracy 0.989999949932\n",
      "Step 201100, training accuracy 0.990000009537\n",
      "Step 201200, training accuracy 1.0\n",
      "Step 201300, training accuracy 0.989999949932\n",
      "Step 201400, training accuracy 0.990000009537\n",
      "Step 201500, training accuracy 0.999999940395\n",
      "Step 201600, training accuracy 0.979999959469\n",
      "Step 201700, training accuracy 0.999999940395\n",
      "Step 201800, training accuracy 0.989999949932\n",
      "Step 201900, training accuracy 0.980000019073\n",
      "Step 202000, training accuracy 0.990000009537\n",
      "Step 202100, training accuracy 0.980000019073\n",
      "Step 202200, training accuracy 0.999999940395\n",
      "Step 202300, training accuracy 0.989999949932\n",
      "Step 202400, training accuracy 0.999999940395\n",
      "Step 202500, training accuracy 0.990000009537\n",
      "Step 202600, training accuracy 0.969999969006\n",
      "Step 202700, training accuracy 1.0\n",
      "Step 202800, training accuracy 1.0\n",
      "Step 202900, training accuracy 0.990000009537\n",
      "Step 203000, training accuracy 0.980000019073\n",
      "Step 203100, training accuracy 0.980000019073\n",
      "Step 203200, training accuracy 0.990000009537\n",
      "Step 203300, training accuracy 1.0\n",
      "Step 203400, training accuracy 0.979999959469\n",
      "Step 203500, training accuracy 0.979999959469\n",
      "Step 203600, training accuracy 0.990000009537\n",
      "Step 203700, training accuracy 0.969999969006\n",
      "Step 203800, training accuracy 0.989999949932\n",
      "Step 203900, training accuracy 0.989999949932\n",
      "Step 204000, training accuracy 0.990000009537\n",
      "Step 204100, training accuracy 1.0\n",
      "Step 204200, training accuracy 0.999999940395\n",
      "Step 204300, training accuracy 0.999999940395\n",
      "Step 204400, training accuracy 1.0\n",
      "Step 204500, training accuracy 1.0\n",
      "Step 204600, training accuracy 0.990000009537\n",
      "Step 204700, training accuracy 0.999999940395\n",
      "Step 204800, training accuracy 0.989999949932\n",
      "Step 204900, training accuracy 0.999999940395\n",
      "Step 205000, training accuracy 0.979999959469\n",
      "Step 205100, training accuracy 1.0\n",
      "Step 205200, training accuracy 0.989999949932\n",
      "Step 205300, training accuracy 0.999999940395\n",
      "Step 205400, training accuracy 0.999999940395\n",
      "Step 205500, training accuracy 0.999999940395\n",
      "Step 205600, training accuracy 0.989999949932\n",
      "Step 205700, training accuracy 0.980000019073\n",
      "Step 205800, training accuracy 0.999999940395\n",
      "Step 205900, training accuracy 0.989999949932\n",
      "Step 206000, training accuracy 0.999999940395\n",
      "Step 206100, training accuracy 1.0\n",
      "Step 206200, training accuracy 0.999999940395\n",
      "Step 206300, training accuracy 0.999999940395\n",
      "Step 206400, training accuracy 0.969999969006\n",
      "Step 206500, training accuracy 0.989999949932\n",
      "Step 206600, training accuracy 0.999999940395\n",
      "Step 206700, training accuracy 1.0\n",
      "Step 206800, training accuracy 0.990000009537\n",
      "Step 206900, training accuracy 0.980000019073\n",
      "Step 207000, training accuracy 0.999999940395\n",
      "Step 207100, training accuracy 1.0\n",
      "Step 207200, training accuracy 0.999999940395\n",
      "Step 207300, training accuracy 0.990000009537\n",
      "Step 207400, training accuracy 0.999999940395\n",
      "Step 207500, training accuracy 0.989999949932\n",
      "Step 207600, training accuracy 0.990000009537\n",
      "Step 207700, training accuracy 0.969999969006\n",
      "Step 207800, training accuracy 0.999999940395\n",
      "Step 207900, training accuracy 1.0\n",
      "Step 208000, training accuracy 0.999999940395\n",
      "Step 208100, training accuracy 0.999999940395\n",
      "Step 208200, training accuracy 0.999999940395\n",
      "Step 208300, training accuracy 0.999999940395\n",
      "Step 208400, training accuracy 0.999999940395\n",
      "Step 208500, training accuracy 0.980000019073\n",
      "Step 208600, training accuracy 0.999999940395\n",
      "Step 208700, training accuracy 0.989999949932\n",
      "Step 208800, training accuracy 0.989999949932\n",
      "Step 208900, training accuracy 0.980000019073\n",
      "Step 209000, training accuracy 0.989999949932\n",
      "Step 209100, training accuracy 1.0\n",
      "Step 209200, training accuracy 0.980000019073\n",
      "Step 209300, training accuracy 0.989999949932\n",
      "Step 209400, training accuracy 0.990000009537\n",
      "Step 209500, training accuracy 0.999999940395\n",
      "Step 209600, training accuracy 0.999999940395\n",
      "Step 209700, training accuracy 0.999999940395\n",
      "Step 209800, training accuracy 1.0\n",
      "Step 209900, training accuracy 0.999999940395\n",
      "Step 210000, training accuracy 1.0\n",
      "Step 210100, training accuracy 1.0\n",
      "Step 210200, training accuracy 0.990000009537\n",
      "Step 210300, training accuracy 0.979999959469\n",
      "Step 210400, training accuracy 1.0\n",
      "Step 210500, training accuracy 0.999999940395\n",
      "Step 210600, training accuracy 1.0\n",
      "Step 210700, training accuracy 1.0\n",
      "Step 210800, training accuracy 0.999999940395\n",
      "Step 210900, training accuracy 1.0\n",
      "Step 211000, training accuracy 1.0\n",
      "Step 211100, training accuracy 0.989999949932\n",
      "Step 211200, training accuracy 0.989999949932\n",
      "Step 211300, training accuracy 0.979999959469\n",
      "Step 211400, training accuracy 0.999999940395\n",
      "Step 211500, training accuracy 1.0\n",
      "Step 211600, training accuracy 0.999999940395\n",
      "Step 211700, training accuracy 1.0\n",
      "Step 211800, training accuracy 0.989999949932\n",
      "Step 211900, training accuracy 0.989999949932\n",
      "Step 212000, training accuracy 0.990000009537\n",
      "Step 212100, training accuracy 0.990000009537\n",
      "Step 212200, training accuracy 1.0\n",
      "Step 212300, training accuracy 0.980000019073\n",
      "Step 212400, training accuracy 0.979999959469\n",
      "Step 212500, training accuracy 0.999999940395\n",
      "Step 212600, training accuracy 0.990000009537\n",
      "Step 212700, training accuracy 0.999999940395\n",
      "Step 212800, training accuracy 0.999999940395\n",
      "Step 212900, training accuracy 0.999999940395\n",
      "Step 213000, training accuracy 0.990000009537\n",
      "Step 213100, training accuracy 0.999999940395\n",
      "Step 213200, training accuracy 0.999999940395\n",
      "Step 213300, training accuracy 0.990000009537\n",
      "Step 213400, training accuracy 0.999999940395\n",
      "Step 213500, training accuracy 1.0\n",
      "Step 213600, training accuracy 0.999999940395\n",
      "Step 213700, training accuracy 0.999999940395\n",
      "Step 213800, training accuracy 0.989999949932\n",
      "Step 213900, training accuracy 1.0\n",
      "Step 214000, training accuracy 0.97000002861\n",
      "Step 214100, training accuracy 0.999999940395\n",
      "Step 214200, training accuracy 0.989999949932\n",
      "Step 214300, training accuracy 0.990000009537\n",
      "Step 214400, training accuracy 0.999999940395\n",
      "Step 214500, training accuracy 1.0\n",
      "Step 214600, training accuracy 0.989999949932\n",
      "Step 214700, training accuracy 0.999999940395\n",
      "Step 214800, training accuracy 0.999999940395\n",
      "Step 214900, training accuracy 0.999999940395\n",
      "Step 215000, training accuracy 0.999999940395\n",
      "Step 215100, training accuracy 0.990000009537\n",
      "Step 215200, training accuracy 1.0\n",
      "Step 215300, training accuracy 0.990000009537\n",
      "Step 215400, training accuracy 1.0\n",
      "Step 215500, training accuracy 0.990000009537\n",
      "Step 215600, training accuracy 0.979999959469\n",
      "Step 215700, training accuracy 0.989999949932\n",
      "Step 215800, training accuracy 0.990000009537\n",
      "Step 215900, training accuracy 0.960000038147\n",
      "Step 216000, training accuracy 0.979999959469\n",
      "Step 216100, training accuracy 1.0\n",
      "Step 216200, training accuracy 0.999999940395\n",
      "Step 216300, training accuracy 1.0\n",
      "Step 216400, training accuracy 0.989999949932\n",
      "Step 216500, training accuracy 0.990000009537\n",
      "Step 216600, training accuracy 1.0\n",
      "Step 216700, training accuracy 0.980000019073\n",
      "Step 216800, training accuracy 0.990000009537\n",
      "Step 216900, training accuracy 1.0\n",
      "Step 217000, training accuracy 1.0\n",
      "Step 217100, training accuracy 1.0\n",
      "Step 217200, training accuracy 0.979999959469\n",
      "Step 217300, training accuracy 0.989999949932\n",
      "Step 217400, training accuracy 1.0\n",
      "Step 217500, training accuracy 0.980000019073\n",
      "Step 217600, training accuracy 0.959999978542\n",
      "Step 217700, training accuracy 1.0\n",
      "Step 217800, training accuracy 0.979999959469\n",
      "Step 217900, training accuracy 0.990000009537\n",
      "Step 218000, training accuracy 0.999999940395\n",
      "Step 218100, training accuracy 0.999999940395\n",
      "Step 218200, training accuracy 1.0\n",
      "Step 218300, training accuracy 1.0\n",
      "Step 218400, training accuracy 0.990000009537\n",
      "Step 218500, training accuracy 0.999999940395\n",
      "Step 218600, training accuracy 0.990000009537\n",
      "Step 218700, training accuracy 0.980000019073\n",
      "Step 218800, training accuracy 0.999999940395\n",
      "Step 218900, training accuracy 0.979999959469\n",
      "Step 219000, training accuracy 1.0\n",
      "Step 219100, training accuracy 1.0\n",
      "Step 219200, training accuracy 0.999999940395\n",
      "Step 219300, training accuracy 0.989999949932\n",
      "Step 219400, training accuracy 1.0\n",
      "Step 219500, training accuracy 0.979999959469\n",
      "Step 219600, training accuracy 0.980000019073\n",
      "Step 219700, training accuracy 0.989999949932\n",
      "Step 219800, training accuracy 0.989999949932\n",
      "Step 219900, training accuracy 0.989999949932\n",
      "Step 220000, training accuracy 1.0\n",
      "Step 220100, training accuracy 1.0\n",
      "Step 220200, training accuracy 0.999999940395\n",
      "Step 220300, training accuracy 1.0\n",
      "Step 220400, training accuracy 0.989999949932\n",
      "Step 220500, training accuracy 0.989999949932\n",
      "Step 220600, training accuracy 0.990000009537\n",
      "Step 220700, training accuracy 1.0\n",
      "Step 220800, training accuracy 0.999999940395\n",
      "Step 220900, training accuracy 0.979999959469\n",
      "Step 221000, training accuracy 0.979999959469\n",
      "Step 221100, training accuracy 1.0\n",
      "Step 221200, training accuracy 0.989999949932\n",
      "Step 221300, training accuracy 0.97000002861\n",
      "Step 221400, training accuracy 0.999999940395\n",
      "Step 221500, training accuracy 0.990000009537\n",
      "Step 221600, training accuracy 0.980000019073\n",
      "Step 221700, training accuracy 0.990000009537\n",
      "Step 221800, training accuracy 1.0\n",
      "Step 221900, training accuracy 0.990000009537\n",
      "Step 222000, training accuracy 0.990000009537\n",
      "Step 222100, training accuracy 0.999999940395\n",
      "Step 222200, training accuracy 0.979999959469\n",
      "Step 222300, training accuracy 0.980000019073\n",
      "Step 222400, training accuracy 1.0\n",
      "Step 222500, training accuracy 1.0\n",
      "Step 222600, training accuracy 1.0\n",
      "Step 222700, training accuracy 0.999999940395\n",
      "Step 222800, training accuracy 1.0\n",
      "Step 222900, training accuracy 1.0\n",
      "Step 223000, training accuracy 0.990000009537\n",
      "Step 223100, training accuracy 0.999999940395\n",
      "Step 223200, training accuracy 0.990000009537\n",
      "Step 223300, training accuracy 1.0\n",
      "Step 223400, training accuracy 0.999999940395\n",
      "Step 223500, training accuracy 1.0\n",
      "Step 223600, training accuracy 0.999999940395\n",
      "Step 223700, training accuracy 0.989999949932\n",
      "Step 223800, training accuracy 0.989999949932\n",
      "Step 223900, training accuracy 0.999999940395\n",
      "Step 224000, training accuracy 0.989999949932\n",
      "Step 224100, training accuracy 0.989999949932\n",
      "Step 224200, training accuracy 1.0\n",
      "Step 224300, training accuracy 0.979999959469\n",
      "Step 224400, training accuracy 0.999999940395\n",
      "Step 224500, training accuracy 0.999999940395\n",
      "Step 224600, training accuracy 1.0\n",
      "Step 224700, training accuracy 0.989999949932\n",
      "Step 224800, training accuracy 0.999999940395\n",
      "Step 224900, training accuracy 0.999999940395\n",
      "Step 225000, training accuracy 0.989999949932\n",
      "Step 225100, training accuracy 0.979999959469\n",
      "Step 225200, training accuracy 1.0\n",
      "Step 225300, training accuracy 0.990000009537\n",
      "Step 225400, training accuracy 0.999999940395\n",
      "Step 225500, training accuracy 0.999999940395\n",
      "Step 225600, training accuracy 1.0\n",
      "Step 225700, training accuracy 0.979999959469\n",
      "Step 225800, training accuracy 0.980000019073\n",
      "Step 225900, training accuracy 0.989999949932\n",
      "Step 226000, training accuracy 0.999999940395\n",
      "Step 226100, training accuracy 1.0\n",
      "Step 226200, training accuracy 1.0\n",
      "Step 226300, training accuracy 0.999999940395\n",
      "Step 226400, training accuracy 0.999999940395\n",
      "Step 226500, training accuracy 0.999999940395\n",
      "Step 226600, training accuracy 1.0\n",
      "Step 226700, training accuracy 0.980000019073\n",
      "Step 226800, training accuracy 0.999999940395\n",
      "Step 226900, training accuracy 0.999999940395\n",
      "Step 227000, training accuracy 0.999999940395\n",
      "Step 227100, training accuracy 0.999999940395\n",
      "Step 227200, training accuracy 0.999999940395\n",
      "Step 227300, training accuracy 0.999999940395\n",
      "Step 227400, training accuracy 0.990000009537\n",
      "Step 227500, training accuracy 1.0\n",
      "Step 227600, training accuracy 0.990000009537\n",
      "Step 227700, training accuracy 0.999999940395\n",
      "Step 227800, training accuracy 0.989999949932\n",
      "Step 227900, training accuracy 0.999999940395\n",
      "Step 228000, training accuracy 1.0\n",
      "Step 228100, training accuracy 1.0\n",
      "Step 228200, training accuracy 0.999999940395\n",
      "Step 228300, training accuracy 0.999999940395\n",
      "Step 228400, training accuracy 0.989999949932\n",
      "Step 228500, training accuracy 0.999999940395\n",
      "Step 228600, training accuracy 1.0\n",
      "Step 228700, training accuracy 0.989999949932\n",
      "Step 228800, training accuracy 0.989999949932\n",
      "Step 228900, training accuracy 0.989999949932\n",
      "Step 229000, training accuracy 0.999999940395\n",
      "Step 229100, training accuracy 0.989999949932\n",
      "Step 229200, training accuracy 0.989999949932\n",
      "Step 229300, training accuracy 0.989999949932\n",
      "Step 229400, training accuracy 0.990000009537\n",
      "Step 229500, training accuracy 1.0\n",
      "Step 229600, training accuracy 1.0\n",
      "Step 229700, training accuracy 1.0\n",
      "Step 229800, training accuracy 1.0\n",
      "Step 229900, training accuracy 0.989999949932\n",
      "Step 230000, training accuracy 0.990000009537\n",
      "Step 230100, training accuracy 1.0\n",
      "Step 230200, training accuracy 0.989999949932\n",
      "Step 230300, training accuracy 0.999999940395\n",
      "Step 230400, training accuracy 0.999999940395\n",
      "Step 230500, training accuracy 0.990000009537\n",
      "Step 230600, training accuracy 1.0\n",
      "Step 230700, training accuracy 0.989999949932\n",
      "Step 230800, training accuracy 0.989999949932\n",
      "Step 230900, training accuracy 1.0\n",
      "Step 231000, training accuracy 0.999999940395\n",
      "Step 231100, training accuracy 1.0\n",
      "Step 231200, training accuracy 0.989999949932\n",
      "Step 231300, training accuracy 1.0\n",
      "Step 231400, training accuracy 0.999999940395\n",
      "Step 231500, training accuracy 1.0\n",
      "Step 231600, training accuracy 0.999999940395\n",
      "Step 231700, training accuracy 1.0\n",
      "Step 231800, training accuracy 1.0\n",
      "Step 231900, training accuracy 0.989999949932\n",
      "Step 232000, training accuracy 1.0\n",
      "Step 232100, training accuracy 1.0\n",
      "Step 232200, training accuracy 1.0\n",
      "Step 232300, training accuracy 0.999999940395\n",
      "Step 232400, training accuracy 0.989999949932\n",
      "Step 232500, training accuracy 0.989999949932\n",
      "Step 232600, training accuracy 0.999999940395\n",
      "Step 232700, training accuracy 0.990000009537\n",
      "Step 232800, training accuracy 1.0\n",
      "Step 232900, training accuracy 0.989999949932\n",
      "Step 233000, training accuracy 0.989999949932\n",
      "Step 233100, training accuracy 0.999999940395\n",
      "Step 233200, training accuracy 1.0\n",
      "Step 233300, training accuracy 0.969999969006\n",
      "Step 233400, training accuracy 0.990000009537\n",
      "Step 233500, training accuracy 0.999999940395\n",
      "Step 233600, training accuracy 1.0\n",
      "Step 233700, training accuracy 1.0\n",
      "Step 233800, training accuracy 0.989999949932\n",
      "Step 233900, training accuracy 0.989999949932\n",
      "Step 234000, training accuracy 1.0\n",
      "Step 234100, training accuracy 1.0\n",
      "Step 234200, training accuracy 0.989999949932\n",
      "Step 234300, training accuracy 0.999999940395\n",
      "Step 234400, training accuracy 0.990000009537\n",
      "Step 234500, training accuracy 0.990000009537\n",
      "Step 234600, training accuracy 1.0\n",
      "Step 234700, training accuracy 0.990000009537\n",
      "Step 234800, training accuracy 0.989999949932\n",
      "Step 234900, training accuracy 1.0\n",
      "Step 235000, training accuracy 1.0\n",
      "Step 235100, training accuracy 0.979999959469\n",
      "Step 235200, training accuracy 0.990000009537\n",
      "Step 235300, training accuracy 0.989999949932\n",
      "Step 235400, training accuracy 1.0\n",
      "Step 235500, training accuracy 1.0\n",
      "Step 235600, training accuracy 0.999999940395\n",
      "Step 235700, training accuracy 0.999999940395\n",
      "Step 235800, training accuracy 0.999999940395\n",
      "Step 235900, training accuracy 1.0\n",
      "Step 236000, training accuracy 0.990000009537\n",
      "Step 236100, training accuracy 1.0\n",
      "Step 236200, training accuracy 0.990000009537\n",
      "Step 236300, training accuracy 0.97000002861\n",
      "Step 236400, training accuracy 1.0\n",
      "Step 236500, training accuracy 1.0\n",
      "Step 236600, training accuracy 1.0\n",
      "Step 236700, training accuracy 0.989999949932\n",
      "Step 236800, training accuracy 1.0\n",
      "Step 236900, training accuracy 1.0\n",
      "Step 237000, training accuracy 1.0\n",
      "Step 237100, training accuracy 0.990000009537\n",
      "Step 237200, training accuracy 1.0\n",
      "Step 237300, training accuracy 0.999999940395\n",
      "Step 237400, training accuracy 0.989999949932\n",
      "Step 237500, training accuracy 0.999999940395\n",
      "Step 237600, training accuracy 0.999999940395\n",
      "Step 237700, training accuracy 0.999999940395\n",
      "Step 237800, training accuracy 1.0\n",
      "Step 237900, training accuracy 1.0\n",
      "Step 238000, training accuracy 0.999999940395\n",
      "Step 238100, training accuracy 0.989999949932\n",
      "Step 238200, training accuracy 1.0\n",
      "Step 238300, training accuracy 0.999999940395\n",
      "Step 238400, training accuracy 0.999999940395\n",
      "Step 238500, training accuracy 0.999999940395\n",
      "Step 238600, training accuracy 0.999999940395\n",
      "Step 238700, training accuracy 1.0\n",
      "Step 238800, training accuracy 0.999999940395\n",
      "Step 238900, training accuracy 1.0\n",
      "Step 239000, training accuracy 1.0\n",
      "Step 239100, training accuracy 1.0\n",
      "Step 239200, training accuracy 0.989999949932\n",
      "Step 239300, training accuracy 0.999999940395\n",
      "Step 239400, training accuracy 0.989999949932\n",
      "Step 239500, training accuracy 0.990000009537\n",
      "Step 239600, training accuracy 0.990000009537\n",
      "Step 239700, training accuracy 0.990000009537\n",
      "Step 239800, training accuracy 0.999999940395\n",
      "Step 239900, training accuracy 0.989999949932\n",
      "Step 240000, training accuracy 1.0\n",
      "Step 240100, training accuracy 0.990000009537\n",
      "Step 240200, training accuracy 0.999999940395\n",
      "Step 240300, training accuracy 0.999999940395\n",
      "Step 240400, training accuracy 0.990000009537\n",
      "Step 240500, training accuracy 0.999999940395\n",
      "Step 240600, training accuracy 0.999999940395\n",
      "Step 240700, training accuracy 0.999999940395\n",
      "Step 240800, training accuracy 1.0\n",
      "Step 240900, training accuracy 1.0\n",
      "Step 241000, training accuracy 1.0\n",
      "Step 241100, training accuracy 0.990000009537\n",
      "Step 241200, training accuracy 1.0\n",
      "Step 241300, training accuracy 0.999999940395\n",
      "Step 241400, training accuracy 0.990000009537\n",
      "Step 241500, training accuracy 1.0\n",
      "Step 241600, training accuracy 0.990000009537\n",
      "Step 241700, training accuracy 0.990000009537\n",
      "Step 241800, training accuracy 0.999999940395\n",
      "Step 241900, training accuracy 0.989999949932\n",
      "Step 242000, training accuracy 1.0\n",
      "Step 242100, training accuracy 1.0\n",
      "Step 242200, training accuracy 0.989999949932\n",
      "Step 242300, training accuracy 0.999999940395\n",
      "Step 242400, training accuracy 0.999999940395\n",
      "Step 242500, training accuracy 1.0\n",
      "Step 242600, training accuracy 1.0\n",
      "Step 242700, training accuracy 0.999999940395\n",
      "Step 242800, training accuracy 1.0\n",
      "Step 242900, training accuracy 0.990000009537\n",
      "Step 243000, training accuracy 1.0\n",
      "Step 243100, training accuracy 0.999999940395\n",
      "Step 243200, training accuracy 0.990000009537\n",
      "Step 243300, training accuracy 1.0\n",
      "Step 243400, training accuracy 0.990000009537\n",
      "Step 243500, training accuracy 1.0\n",
      "Step 243600, training accuracy 0.999999940395\n",
      "Step 243700, training accuracy 1.0\n",
      "Step 243800, training accuracy 0.999999940395\n",
      "Step 243900, training accuracy 0.989999949932\n",
      "Step 244000, training accuracy 1.0\n",
      "Step 244100, training accuracy 0.969999969006\n",
      "Step 244200, training accuracy 1.0\n",
      "Step 244300, training accuracy 1.0\n",
      "Step 244400, training accuracy 0.980000019073\n",
      "Step 244500, training accuracy 1.0\n",
      "Step 244600, training accuracy 0.999999940395\n",
      "Step 244700, training accuracy 0.999999940395\n",
      "Step 244800, training accuracy 0.999999940395\n",
      "Step 244900, training accuracy 0.999999940395\n",
      "Step 245000, training accuracy 1.0\n",
      "Step 245100, training accuracy 1.0\n",
      "Step 245200, training accuracy 1.0\n",
      "Step 245300, training accuracy 0.999999940395\n",
      "Step 245400, training accuracy 1.0\n",
      "Step 245500, training accuracy 0.999999940395\n",
      "Step 245600, training accuracy 0.999999940395\n",
      "Step 245700, training accuracy 0.989999949932\n",
      "Step 245800, training accuracy 0.989999949932\n",
      "Step 245900, training accuracy 0.999999940395\n",
      "Step 246000, training accuracy 1.0\n",
      "Step 246100, training accuracy 0.989999949932\n",
      "Step 246200, training accuracy 0.990000009537\n",
      "Step 246300, training accuracy 0.980000019073\n",
      "Step 246400, training accuracy 1.0\n",
      "Step 246500, training accuracy 0.990000009537\n",
      "Step 246600, training accuracy 1.0\n",
      "Step 246700, training accuracy 0.999999940395\n",
      "Step 246800, training accuracy 0.999999940395\n",
      "Step 246900, training accuracy 0.999999940395\n",
      "Step 247000, training accuracy 0.980000019073\n",
      "Step 247100, training accuracy 0.999999940395\n",
      "Step 247200, training accuracy 0.999999940395\n",
      "Step 247300, training accuracy 0.980000019073\n",
      "Step 247400, training accuracy 0.979999959469\n",
      "Step 247500, training accuracy 1.0\n",
      "Step 247600, training accuracy 0.999999940395\n",
      "Step 247700, training accuracy 0.999999940395\n",
      "Step 247800, training accuracy 0.989999949932\n",
      "Step 247900, training accuracy 0.989999949932\n",
      "Step 248000, training accuracy 1.0\n",
      "Step 248100, training accuracy 1.0\n",
      "Step 248200, training accuracy 0.990000009537\n",
      "Step 248300, training accuracy 0.989999949932\n",
      "Step 248400, training accuracy 1.0\n",
      "Step 248500, training accuracy 1.0\n",
      "Step 248600, training accuracy 1.0\n",
      "Step 248700, training accuracy 1.0\n",
      "Step 248800, training accuracy 0.999999940395\n",
      "Step 248900, training accuracy 0.990000009537\n",
      "Step 249000, training accuracy 1.0\n",
      "Step 249100, training accuracy 0.999999940395\n",
      "Step 249200, training accuracy 1.0\n",
      "Step 249300, training accuracy 0.980000019073\n",
      "Step 249400, training accuracy 0.999999940395\n",
      "Step 249500, training accuracy 1.0\n",
      "Step 249600, training accuracy 0.979999959469\n",
      "Step 249700, training accuracy 0.990000009537\n",
      "Step 249800, training accuracy 0.990000009537\n",
      "Step 249900, training accuracy 1.0\n",
      "Step 250000, training accuracy 0.999999940395\n",
      "Step 250100, training accuracy 0.989999949932\n",
      "Step 250200, training accuracy 0.999999940395\n",
      "Step 250300, training accuracy 1.0\n",
      "Step 250400, training accuracy 0.999999940395\n",
      "Step 250500, training accuracy 0.990000009537\n",
      "Step 250600, training accuracy 1.0\n",
      "Step 250700, training accuracy 0.989999949932\n",
      "Step 250800, training accuracy 0.999999940395\n",
      "Step 250900, training accuracy 0.999999940395\n",
      "Step 251000, training accuracy 0.999999940395\n",
      "Step 251100, training accuracy 0.990000009537\n",
      "Step 251200, training accuracy 1.0\n",
      "Step 251300, training accuracy 1.0\n",
      "Step 251400, training accuracy 0.989999949932\n",
      "Step 251500, training accuracy 0.989999949932\n",
      "Step 251600, training accuracy 1.0\n",
      "Step 251700, training accuracy 0.990000009537\n",
      "Step 251800, training accuracy 0.999999940395\n",
      "Step 251900, training accuracy 0.980000019073\n",
      "Step 252000, training accuracy 1.0\n",
      "Step 252100, training accuracy 1.0\n",
      "Step 252200, training accuracy 0.989999949932\n",
      "Step 252300, training accuracy 1.0\n",
      "Step 252400, training accuracy 1.0\n",
      "Step 252500, training accuracy 1.0\n",
      "Step 252600, training accuracy 1.0\n",
      "Step 252700, training accuracy 1.0\n",
      "Step 252800, training accuracy 1.0\n",
      "Step 252900, training accuracy 0.999999940395\n",
      "Step 253000, training accuracy 0.989999949932\n",
      "Step 253100, training accuracy 0.999999940395\n",
      "Step 253200, training accuracy 0.999999940395\n",
      "Step 253300, training accuracy 0.999999940395\n",
      "Step 253400, training accuracy 0.990000009537\n",
      "Step 253500, training accuracy 0.989999949932\n",
      "Step 253600, training accuracy 0.999999940395\n",
      "Step 253700, training accuracy 0.999999940395\n",
      "Step 253800, training accuracy 1.0\n",
      "Step 253900, training accuracy 1.0\n",
      "Step 254000, training accuracy 0.989999949932\n",
      "Step 254100, training accuracy 0.989999949932\n",
      "Step 254200, training accuracy 1.0\n",
      "Step 254300, training accuracy 1.0\n",
      "Step 254400, training accuracy 0.989999949932\n",
      "Step 254500, training accuracy 1.0\n",
      "Step 254600, training accuracy 1.0\n",
      "Step 254700, training accuracy 0.979999959469\n",
      "Step 254800, training accuracy 0.990000009537\n",
      "Step 254900, training accuracy 0.999999940395\n",
      "Step 255000, training accuracy 1.0\n",
      "Step 255100, training accuracy 0.999999940395\n",
      "Step 255200, training accuracy 0.989999949932\n",
      "Step 255300, training accuracy 0.999999940395\n",
      "Step 255400, training accuracy 1.0\n",
      "Step 255500, training accuracy 0.990000009537\n",
      "Step 255600, training accuracy 0.999999940395\n",
      "Step 255700, training accuracy 0.999999940395\n",
      "Step 255800, training accuracy 1.0\n",
      "Step 255900, training accuracy 1.0\n",
      "Step 256000, training accuracy 1.0\n",
      "Step 256100, training accuracy 1.0\n",
      "Step 256200, training accuracy 0.990000009537\n",
      "Step 256300, training accuracy 0.999999940395\n",
      "Step 256400, training accuracy 0.999999940395\n",
      "Step 256500, training accuracy 0.969999969006\n",
      "Step 256600, training accuracy 0.999999940395\n",
      "Step 256700, training accuracy 0.980000019073\n",
      "Step 256800, training accuracy 1.0\n",
      "Step 256900, training accuracy 1.0\n",
      "Step 257000, training accuracy 1.0\n",
      "Step 257100, training accuracy 0.999999940395\n",
      "Step 257200, training accuracy 0.999999940395\n",
      "Step 257300, training accuracy 0.999999940395\n",
      "Step 257400, training accuracy 0.999999940395\n",
      "Step 257500, training accuracy 0.999999940395\n",
      "Step 257600, training accuracy 0.999999940395\n",
      "Step 257700, training accuracy 0.999999940395\n",
      "Step 257800, training accuracy 0.990000009537\n",
      "Step 257900, training accuracy 1.0\n",
      "Step 258000, training accuracy 0.979999959469\n",
      "Step 258100, training accuracy 0.999999940395\n",
      "Step 258200, training accuracy 1.0\n",
      "Step 258300, training accuracy 1.0\n",
      "Step 258400, training accuracy 0.999999940395\n",
      "Step 258500, training accuracy 0.989999949932\n",
      "Step 258600, training accuracy 0.990000009537\n",
      "Step 258700, training accuracy 0.989999949932\n",
      "Step 258800, training accuracy 0.990000009537\n",
      "Step 258900, training accuracy 1.0\n",
      "Step 259000, training accuracy 1.0\n",
      "Step 259100, training accuracy 0.990000009537\n",
      "Step 259200, training accuracy 1.0\n",
      "Step 259300, training accuracy 1.0\n",
      "Step 259400, training accuracy 0.990000009537\n",
      "Step 259500, training accuracy 1.0\n",
      "Step 259600, training accuracy 0.990000009537\n",
      "Step 259700, training accuracy 0.999999940395\n",
      "Step 259800, training accuracy 0.999999940395\n",
      "Step 259900, training accuracy 0.979999959469\n",
      "Step 260000, training accuracy 0.989999949932\n",
      "Step 260100, training accuracy 1.0\n",
      "Step 260200, training accuracy 1.0\n",
      "Step 260300, training accuracy 1.0\n",
      "Step 260400, training accuracy 1.0\n",
      "Step 260500, training accuracy 1.0\n",
      "Step 260600, training accuracy 0.999999940395\n",
      "Step 260700, training accuracy 0.999999940395\n",
      "Step 260800, training accuracy 0.999999940395\n",
      "Step 260900, training accuracy 1.0\n",
      "Step 261000, training accuracy 0.999999940395\n",
      "Step 261100, training accuracy 0.999999940395\n",
      "Step 261200, training accuracy 0.999999940395\n",
      "Step 261300, training accuracy 1.0\n",
      "Step 261400, training accuracy 1.0\n",
      "Step 261500, training accuracy 0.999999940395\n",
      "Step 261600, training accuracy 0.999999940395\n",
      "Step 261700, training accuracy 0.990000009537\n",
      "Step 261800, training accuracy 0.980000019073\n",
      "Step 261900, training accuracy 1.0\n",
      "Step 262000, training accuracy 0.999999940395\n",
      "Step 262100, training accuracy 0.989999949932\n",
      "Step 262200, training accuracy 0.990000009537\n",
      "Step 262300, training accuracy 0.989999949932\n",
      "Step 262400, training accuracy 0.999999940395\n",
      "Step 262500, training accuracy 1.0\n",
      "Step 262600, training accuracy 0.999999940395\n",
      "Step 262700, training accuracy 0.990000009537\n",
      "Step 262800, training accuracy 0.999999940395\n",
      "Step 262900, training accuracy 1.0\n",
      "Step 263000, training accuracy 0.999999940395\n",
      "Step 263100, training accuracy 1.0\n",
      "Step 263200, training accuracy 0.999999940395\n",
      "Step 263300, training accuracy 0.999999940395\n",
      "Step 263400, training accuracy 0.999999940395\n",
      "Step 263500, training accuracy 1.0\n",
      "Step 263600, training accuracy 0.999999940395\n",
      "Step 263700, training accuracy 0.999999940395\n",
      "Step 263800, training accuracy 1.0\n",
      "Step 263900, training accuracy 0.990000009537\n",
      "Step 264000, training accuracy 0.999999940395\n",
      "Step 264100, training accuracy 0.989999949932\n",
      "Step 264200, training accuracy 1.0\n",
      "Step 264300, training accuracy 0.999999940395\n",
      "Step 264400, training accuracy 1.0\n",
      "Step 264500, training accuracy 0.999999940395\n",
      "Step 264600, training accuracy 0.999999940395\n",
      "Step 264700, training accuracy 1.0\n",
      "Step 264800, training accuracy 1.0\n",
      "Step 264900, training accuracy 0.990000009537\n",
      "Step 265000, training accuracy 1.0\n",
      "Step 265100, training accuracy 1.0\n",
      "Step 265200, training accuracy 0.999999940395\n",
      "Step 265300, training accuracy 1.0\n",
      "Step 265400, training accuracy 0.999999940395\n",
      "Step 265500, training accuracy 0.990000009537\n",
      "Step 265600, training accuracy 1.0\n",
      "Step 265700, training accuracy 0.989999949932\n",
      "Step 265800, training accuracy 0.980000019073\n",
      "Step 265900, training accuracy 1.0\n",
      "Step 266000, training accuracy 0.999999940395\n",
      "Step 266100, training accuracy 0.990000009537\n",
      "Step 266200, training accuracy 0.999999940395\n",
      "Step 266300, training accuracy 1.0\n",
      "Step 266400, training accuracy 0.999999940395\n",
      "Step 266500, training accuracy 1.0\n",
      "Step 266600, training accuracy 0.990000009537\n",
      "Step 266700, training accuracy 1.0\n",
      "Step 266800, training accuracy 1.0\n",
      "Step 266900, training accuracy 0.999999940395\n",
      "Step 267000, training accuracy 1.0\n",
      "Step 267100, training accuracy 0.979999959469\n",
      "Step 267200, training accuracy 0.999999940395\n",
      "Step 267300, training accuracy 1.0\n",
      "Step 267400, training accuracy 0.999999940395\n",
      "Step 267500, training accuracy 0.989999949932\n",
      "Step 267600, training accuracy 0.999999940395\n",
      "Step 267700, training accuracy 0.990000009537\n",
      "Step 267800, training accuracy 0.999999940395\n",
      "Step 267900, training accuracy 0.999999940395\n",
      "Step 268000, training accuracy 1.0\n",
      "Step 268100, training accuracy 1.0\n",
      "Step 268200, training accuracy 0.999999940395\n",
      "Step 268300, training accuracy 0.989999949932\n",
      "Step 268400, training accuracy 0.989999949932\n",
      "Step 268500, training accuracy 1.0\n",
      "Step 268600, training accuracy 0.999999940395\n",
      "Step 268700, training accuracy 1.0\n",
      "Step 268800, training accuracy 1.0\n",
      "Step 268900, training accuracy 0.999999940395\n",
      "Step 269000, training accuracy 0.999999940395\n",
      "Step 269100, training accuracy 1.0\n",
      "Step 269200, training accuracy 0.989999949932\n",
      "Step 269300, training accuracy 0.989999949932\n",
      "Step 269400, training accuracy 1.0\n",
      "Step 269500, training accuracy 1.0\n",
      "Step 269600, training accuracy 1.0\n",
      "Step 269700, training accuracy 1.0\n",
      "Step 269800, training accuracy 0.999999940395\n",
      "Step 269900, training accuracy 1.0\n",
      "Step 270000, training accuracy 1.0\n",
      "Step 270100, training accuracy 1.0\n",
      "Step 270200, training accuracy 0.999999940395\n",
      "Step 270300, training accuracy 0.999999940395\n",
      "Step 270400, training accuracy 0.999999940395\n",
      "Step 270500, training accuracy 1.0\n",
      "Step 270600, training accuracy 0.999999940395\n",
      "Step 270700, training accuracy 0.990000009537\n",
      "Step 270800, training accuracy 0.999999940395\n",
      "Step 270900, training accuracy 0.999999940395\n",
      "Step 271000, training accuracy 1.0\n",
      "Step 271100, training accuracy 1.0\n",
      "Step 271200, training accuracy 0.999999940395\n",
      "Step 271300, training accuracy 1.0\n",
      "Step 271400, training accuracy 0.999999940395\n",
      "Step 271500, training accuracy 0.990000009537\n",
      "Step 271600, training accuracy 1.0\n",
      "Step 271700, training accuracy 0.989999949932\n",
      "Step 271800, training accuracy 0.999999940395\n",
      "Step 271900, training accuracy 0.990000009537\n",
      "Step 272000, training accuracy 0.999999940395\n",
      "Step 272100, training accuracy 0.990000009537\n",
      "Step 272200, training accuracy 1.0\n",
      "Step 272300, training accuracy 1.0\n",
      "Step 272400, training accuracy 1.0\n",
      "Step 272500, training accuracy 1.0\n",
      "Step 272600, training accuracy 1.0\n",
      "Step 272700, training accuracy 0.990000009537\n",
      "Step 272800, training accuracy 1.0\n",
      "Step 272900, training accuracy 0.999999940395\n",
      "Step 273000, training accuracy 0.990000009537\n",
      "Step 273100, training accuracy 0.989999949932\n",
      "Step 273200, training accuracy 0.999999940395\n",
      "Step 273300, training accuracy 0.999999940395\n",
      "Step 273400, training accuracy 0.999999940395\n",
      "Step 273500, training accuracy 0.989999949932\n",
      "Step 273600, training accuracy 0.990000009537\n",
      "Step 273700, training accuracy 0.999999940395\n",
      "Step 273800, training accuracy 0.999999940395\n",
      "Step 273900, training accuracy 0.999999940395\n",
      "Step 274000, training accuracy 1.0\n",
      "Step 274100, training accuracy 0.999999940395\n",
      "Step 274200, training accuracy 0.989999949932\n",
      "Step 274300, training accuracy 0.999999940395\n",
      "Step 274400, training accuracy 0.989999949932\n",
      "Step 274500, training accuracy 1.0\n",
      "Step 274600, training accuracy 1.0\n",
      "Step 274700, training accuracy 0.999999940395\n",
      "Step 274800, training accuracy 1.0\n",
      "Step 274900, training accuracy 1.0\n",
      "Step 275000, training accuracy 1.0\n",
      "Step 275100, training accuracy 1.0\n",
      "Step 275200, training accuracy 0.999999940395\n",
      "Step 275300, training accuracy 0.979999959469\n",
      "Step 275400, training accuracy 0.999999940395\n",
      "Step 275500, training accuracy 0.999999940395\n",
      "Step 275600, training accuracy 0.989999949932\n",
      "Step 275700, training accuracy 1.0\n",
      "Step 275800, training accuracy 1.0\n",
      "Step 275900, training accuracy 0.990000009537\n",
      "Step 276000, training accuracy 1.0\n",
      "Step 276100, training accuracy 1.0\n",
      "Step 276200, training accuracy 0.999999940395\n",
      "Step 276300, training accuracy 1.0\n",
      "Step 276400, training accuracy 1.0\n",
      "Step 276500, training accuracy 1.0\n",
      "Step 276600, training accuracy 0.999999940395\n",
      "Step 276700, training accuracy 1.0\n",
      "Step 276800, training accuracy 0.999999940395\n",
      "Step 276900, training accuracy 0.990000009537\n",
      "Step 277000, training accuracy 0.989999949932\n",
      "Step 277100, training accuracy 1.0\n",
      "Step 277200, training accuracy 0.989999949932\n",
      "Step 277300, training accuracy 1.0\n",
      "Step 277400, training accuracy 0.999999940395\n",
      "Step 277500, training accuracy 0.999999940395\n",
      "Step 277600, training accuracy 0.999999940395\n",
      "Step 277700, training accuracy 0.999999940395\n",
      "Step 277800, training accuracy 1.0\n",
      "Step 277900, training accuracy 0.989999949932\n",
      "Step 278000, training accuracy 0.999999940395\n",
      "Step 278100, training accuracy 0.989999949932\n",
      "Step 278200, training accuracy 0.999999940395\n",
      "Step 278300, training accuracy 1.0\n",
      "Step 278400, training accuracy 0.999999940395\n",
      "Step 278500, training accuracy 0.999999940395\n",
      "Step 278600, training accuracy 0.999999940395\n",
      "Step 278700, training accuracy 1.0\n",
      "Step 278800, training accuracy 0.990000009537\n",
      "Step 278900, training accuracy 1.0\n",
      "Step 279000, training accuracy 1.0\n",
      "Step 279100, training accuracy 0.999999940395\n",
      "Step 279200, training accuracy 0.999999940395\n",
      "Step 279300, training accuracy 0.999999940395\n",
      "Step 279400, training accuracy 1.0\n",
      "Step 279500, training accuracy 0.999999940395\n",
      "Step 279600, training accuracy 0.990000009537\n",
      "Step 279700, training accuracy 0.989999949932\n",
      "Step 279800, training accuracy 1.0\n",
      "Step 279900, training accuracy 0.999999940395\n",
      "Step 280000, training accuracy 1.0\n",
      "Step 280100, training accuracy 1.0\n",
      "Step 280200, training accuracy 0.990000009537\n",
      "Step 280300, training accuracy 0.989999949932\n",
      "Step 280400, training accuracy 1.0\n",
      "Step 280500, training accuracy 0.990000009537\n",
      "Step 280600, training accuracy 1.0\n",
      "Step 280700, training accuracy 0.999999940395\n",
      "Step 280800, training accuracy 0.999999940395\n",
      "Step 280900, training accuracy 0.999999940395\n",
      "Step 281000, training accuracy 0.999999940395\n",
      "Step 281100, training accuracy 1.0\n",
      "Step 281200, training accuracy 1.0\n",
      "Step 281300, training accuracy 0.989999949932\n",
      "Step 281400, training accuracy 0.999999940395\n",
      "Step 281500, training accuracy 1.0\n",
      "Step 281600, training accuracy 0.999999940395\n",
      "Step 281700, training accuracy 0.999999940395\n",
      "Step 281800, training accuracy 0.999999940395\n",
      "Step 281900, training accuracy 1.0\n",
      "Step 282000, training accuracy 1.0\n",
      "Step 282100, training accuracy 0.999999940395\n",
      "Step 282200, training accuracy 0.989999949932\n",
      "Step 282300, training accuracy 1.0\n",
      "Step 282400, training accuracy 0.989999949932\n",
      "Step 282500, training accuracy 0.999999940395\n",
      "Step 282600, training accuracy 0.989999949932\n",
      "Step 282700, training accuracy 0.999999940395\n",
      "Step 282800, training accuracy 1.0\n",
      "Step 282900, training accuracy 0.999999940395\n",
      "Step 283000, training accuracy 0.999999940395\n",
      "Step 283100, training accuracy 0.999999940395\n",
      "Step 283200, training accuracy 0.999999940395\n",
      "Step 283300, training accuracy 1.0\n",
      "Step 283400, training accuracy 0.999999940395\n",
      "Step 283500, training accuracy 0.999999940395\n",
      "Step 283600, training accuracy 0.999999940395\n",
      "Step 283700, training accuracy 1.0\n",
      "Step 283800, training accuracy 0.989999949932\n",
      "Step 283900, training accuracy 0.999999940395\n",
      "Step 284000, training accuracy 0.999999940395\n",
      "Step 284100, training accuracy 1.0\n",
      "Step 284200, training accuracy 0.999999940395\n",
      "Step 284300, training accuracy 0.990000009537\n",
      "Step 284400, training accuracy 0.999999940395\n",
      "Step 284500, training accuracy 0.989999949932\n",
      "Step 284600, training accuracy 1.0\n",
      "Step 284700, training accuracy 0.979999959469\n",
      "Step 284800, training accuracy 0.990000009537\n",
      "Step 284900, training accuracy 0.999999940395\n",
      "Step 285000, training accuracy 0.989999949932\n",
      "Step 285100, training accuracy 1.0\n",
      "Step 285200, training accuracy 0.999999940395\n",
      "Step 285300, training accuracy 0.989999949932\n",
      "Step 285400, training accuracy 0.999999940395\n",
      "Step 285500, training accuracy 0.999999940395\n",
      "Step 285600, training accuracy 1.0\n",
      "Step 285700, training accuracy 0.999999940395\n",
      "Step 285800, training accuracy 1.0\n",
      "Step 285900, training accuracy 0.999999940395\n",
      "Step 286000, training accuracy 0.999999940395\n",
      "Step 286100, training accuracy 0.999999940395\n",
      "Step 286200, training accuracy 0.999999940395\n",
      "Step 286300, training accuracy 0.990000009537\n",
      "Step 286400, training accuracy 0.990000009537\n",
      "Step 286500, training accuracy 0.990000009537\n",
      "Step 286600, training accuracy 1.0\n",
      "Step 286700, training accuracy 0.990000009537\n",
      "Step 286800, training accuracy 0.999999940395\n",
      "Step 286900, training accuracy 0.990000009537\n",
      "Step 287000, training accuracy 0.97000002861\n",
      "Step 287100, training accuracy 0.999999940395\n",
      "Step 287200, training accuracy 1.0\n",
      "Step 287300, training accuracy 1.0\n",
      "Step 287400, training accuracy 0.999999940395\n",
      "Step 287500, training accuracy 0.999999940395\n",
      "Step 287600, training accuracy 0.999999940395\n",
      "Step 287700, training accuracy 1.0\n",
      "Step 287800, training accuracy 0.989999949932\n",
      "Step 287900, training accuracy 0.990000009537\n",
      "Step 288000, training accuracy 1.0\n",
      "Step 288100, training accuracy 0.999999940395\n",
      "Step 288200, training accuracy 1.0\n",
      "Step 288300, training accuracy 0.999999940395\n",
      "Step 288400, training accuracy 1.0\n",
      "Step 288500, training accuracy 0.999999940395\n",
      "Step 288600, training accuracy 1.0\n",
      "Step 288700, training accuracy 1.0\n",
      "Step 288800, training accuracy 1.0\n",
      "Step 288900, training accuracy 0.999999940395\n",
      "Step 289000, training accuracy 0.999999940395\n",
      "Step 289100, training accuracy 0.999999940395\n",
      "Step 289200, training accuracy 1.0\n",
      "Step 289300, training accuracy 0.999999940395\n",
      "Step 289400, training accuracy 0.999999940395\n",
      "Step 289500, training accuracy 1.0\n",
      "Step 289600, training accuracy 1.0\n",
      "Step 289700, training accuracy 1.0\n",
      "Step 289800, training accuracy 0.990000009537\n",
      "Step 289900, training accuracy 0.990000009537\n",
      "Step 290000, training accuracy 1.0\n",
      "Step 290100, training accuracy 0.989999949932\n",
      "Step 290200, training accuracy 0.989999949932\n",
      "Step 290300, training accuracy 0.999999940395\n",
      "Step 290400, training accuracy 1.0\n",
      "Step 290500, training accuracy 0.989999949932\n",
      "Step 290600, training accuracy 0.989999949932\n",
      "Step 290700, training accuracy 0.999999940395\n",
      "Step 290800, training accuracy 1.0\n",
      "Step 290900, training accuracy 0.999999940395\n",
      "Step 291000, training accuracy 1.0\n",
      "Step 291100, training accuracy 0.990000009537\n",
      "Step 291200, training accuracy 0.989999949932\n",
      "Step 291300, training accuracy 0.999999940395\n",
      "Step 291400, training accuracy 0.999999940395\n",
      "Step 291500, training accuracy 1.0\n",
      "Step 291600, training accuracy 1.0\n",
      "Step 291700, training accuracy 0.999999940395\n",
      "Step 291800, training accuracy 0.990000009537\n",
      "Step 291900, training accuracy 0.999999940395\n",
      "Step 292000, training accuracy 0.990000009537\n",
      "Step 292100, training accuracy 0.999999940395\n",
      "Step 292200, training accuracy 0.999999940395\n",
      "Step 292300, training accuracy 0.999999940395\n",
      "Step 292400, training accuracy 0.990000009537\n",
      "Step 292500, training accuracy 0.999999940395\n",
      "Step 292600, training accuracy 1.0\n",
      "Step 292700, training accuracy 0.999999940395\n",
      "Step 292800, training accuracy 0.999999940395\n",
      "Step 292900, training accuracy 1.0\n",
      "Step 293000, training accuracy 1.0\n",
      "Step 293100, training accuracy 1.0\n",
      "Step 293200, training accuracy 0.990000009537\n",
      "Step 293300, training accuracy 0.999999940395\n",
      "Step 293400, training accuracy 0.999999940395\n",
      "Step 293500, training accuracy 1.0\n",
      "Step 293600, training accuracy 1.0\n",
      "Step 293700, training accuracy 1.0\n",
      "Step 293800, training accuracy 1.0\n",
      "Step 293900, training accuracy 0.999999940395\n",
      "Step 294000, training accuracy 0.999999940395\n",
      "Step 294100, training accuracy 1.0\n",
      "Step 294200, training accuracy 1.0\n",
      "Step 294300, training accuracy 1.0\n",
      "Step 294400, training accuracy 0.999999940395\n",
      "Step 294500, training accuracy 0.979999959469\n",
      "Step 294600, training accuracy 0.999999940395\n",
      "Step 294700, training accuracy 0.999999940395\n",
      "Step 294800, training accuracy 0.999999940395\n",
      "Step 294900, training accuracy 0.989999949932\n",
      "Step 295000, training accuracy 1.0\n",
      "Step 295100, training accuracy 1.0\n",
      "Step 295200, training accuracy 0.999999940395\n",
      "Step 295300, training accuracy 1.0\n",
      "Step 295400, training accuracy 0.999999940395\n",
      "Step 295500, training accuracy 1.0\n",
      "Step 295600, training accuracy 1.0\n",
      "Step 295700, training accuracy 1.0\n",
      "Step 295800, training accuracy 0.999999940395\n",
      "Step 295900, training accuracy 0.999999940395\n",
      "Step 296000, training accuracy 0.989999949932\n",
      "Step 296100, training accuracy 0.999999940395\n",
      "Step 296200, training accuracy 0.989999949932\n",
      "Step 296300, training accuracy 1.0\n",
      "Step 296400, training accuracy 0.999999940395\n",
      "Step 296500, training accuracy 0.979999959469\n",
      "Step 296600, training accuracy 0.999999940395\n",
      "Step 296700, training accuracy 1.0\n",
      "Step 296800, training accuracy 1.0\n",
      "Step 296900, training accuracy 0.980000019073\n",
      "Step 297000, training accuracy 0.999999940395\n",
      "Step 297100, training accuracy 1.0\n",
      "Step 297200, training accuracy 0.999999940395\n",
      "Step 297300, training accuracy 1.0\n",
      "Step 297400, training accuracy 0.999999940395\n",
      "Step 297500, training accuracy 1.0\n",
      "Step 297600, training accuracy 1.0\n",
      "Step 297700, training accuracy 1.0\n",
      "Step 297800, training accuracy 1.0\n",
      "Step 297900, training accuracy 0.999999940395\n",
      "Step 298000, training accuracy 1.0\n",
      "Step 298100, training accuracy 0.999999940395\n",
      "Step 298200, training accuracy 1.0\n",
      "Step 298300, training accuracy 0.999999940395\n",
      "Step 298400, training accuracy 0.990000009537\n",
      "Step 298500, training accuracy 0.990000009537\n",
      "Step 298600, training accuracy 0.989999949932\n",
      "Step 298700, training accuracy 1.0\n",
      "Step 298800, training accuracy 1.0\n",
      "Step 298900, training accuracy 0.999999940395\n",
      "Step 299000, training accuracy 0.999999940395\n",
      "Step 299100, training accuracy 0.999999940395\n",
      "Step 299200, training accuracy 0.999999940395\n",
      "Step 299300, training accuracy 0.989999949932\n",
      "Step 299400, training accuracy 0.999999940395\n",
      "Step 299500, training accuracy 0.999999940395\n",
      "Step 299600, training accuracy 1.0\n",
      "Step 299700, training accuracy 0.999999940395\n",
      "Step 299800, training accuracy 1.0\n",
      "Step 299900, training accuracy 0.999999940395\n",
      "Step 300000, training accuracy 0.999999940395\n",
      "Step 300100, training accuracy 0.989999949932\n",
      "Step 300200, training accuracy 0.999999940395\n",
      "Step 300300, training accuracy 1.0\n",
      "Step 300400, training accuracy 0.999999940395\n",
      "Step 300500, training accuracy 1.0\n",
      "Step 300600, training accuracy 1.0\n",
      "Step 300700, training accuracy 0.999999940395\n",
      "Step 300800, training accuracy 0.999999940395\n",
      "Step 300900, training accuracy 0.999999940395\n",
      "Step 301000, training accuracy 0.989999949932\n",
      "Step 301100, training accuracy 1.0\n",
      "Step 301200, training accuracy 1.0\n",
      "Step 301300, training accuracy 0.999999940395\n",
      "Step 301400, training accuracy 0.999999940395\n",
      "Step 301500, training accuracy 1.0\n",
      "Step 301600, training accuracy 1.0\n",
      "Step 301700, training accuracy 0.999999940395\n",
      "Step 301800, training accuracy 0.999999940395\n",
      "Step 301900, training accuracy 0.999999940395\n",
      "Step 302000, training accuracy 0.999999940395\n",
      "Step 302100, training accuracy 0.999999940395\n",
      "Step 302200, training accuracy 0.999999940395\n",
      "Step 302300, training accuracy 1.0\n",
      "Step 302400, training accuracy 1.0\n",
      "Step 302500, training accuracy 0.990000009537\n",
      "Step 302600, training accuracy 0.989999949932\n",
      "Step 302700, training accuracy 0.999999940395\n",
      "Step 302800, training accuracy 0.990000009537\n",
      "Step 302900, training accuracy 1.0\n",
      "Step 303000, training accuracy 0.999999940395\n",
      "Step 303100, training accuracy 0.999999940395\n",
      "Step 303200, training accuracy 0.999999940395\n",
      "Step 303300, training accuracy 0.999999940395\n",
      "Step 303400, training accuracy 1.0\n",
      "Step 303500, training accuracy 0.999999940395\n",
      "Step 303600, training accuracy 0.999999940395\n",
      "Step 303700, training accuracy 0.999999940395\n",
      "Step 303800, training accuracy 0.989999949932\n",
      "Step 303900, training accuracy 1.0\n",
      "Step 304000, training accuracy 0.989999949932\n",
      "Step 304100, training accuracy 1.0\n",
      "Step 304200, training accuracy 0.989999949932\n",
      "Step 304300, training accuracy 1.0\n",
      "Step 304400, training accuracy 1.0\n",
      "Step 304500, training accuracy 0.990000009537\n",
      "Step 304600, training accuracy 0.999999940395\n",
      "Step 304700, training accuracy 1.0\n",
      "Step 304800, training accuracy 1.0\n",
      "Step 304900, training accuracy 1.0\n",
      "Step 305000, training accuracy 0.990000009537\n",
      "Step 305100, training accuracy 1.0\n",
      "Step 305200, training accuracy 1.0\n",
      "Step 305300, training accuracy 0.990000009537\n",
      "Step 305400, training accuracy 1.0\n",
      "Step 305500, training accuracy 0.989999949932\n",
      "Step 305600, training accuracy 1.0\n",
      "Step 305700, training accuracy 1.0\n",
      "Step 305800, training accuracy 1.0\n",
      "Step 305900, training accuracy 1.0\n",
      "Step 306000, training accuracy 0.999999940395\n",
      "Step 306100, training accuracy 1.0\n",
      "Step 306200, training accuracy 0.989999949932\n",
      "Step 306300, training accuracy 0.999999940395\n",
      "Step 306400, training accuracy 1.0\n",
      "Step 306500, training accuracy 1.0\n",
      "Step 306600, training accuracy 0.989999949932\n",
      "Step 306700, training accuracy 1.0\n",
      "Step 306800, training accuracy 1.0\n",
      "Step 306900, training accuracy 1.0\n",
      "Step 307000, training accuracy 0.990000009537\n",
      "Step 307100, training accuracy 0.999999940395\n",
      "Step 307200, training accuracy 1.0\n",
      "Step 307300, training accuracy 0.989999949932\n",
      "Step 307400, training accuracy 0.989999949932\n",
      "Step 307500, training accuracy 0.989999949932\n",
      "Step 307600, training accuracy 0.999999940395\n",
      "Step 307700, training accuracy 0.990000009537\n",
      "Step 307800, training accuracy 0.999999940395\n",
      "Step 307900, training accuracy 0.999999940395\n",
      "Step 308000, training accuracy 0.999999940395\n",
      "Step 308100, training accuracy 0.989999949932\n",
      "Step 308200, training accuracy 1.0\n",
      "Step 308300, training accuracy 1.0\n",
      "Step 308400, training accuracy 0.999999940395\n",
      "Step 308500, training accuracy 1.0\n",
      "Step 308600, training accuracy 1.0\n",
      "Step 308700, training accuracy 0.999999940395\n",
      "Step 308800, training accuracy 1.0\n",
      "Step 308900, training accuracy 1.0\n",
      "Step 309000, training accuracy 0.999999940395\n",
      "Step 309100, training accuracy 0.999999940395\n",
      "Step 309200, training accuracy 1.0\n",
      "Step 309300, training accuracy 1.0\n",
      "Step 309400, training accuracy 0.979999959469\n",
      "Step 309500, training accuracy 1.0\n",
      "Step 309600, training accuracy 1.0\n",
      "Step 309700, training accuracy 1.0\n",
      "Step 309800, training accuracy 1.0\n",
      "Step 309900, training accuracy 1.0\n",
      "Step 310000, training accuracy 0.999999940395\n",
      "Step 310100, training accuracy 1.0\n",
      "Step 310200, training accuracy 1.0\n",
      "Step 310300, training accuracy 0.990000009537\n",
      "Step 310400, training accuracy 0.999999940395\n",
      "Step 310500, training accuracy 0.989999949932\n",
      "Step 310600, training accuracy 0.999999940395\n",
      "Step 310700, training accuracy 1.0\n",
      "Step 310800, training accuracy 1.0\n",
      "Step 310900, training accuracy 0.999999940395\n",
      "Step 311000, training accuracy 0.990000009537\n",
      "Step 311100, training accuracy 0.999999940395\n",
      "Step 311200, training accuracy 0.999999940395\n",
      "Step 311300, training accuracy 0.990000009537\n",
      "Step 311400, training accuracy 0.999999940395\n",
      "Step 311500, training accuracy 0.989999949932\n",
      "Step 311600, training accuracy 0.980000019073\n",
      "Step 311700, training accuracy 1.0\n",
      "Step 311800, training accuracy 1.0\n",
      "Step 311900, training accuracy 1.0\n",
      "Step 312000, training accuracy 0.999999940395\n",
      "Step 312100, training accuracy 0.989999949932\n",
      "Step 312200, training accuracy 1.0\n",
      "Step 312300, training accuracy 1.0\n",
      "Step 312400, training accuracy 1.0\n",
      "Step 312500, training accuracy 1.0\n",
      "Step 312600, training accuracy 0.999999940395\n",
      "Step 312700, training accuracy 0.999999940395\n",
      "Step 312800, training accuracy 1.0\n",
      "Step 312900, training accuracy 0.999999940395\n",
      "Step 313000, training accuracy 1.0\n",
      "Step 313100, training accuracy 0.990000009537\n",
      "Step 313200, training accuracy 0.989999949932\n",
      "Step 313300, training accuracy 1.0\n",
      "Step 313400, training accuracy 1.0\n",
      "Step 313500, training accuracy 0.979999959469\n",
      "Step 313600, training accuracy 1.0\n",
      "Step 313700, training accuracy 0.990000009537\n",
      "Step 313800, training accuracy 1.0\n",
      "Step 313900, training accuracy 1.0\n",
      "Step 314000, training accuracy 0.990000009537\n",
      "Step 314100, training accuracy 0.999999940395\n",
      "Step 314200, training accuracy 1.0\n",
      "Step 314300, training accuracy 0.980000019073\n",
      "Step 314400, training accuracy 0.999999940395\n",
      "Step 314500, training accuracy 1.0\n",
      "Step 314600, training accuracy 1.0\n",
      "Step 314700, training accuracy 0.999999940395\n",
      "Step 314800, training accuracy 1.0\n",
      "Step 314900, training accuracy 0.999999940395\n",
      "Step 315000, training accuracy 0.989999949932\n",
      "Step 315100, training accuracy 1.0\n",
      "Step 315200, training accuracy 1.0\n",
      "Step 315300, training accuracy 0.999999940395\n",
      "Step 315400, training accuracy 1.0\n",
      "Step 315500, training accuracy 1.0\n",
      "Step 315600, training accuracy 1.0\n",
      "Step 315700, training accuracy 1.0\n",
      "Step 315800, training accuracy 0.989999949932\n",
      "Step 315900, training accuracy 1.0\n",
      "Step 316000, training accuracy 1.0\n",
      "Step 316100, training accuracy 1.0\n",
      "Step 316200, training accuracy 1.0\n",
      "Step 316300, training accuracy 1.0\n",
      "Step 316400, training accuracy 1.0\n",
      "Step 316500, training accuracy 0.989999949932\n",
      "Step 316600, training accuracy 1.0\n",
      "Step 316700, training accuracy 1.0\n",
      "Step 316800, training accuracy 1.0\n",
      "Step 316900, training accuracy 0.999999940395\n",
      "Step 317000, training accuracy 0.999999940395\n",
      "Step 317100, training accuracy 0.989999949932\n",
      "Step 317200, training accuracy 0.980000019073\n",
      "Step 317300, training accuracy 1.0\n",
      "Step 317400, training accuracy 0.999999940395\n",
      "Step 317500, training accuracy 1.0\n",
      "Step 317600, training accuracy 0.999999940395\n",
      "Step 317700, training accuracy 0.999999940395\n",
      "Step 317800, training accuracy 0.999999940395\n",
      "Step 317900, training accuracy 1.0\n",
      "Step 318000, training accuracy 0.999999940395\n",
      "Step 318100, training accuracy 0.999999940395\n",
      "Step 318200, training accuracy 0.990000009537\n",
      "Step 318300, training accuracy 1.0\n",
      "Step 318400, training accuracy 0.999999940395\n",
      "Step 318500, training accuracy 0.999999940395\n",
      "Step 318600, training accuracy 0.999999940395\n",
      "Step 318700, training accuracy 1.0\n",
      "Step 318800, training accuracy 1.0\n",
      "Step 318900, training accuracy 1.0\n",
      "Step 319000, training accuracy 1.0\n",
      "Step 319100, training accuracy 1.0\n",
      "Step 319200, training accuracy 1.0\n",
      "Step 319300, training accuracy 0.990000009537\n",
      "Step 319400, training accuracy 0.989999949932\n",
      "Step 319500, training accuracy 1.0\n",
      "Step 319600, training accuracy 1.0\n",
      "Step 319700, training accuracy 1.0\n",
      "Step 319800, training accuracy 1.0\n",
      "Step 319900, training accuracy 0.999999940395\n",
      "Step 320000, training accuracy 0.999999940395\n",
      "Step 320100, training accuracy 0.989999949932\n",
      "Step 320200, training accuracy 0.989999949932\n",
      "Step 320300, training accuracy 0.999999940395\n",
      "Step 320400, training accuracy 0.989999949932\n",
      "Step 320500, training accuracy 1.0\n",
      "Step 320600, training accuracy 0.999999940395\n",
      "Step 320700, training accuracy 1.0\n",
      "Step 320800, training accuracy 0.999999940395\n",
      "Step 320900, training accuracy 0.999999940395\n",
      "Step 321000, training accuracy 1.0\n",
      "Step 321100, training accuracy 1.0\n",
      "Step 321200, training accuracy 0.999999940395\n",
      "Step 321300, training accuracy 0.990000009537\n",
      "Step 321400, training accuracy 1.0\n",
      "Step 321500, training accuracy 0.999999940395\n",
      "Step 321600, training accuracy 1.0\n",
      "Step 321700, training accuracy 0.999999940395\n",
      "Step 321800, training accuracy 1.0\n",
      "Step 321900, training accuracy 0.999999940395\n",
      "Step 322000, training accuracy 1.0\n",
      "Step 322100, training accuracy 0.999999940395\n",
      "Step 322200, training accuracy 0.999999940395\n",
      "Step 322300, training accuracy 1.0\n",
      "Step 322400, training accuracy 0.989999949932\n",
      "Step 322500, training accuracy 0.999999940395\n",
      "Step 322600, training accuracy 1.0\n",
      "Step 322700, training accuracy 0.999999940395\n",
      "Step 322800, training accuracy 0.999999940395\n",
      "Step 322900, training accuracy 1.0\n",
      "Step 323000, training accuracy 0.999999940395\n",
      "Step 323100, training accuracy 0.990000009537\n",
      "Step 323200, training accuracy 0.999999940395\n",
      "Step 323300, training accuracy 0.999999940395\n",
      "Step 323400, training accuracy 0.999999940395\n",
      "Step 323500, training accuracy 0.990000009537\n",
      "Step 323600, training accuracy 1.0\n",
      "Step 323700, training accuracy 1.0\n",
      "Step 323800, training accuracy 0.990000009537\n",
      "Step 323900, training accuracy 1.0\n",
      "Step 324000, training accuracy 0.999999940395\n",
      "Step 324100, training accuracy 0.999999940395\n",
      "Step 324200, training accuracy 0.990000009537\n",
      "Step 324300, training accuracy 0.999999940395\n",
      "Step 324400, training accuracy 1.0\n",
      "Step 324500, training accuracy 1.0\n",
      "Step 324600, training accuracy 0.999999940395\n",
      "Step 324700, training accuracy 0.989999949932\n",
      "Step 324800, training accuracy 0.999999940395\n",
      "Step 324900, training accuracy 1.0\n",
      "Step 325000, training accuracy 1.0\n",
      "Step 325100, training accuracy 0.999999940395\n",
      "Step 325200, training accuracy 0.990000009537\n",
      "Step 325300, training accuracy 0.999999940395\n",
      "Step 325400, training accuracy 0.989999949932\n",
      "Step 325500, training accuracy 1.0\n",
      "Step 325600, training accuracy 1.0\n",
      "Step 325700, training accuracy 1.0\n",
      "Step 325800, training accuracy 1.0\n",
      "Step 325900, training accuracy 1.0\n",
      "Step 326000, training accuracy 0.999999940395\n",
      "Step 326100, training accuracy 1.0\n",
      "Step 326200, training accuracy 1.0\n",
      "Step 326300, training accuracy 1.0\n",
      "Step 326400, training accuracy 0.999999940395\n",
      "Step 326500, training accuracy 0.989999949932\n",
      "Step 326600, training accuracy 0.999999940395\n",
      "Step 326700, training accuracy 0.999999940395\n",
      "Step 326800, training accuracy 1.0\n",
      "Step 326900, training accuracy 0.999999940395\n",
      "Step 327000, training accuracy 1.0\n",
      "Step 327100, training accuracy 1.0\n",
      "Step 327200, training accuracy 1.0\n",
      "Step 327300, training accuracy 0.990000009537\n",
      "Step 327400, training accuracy 1.0\n",
      "Step 327500, training accuracy 0.999999940395\n",
      "Step 327600, training accuracy 0.999999940395\n",
      "Step 327700, training accuracy 0.990000009537\n",
      "Step 327800, training accuracy 0.999999940395\n",
      "Step 327900, training accuracy 0.999999940395\n",
      "Step 328000, training accuracy 1.0\n",
      "Step 328100, training accuracy 0.999999940395\n",
      "Step 328200, training accuracy 1.0\n",
      "Step 328300, training accuracy 0.999999940395\n",
      "Step 328400, training accuracy 0.990000009537\n",
      "Step 328500, training accuracy 1.0\n",
      "Step 328600, training accuracy 1.0\n",
      "Step 328700, training accuracy 0.999999940395\n",
      "Step 328800, training accuracy 1.0\n",
      "Step 328900, training accuracy 1.0\n",
      "Step 329000, training accuracy 0.999999940395\n",
      "Step 329100, training accuracy 0.999999940395\n",
      "Step 329200, training accuracy 1.0\n",
      "Step 329300, training accuracy 0.999999940395\n",
      "Step 329400, training accuracy 1.0\n",
      "Step 329500, training accuracy 1.0\n",
      "Step 329600, training accuracy 1.0\n",
      "Step 329700, training accuracy 1.0\n",
      "Step 329800, training accuracy 1.0\n",
      "Step 329900, training accuracy 0.999999940395\n",
      "Step 330000, training accuracy 0.999999940395\n",
      "Step 330100, training accuracy 0.999999940395\n",
      "Step 330200, training accuracy 0.989999949932\n",
      "Step 330300, training accuracy 1.0\n",
      "Step 330400, training accuracy 0.990000009537\n",
      "Step 330500, training accuracy 1.0\n",
      "Step 330600, training accuracy 0.990000009537\n",
      "Step 330700, training accuracy 0.999999940395\n",
      "Step 330800, training accuracy 0.999999940395\n",
      "Step 330900, training accuracy 0.999999940395\n",
      "Step 331000, training accuracy 0.989999949932\n",
      "Step 331100, training accuracy 0.999999940395\n",
      "Step 331200, training accuracy 0.999999940395\n",
      "Step 331300, training accuracy 0.999999940395\n",
      "Step 331400, training accuracy 1.0\n",
      "Step 331500, training accuracy 1.0\n",
      "Step 331600, training accuracy 0.999999940395\n",
      "Step 331700, training accuracy 1.0\n",
      "Step 331800, training accuracy 1.0\n",
      "Step 331900, training accuracy 1.0\n",
      "Step 332000, training accuracy 0.999999940395\n",
      "Step 332100, training accuracy 0.989999949932\n",
      "Step 332200, training accuracy 1.0\n",
      "Step 332300, training accuracy 0.999999940395\n",
      "Step 332400, training accuracy 0.989999949932\n",
      "Step 332500, training accuracy 1.0\n",
      "Step 332600, training accuracy 0.999999940395\n",
      "Step 332700, training accuracy 0.989999949932\n",
      "Step 332800, training accuracy 1.0\n",
      "Step 332900, training accuracy 0.999999940395\n",
      "Step 333000, training accuracy 0.999999940395\n",
      "Step 333100, training accuracy 0.999999940395\n",
      "Step 333200, training accuracy 0.989999949932\n",
      "Step 333300, training accuracy 0.999999940395\n",
      "Step 333400, training accuracy 1.0\n",
      "Step 333500, training accuracy 0.999999940395\n",
      "Step 333600, training accuracy 0.999999940395\n",
      "Step 333700, training accuracy 1.0\n",
      "Step 333800, training accuracy 0.999999940395\n",
      "Step 333900, training accuracy 0.990000009537\n",
      "Step 334000, training accuracy 0.999999940395\n",
      "Step 334100, training accuracy 0.999999940395\n",
      "Step 334200, training accuracy 1.0\n",
      "Step 334300, training accuracy 0.999999940395\n",
      "Step 334400, training accuracy 0.999999940395\n",
      "Step 334500, training accuracy 1.0\n",
      "Step 334600, training accuracy 0.999999940395\n",
      "Step 334700, training accuracy 0.999999940395\n",
      "Step 334800, training accuracy 1.0\n",
      "Step 334900, training accuracy 0.990000009537\n",
      "Step 335000, training accuracy 1.0\n",
      "Step 335100, training accuracy 1.0\n",
      "Step 335200, training accuracy 0.999999940395\n",
      "Step 335300, training accuracy 0.989999949932\n",
      "Step 335400, training accuracy 1.0\n",
      "Step 335500, training accuracy 1.0\n",
      "Step 335600, training accuracy 0.999999940395\n",
      "Step 335700, training accuracy 0.999999940395\n",
      "Step 335800, training accuracy 1.0\n",
      "Step 335900, training accuracy 0.999999940395\n",
      "Step 336000, training accuracy 1.0\n",
      "Step 336100, training accuracy 0.990000009537\n",
      "Step 336200, training accuracy 0.999999940395\n",
      "Step 336300, training accuracy 0.999999940395\n",
      "Step 336400, training accuracy 1.0\n",
      "Step 336500, training accuracy 1.0\n",
      "Step 336600, training accuracy 1.0\n",
      "Step 336700, training accuracy 1.0\n",
      "Step 336800, training accuracy 0.990000009537\n",
      "Step 336900, training accuracy 1.0\n",
      "Step 337000, training accuracy 1.0\n",
      "Step 337100, training accuracy 0.989999949932\n",
      "Step 337200, training accuracy 0.989999949932\n",
      "Step 337300, training accuracy 1.0\n",
      "Step 337400, training accuracy 0.999999940395\n",
      "Step 337500, training accuracy 0.999999940395\n",
      "Step 337600, training accuracy 0.999999940395\n",
      "Step 337700, training accuracy 0.999999940395\n",
      "Step 337800, training accuracy 0.999999940395\n",
      "Step 337900, training accuracy 1.0\n",
      "Step 338000, training accuracy 0.999999940395\n",
      "Step 338100, training accuracy 1.0\n",
      "Step 338200, training accuracy 0.989999949932\n",
      "Step 338300, training accuracy 0.999999940395\n",
      "Step 338400, training accuracy 0.999999940395\n",
      "Step 338500, training accuracy 0.999999940395\n",
      "Step 338600, training accuracy 1.0\n",
      "Step 338700, training accuracy 1.0\n",
      "Step 338800, training accuracy 0.999999940395\n",
      "Step 338900, training accuracy 1.0\n",
      "Step 339000, training accuracy 0.999999940395\n",
      "Step 339100, training accuracy 1.0\n",
      "Step 339200, training accuracy 0.999999940395\n",
      "Step 339300, training accuracy 1.0\n",
      "Step 339400, training accuracy 1.0\n",
      "Step 339500, training accuracy 0.999999940395\n",
      "Step 339600, training accuracy 1.0\n",
      "Step 339700, training accuracy 1.0\n",
      "Step 339800, training accuracy 1.0\n",
      "Step 339900, training accuracy 0.999999940395\n",
      "Step 340000, training accuracy 1.0\n",
      "Step 340100, training accuracy 0.980000019073\n",
      "Step 340200, training accuracy 0.989999949932\n",
      "Step 340300, training accuracy 0.999999940395\n",
      "Step 340400, training accuracy 0.999999940395\n",
      "Step 340500, training accuracy 1.0\n",
      "Step 340600, training accuracy 1.0\n",
      "Step 340700, training accuracy 0.999999940395\n",
      "Step 340800, training accuracy 1.0\n",
      "Step 340900, training accuracy 0.989999949932\n",
      "Step 341000, training accuracy 0.990000009537\n",
      "Step 341100, training accuracy 1.0\n",
      "Step 341200, training accuracy 0.999999940395\n",
      "Step 341300, training accuracy 1.0\n",
      "Step 341400, training accuracy 1.0\n",
      "Step 341500, training accuracy 0.999999940395\n",
      "Step 341600, training accuracy 0.999999940395\n",
      "Step 341700, training accuracy 1.0\n",
      "Step 341800, training accuracy 0.999999940395\n",
      "Step 341900, training accuracy 0.999999940395\n",
      "Step 342000, training accuracy 0.999999940395\n",
      "Step 342100, training accuracy 0.990000009537\n",
      "Step 342200, training accuracy 0.999999940395\n",
      "Step 342300, training accuracy 1.0\n",
      "Step 342400, training accuracy 0.999999940395\n",
      "Step 342500, training accuracy 1.0\n",
      "Step 342600, training accuracy 0.999999940395\n",
      "Step 342700, training accuracy 1.0\n",
      "Step 342800, training accuracy 1.0\n",
      "Step 342900, training accuracy 1.0\n",
      "Step 343000, training accuracy 0.980000019073\n",
      "Step 343100, training accuracy 1.0\n",
      "Step 343200, training accuracy 0.999999940395\n",
      "Step 343300, training accuracy 1.0\n",
      "Step 343400, training accuracy 0.999999940395\n",
      "Step 343500, training accuracy 0.999999940395\n",
      "Step 343600, training accuracy 0.999999940395\n",
      "Step 343700, training accuracy 0.999999940395\n",
      "Step 343800, training accuracy 0.999999940395\n",
      "Step 343900, training accuracy 1.0\n",
      "Step 344000, training accuracy 0.999999940395\n",
      "Step 344100, training accuracy 1.0\n",
      "Step 344200, training accuracy 0.999999940395\n",
      "Step 344300, training accuracy 0.989999949932\n",
      "Step 344400, training accuracy 0.999999940395\n",
      "Step 344500, training accuracy 1.0\n",
      "Step 344600, training accuracy 1.0\n",
      "Step 344700, training accuracy 0.979999959469\n",
      "Step 344800, training accuracy 0.999999940395\n",
      "Step 344900, training accuracy 0.990000009537\n",
      "Step 345000, training accuracy 0.999999940395\n",
      "Step 345100, training accuracy 1.0\n",
      "Step 345200, training accuracy 1.0\n",
      "Step 345300, training accuracy 0.999999940395\n",
      "Step 345400, training accuracy 0.999999940395\n",
      "Step 345500, training accuracy 0.999999940395\n",
      "Step 345600, training accuracy 0.999999940395\n",
      "Step 345700, training accuracy 0.999999940395\n",
      "Step 345800, training accuracy 1.0\n",
      "Step 345900, training accuracy 0.999999940395\n",
      "Step 346000, training accuracy 1.0\n",
      "Step 346100, training accuracy 1.0\n",
      "Step 346200, training accuracy 1.0\n",
      "Step 346300, training accuracy 0.999999940395\n",
      "Step 346400, training accuracy 1.0\n",
      "Step 346500, training accuracy 0.999999940395\n",
      "Step 346600, training accuracy 1.0\n",
      "Step 346700, training accuracy 0.999999940395\n",
      "Step 346800, training accuracy 1.0\n",
      "Step 346900, training accuracy 1.0\n",
      "Step 347000, training accuracy 0.999999940395\n",
      "Step 347100, training accuracy 0.999999940395\n",
      "Step 347200, training accuracy 0.999999940395\n",
      "Step 347300, training accuracy 1.0\n",
      "Step 347400, training accuracy 0.999999940395\n",
      "Step 347500, training accuracy 0.999999940395\n",
      "Step 347600, training accuracy 1.0\n",
      "Step 347700, training accuracy 1.0\n",
      "Step 347800, training accuracy 1.0\n",
      "Step 347900, training accuracy 0.999999940395\n",
      "Step 348000, training accuracy 0.999999940395\n",
      "Step 348100, training accuracy 1.0\n",
      "Step 348200, training accuracy 1.0\n",
      "Step 348300, training accuracy 1.0\n",
      "Step 348400, training accuracy 0.999999940395\n",
      "Step 348500, training accuracy 0.990000009537\n",
      "Step 348600, training accuracy 1.0\n",
      "Step 348700, training accuracy 1.0\n",
      "Step 348800, training accuracy 1.0\n",
      "Step 348900, training accuracy 0.999999940395\n",
      "Step 349000, training accuracy 1.0\n",
      "Step 349100, training accuracy 0.999999940395\n",
      "Step 349200, training accuracy 1.0\n",
      "Step 349300, training accuracy 1.0\n",
      "Step 349400, training accuracy 1.0\n",
      "Step 349500, training accuracy 0.999999940395\n",
      "Step 349600, training accuracy 0.979999959469\n",
      "Step 349700, training accuracy 0.999999940395\n",
      "Step 349800, training accuracy 0.989999949932\n",
      "Step 349900, training accuracy 0.990000009537\n",
      "Step 350000, training accuracy 1.0\n",
      "Step 350100, training accuracy 0.990000009537\n",
      "Step 350200, training accuracy 1.0\n",
      "Step 350300, training accuracy 0.999999940395\n",
      "Step 350400, training accuracy 0.999999940395\n",
      "Step 350500, training accuracy 0.999999940395\n",
      "Step 350600, training accuracy 0.999999940395\n",
      "Step 350700, training accuracy 1.0\n",
      "Step 350800, training accuracy 0.999999940395\n",
      "Step 350900, training accuracy 0.990000009537\n",
      "Step 351000, training accuracy 0.990000009537\n",
      "Step 351100, training accuracy 1.0\n",
      "Step 351200, training accuracy 1.0\n",
      "Step 351300, training accuracy 1.0\n",
      "Step 351400, training accuracy 1.0\n",
      "Step 351500, training accuracy 0.999999940395\n",
      "Step 351600, training accuracy 1.0\n",
      "Step 351700, training accuracy 0.989999949932\n",
      "Step 351800, training accuracy 1.0\n",
      "Step 351900, training accuracy 0.999999940395\n",
      "Step 352000, training accuracy 0.999999940395\n",
      "Step 352100, training accuracy 0.990000009537\n",
      "Step 352200, training accuracy 0.999999940395\n",
      "Step 352300, training accuracy 0.989999949932\n",
      "Step 352400, training accuracy 1.0\n",
      "Step 352500, training accuracy 1.0\n",
      "Step 352600, training accuracy 1.0\n",
      "Step 352700, training accuracy 0.989999949932\n",
      "Step 352800, training accuracy 1.0\n",
      "Step 352900, training accuracy 0.999999940395\n",
      "Step 353000, training accuracy 1.0\n",
      "Step 353100, training accuracy 0.999999940395\n",
      "Step 353200, training accuracy 1.0\n",
      "Step 353300, training accuracy 0.999999940395\n",
      "Step 353400, training accuracy 0.999999940395\n",
      "Step 353500, training accuracy 0.999999940395\n",
      "Step 353600, training accuracy 0.999999940395\n",
      "Step 353700, training accuracy 0.999999940395\n",
      "Step 353800, training accuracy 0.999999940395\n",
      "Step 353900, training accuracy 1.0\n",
      "Step 354000, training accuracy 1.0\n",
      "Step 354100, training accuracy 0.989999949932\n",
      "Step 354200, training accuracy 1.0\n",
      "Step 354300, training accuracy 0.999999940395\n",
      "Step 354400, training accuracy 0.999999940395\n",
      "Step 354500, training accuracy 1.0\n",
      "Step 354600, training accuracy 1.0\n",
      "Step 354700, training accuracy 1.0\n",
      "Step 354800, training accuracy 0.999999940395\n",
      "Step 354900, training accuracy 0.999999940395\n",
      "Step 355000, training accuracy 0.999999940395\n",
      "Step 355100, training accuracy 0.999999940395\n",
      "Step 355200, training accuracy 0.989999949932\n",
      "Step 355300, training accuracy 1.0\n",
      "Step 355400, training accuracy 0.999999940395\n",
      "Step 355500, training accuracy 0.999999940395\n",
      "Step 355600, training accuracy 1.0\n",
      "Step 355700, training accuracy 1.0\n",
      "Step 355800, training accuracy 0.999999940395\n",
      "Step 355900, training accuracy 1.0\n",
      "Step 356000, training accuracy 0.999999940395\n",
      "Step 356100, training accuracy 1.0\n",
      "Step 356200, training accuracy 1.0\n",
      "Step 356300, training accuracy 0.999999940395\n",
      "Step 356400, training accuracy 0.999999940395\n",
      "Step 356500, training accuracy 0.990000009537\n",
      "Step 356600, training accuracy 0.999999940395\n",
      "Step 356700, training accuracy 1.0\n",
      "Step 356800, training accuracy 1.0\n",
      "Step 356900, training accuracy 0.989999949932\n",
      "Step 357000, training accuracy 1.0\n",
      "Step 357100, training accuracy 0.999999940395\n",
      "Step 357200, training accuracy 0.999999940395\n",
      "Step 357300, training accuracy 0.999999940395\n",
      "Step 357400, training accuracy 0.999999940395\n",
      "Step 357500, training accuracy 1.0\n",
      "Step 357600, training accuracy 0.989999949932\n",
      "Step 357700, training accuracy 0.999999940395\n",
      "Step 357800, training accuracy 0.990000009537\n",
      "Step 357900, training accuracy 0.999999940395\n",
      "Step 358000, training accuracy 0.990000009537\n",
      "Step 358100, training accuracy 0.990000009537\n",
      "Step 358200, training accuracy 0.999999940395\n",
      "Step 358300, training accuracy 1.0\n",
      "Step 358400, training accuracy 0.999999940395\n",
      "Step 358500, training accuracy 1.0\n",
      "Step 358600, training accuracy 0.999999940395\n",
      "Step 358700, training accuracy 0.999999940395\n",
      "Step 358800, training accuracy 0.979999959469\n",
      "Step 358900, training accuracy 0.999999940395\n",
      "Step 359000, training accuracy 0.999999940395\n",
      "Step 359100, training accuracy 0.999999940395\n",
      "Step 359200, training accuracy 0.999999940395\n",
      "Step 359300, training accuracy 1.0\n",
      "Step 359400, training accuracy 0.999999940395\n",
      "Step 359500, training accuracy 1.0\n",
      "Step 359600, training accuracy 1.0\n",
      "Step 359700, training accuracy 0.999999940395\n",
      "Step 359800, training accuracy 1.0\n",
      "Step 359900, training accuracy 1.0\n",
      "Step 360000, training accuracy 1.0\n",
      "Step 360100, training accuracy 1.0\n",
      "Step 360200, training accuracy 1.0\n",
      "Step 360300, training accuracy 0.999999940395\n",
      "Step 360400, training accuracy 1.0\n",
      "Step 360500, training accuracy 0.999999940395\n",
      "Step 360600, training accuracy 0.980000019073\n",
      "Step 360700, training accuracy 0.989999949932\n",
      "Step 360800, training accuracy 0.990000009537\n",
      "Step 360900, training accuracy 1.0\n",
      "Step 361000, training accuracy 0.999999940395\n",
      "Step 361100, training accuracy 0.989999949932\n",
      "Step 361200, training accuracy 1.0\n",
      "Step 361300, training accuracy 1.0\n",
      "Step 361400, training accuracy 0.989999949932\n",
      "Step 361500, training accuracy 1.0\n",
      "Step 361600, training accuracy 0.990000009537\n",
      "Step 361700, training accuracy 1.0\n",
      "Step 361800, training accuracy 1.0\n",
      "Step 361900, training accuracy 1.0\n",
      "Step 362000, training accuracy 0.999999940395\n",
      "Step 362100, training accuracy 0.999999940395\n",
      "Step 362200, training accuracy 1.0\n",
      "Step 362300, training accuracy 0.990000009537\n",
      "Step 362400, training accuracy 0.999999940395\n",
      "Step 362500, training accuracy 0.999999940395\n",
      "Step 362600, training accuracy 0.980000019073\n",
      "Step 362700, training accuracy 0.999999940395\n",
      "Step 362800, training accuracy 1.0\n",
      "Step 362900, training accuracy 1.0\n",
      "Step 363000, training accuracy 1.0\n",
      "Step 363100, training accuracy 1.0\n",
      "Step 363200, training accuracy 0.999999940395\n",
      "Step 363300, training accuracy 1.0\n",
      "Step 363400, training accuracy 0.989999949932\n",
      "Step 363500, training accuracy 0.990000009537\n",
      "Step 363600, training accuracy 0.999999940395\n",
      "Step 363700, training accuracy 0.989999949932\n",
      "Step 363800, training accuracy 0.999999940395\n",
      "Step 363900, training accuracy 0.990000009537\n",
      "Step 364000, training accuracy 0.989999949932\n",
      "Step 364100, training accuracy 1.0\n",
      "Step 364200, training accuracy 0.990000009537\n",
      "Step 364300, training accuracy 0.980000019073\n",
      "Step 364400, training accuracy 1.0\n",
      "Step 364500, training accuracy 0.999999940395\n",
      "Step 364600, training accuracy 1.0\n",
      "Step 364700, training accuracy 0.990000009537\n",
      "Step 364800, training accuracy 1.0\n",
      "Step 364900, training accuracy 0.999999940395\n",
      "Step 365000, training accuracy 0.999999940395\n",
      "Step 365100, training accuracy 1.0\n",
      "Step 365200, training accuracy 0.999999940395\n",
      "Step 365300, training accuracy 1.0\n",
      "Step 365400, training accuracy 1.0\n",
      "Step 365500, training accuracy 1.0\n",
      "Step 365600, training accuracy 0.999999940395\n",
      "Step 365700, training accuracy 0.989999949932\n",
      "Step 365800, training accuracy 1.0\n",
      "Step 365900, training accuracy 0.999999940395\n",
      "Step 366000, training accuracy 0.999999940395\n",
      "Step 366100, training accuracy 0.990000009537\n",
      "Step 366200, training accuracy 1.0\n",
      "Step 366300, training accuracy 1.0\n",
      "Step 366400, training accuracy 0.999999940395\n",
      "Step 366500, training accuracy 0.999999940395\n",
      "Step 366600, training accuracy 0.999999940395\n",
      "Step 366700, training accuracy 1.0\n",
      "Step 366800, training accuracy 1.0\n",
      "Step 366900, training accuracy 0.990000009537\n",
      "Step 367000, training accuracy 1.0\n",
      "Step 367100, training accuracy 0.989999949932\n",
      "Step 367200, training accuracy 0.999999940395\n",
      "Step 367300, training accuracy 1.0\n",
      "Step 367400, training accuracy 0.989999949932\n",
      "Step 367500, training accuracy 1.0\n",
      "Step 367600, training accuracy 0.999999940395\n",
      "Step 367700, training accuracy 0.999999940395\n",
      "Step 367800, training accuracy 1.0\n",
      "Step 367900, training accuracy 1.0\n",
      "Step 368000, training accuracy 0.999999940395\n",
      "Step 368100, training accuracy 1.0\n",
      "Step 368200, training accuracy 1.0\n",
      "Step 368300, training accuracy 0.999999940395\n",
      "Step 368400, training accuracy 1.0\n",
      "Step 368500, training accuracy 0.989999949932\n",
      "Step 368600, training accuracy 0.989999949932\n",
      "Step 368700, training accuracy 0.999999940395\n",
      "Step 368800, training accuracy 1.0\n",
      "Step 368900, training accuracy 0.999999940395\n",
      "Step 369000, training accuracy 1.0\n",
      "Step 369100, training accuracy 0.989999949932\n",
      "Step 369200, training accuracy 1.0\n",
      "Step 369300, training accuracy 1.0\n",
      "Step 369400, training accuracy 1.0\n",
      "Step 369500, training accuracy 1.0\n",
      "Step 369600, training accuracy 1.0\n",
      "Step 369700, training accuracy 1.0\n",
      "Step 369800, training accuracy 0.999999940395\n",
      "Step 369900, training accuracy 1.0\n",
      "Step 370000, training accuracy 0.999999940395\n",
      "Step 370100, training accuracy 1.0\n",
      "Step 370200, training accuracy 1.0\n",
      "Step 370300, training accuracy 0.999999940395\n",
      "Step 370400, training accuracy 1.0\n",
      "Step 370500, training accuracy 0.999999940395\n",
      "Step 370600, training accuracy 1.0\n",
      "Step 370700, training accuracy 0.999999940395\n",
      "Step 370800, training accuracy 0.999999940395\n",
      "Step 370900, training accuracy 0.999999940395\n",
      "Step 371000, training accuracy 1.0\n",
      "Step 371100, training accuracy 1.0\n",
      "Step 371200, training accuracy 1.0\n",
      "Step 371300, training accuracy 1.0\n",
      "Step 371400, training accuracy 0.999999940395\n",
      "Step 371500, training accuracy 1.0\n",
      "Step 371600, training accuracy 0.999999940395\n",
      "Step 371700, training accuracy 1.0\n",
      "Step 371800, training accuracy 0.999999940395\n",
      "Step 371900, training accuracy 0.999999940395\n",
      "Step 372000, training accuracy 1.0\n",
      "Step 372100, training accuracy 1.0\n",
      "Step 372200, training accuracy 0.999999940395\n",
      "Step 372300, training accuracy 0.999999940395\n",
      "Step 372400, training accuracy 0.999999940395\n",
      "Step 372500, training accuracy 1.0\n",
      "Step 372600, training accuracy 1.0\n",
      "Step 372700, training accuracy 1.0\n",
      "Step 372800, training accuracy 0.999999940395\n",
      "Step 372900, training accuracy 0.999999940395\n",
      "Step 373000, training accuracy 1.0\n",
      "Step 373100, training accuracy 1.0\n",
      "Step 373200, training accuracy 0.999999940395\n",
      "Step 373300, training accuracy 1.0\n",
      "Step 373400, training accuracy 0.989999949932\n",
      "Step 373500, training accuracy 0.999999940395\n",
      "Step 373600, training accuracy 0.999999940395\n",
      "Step 373700, training accuracy 0.999999940395\n",
      "Step 373800, training accuracy 0.999999940395\n",
      "Step 373900, training accuracy 1.0\n",
      "Step 374000, training accuracy 1.0\n",
      "Step 374100, training accuracy 1.0\n",
      "Step 374200, training accuracy 0.999999940395\n",
      "Step 374300, training accuracy 1.0\n",
      "Step 374400, training accuracy 1.0\n",
      "Step 374500, training accuracy 1.0\n",
      "Step 374600, training accuracy 0.990000009537\n",
      "Step 374700, training accuracy 1.0\n",
      "Step 374800, training accuracy 1.0\n",
      "Step 374900, training accuracy 1.0\n",
      "Step 375000, training accuracy 0.999999940395\n",
      "Step 375100, training accuracy 1.0\n",
      "Step 375200, training accuracy 0.999999940395\n",
      "Step 375300, training accuracy 1.0\n",
      "Step 375400, training accuracy 0.999999940395\n",
      "Step 375500, training accuracy 1.0\n",
      "Step 375600, training accuracy 1.0\n",
      "Step 375700, training accuracy 1.0\n",
      "Step 375800, training accuracy 1.0\n",
      "Step 375900, training accuracy 1.0\n",
      "Step 376000, training accuracy 0.999999940395\n",
      "Step 376100, training accuracy 1.0\n",
      "Step 376200, training accuracy 0.999999940395\n",
      "Step 376300, training accuracy 0.999999940395\n",
      "Step 376400, training accuracy 1.0\n",
      "Step 376500, training accuracy 0.999999940395\n",
      "Step 376600, training accuracy 0.999999940395\n",
      "Step 376700, training accuracy 0.990000009537\n",
      "Step 376800, training accuracy 0.999999940395\n",
      "Step 376900, training accuracy 0.999999940395\n",
      "Step 377000, training accuracy 1.0\n",
      "Step 377100, training accuracy 0.989999949932\n",
      "Step 377200, training accuracy 1.0\n",
      "Step 377300, training accuracy 1.0\n",
      "Step 377400, training accuracy 0.999999940395\n",
      "Step 377500, training accuracy 0.979999959469\n",
      "Step 377600, training accuracy 0.999999940395\n",
      "Step 377700, training accuracy 1.0\n",
      "Step 377800, training accuracy 1.0\n",
      "Step 377900, training accuracy 1.0\n",
      "Step 378000, training accuracy 0.989999949932\n",
      "Step 378100, training accuracy 0.990000009537\n",
      "Step 378200, training accuracy 0.999999940395\n",
      "Step 378300, training accuracy 1.0\n",
      "Step 378400, training accuracy 0.999999940395\n",
      "Step 378500, training accuracy 1.0\n",
      "Step 378600, training accuracy 0.999999940395\n",
      "Step 378700, training accuracy 1.0\n",
      "Step 378800, training accuracy 1.0\n",
      "Step 378900, training accuracy 1.0\n",
      "Step 379000, training accuracy 1.0\n",
      "Step 379100, training accuracy 0.989999949932\n",
      "Step 379200, training accuracy 0.979999959469\n",
      "Step 379300, training accuracy 0.999999940395\n",
      "Step 379400, training accuracy 0.999999940395\n",
      "Step 379500, training accuracy 0.989999949932\n",
      "Step 379600, training accuracy 0.990000009537\n",
      "Step 379700, training accuracy 1.0\n",
      "Step 379800, training accuracy 0.999999940395\n",
      "Step 379900, training accuracy 0.999999940395\n",
      "Step 380000, training accuracy 0.999999940395\n",
      "Step 380100, training accuracy 0.999999940395\n",
      "Step 380200, training accuracy 0.999999940395\n",
      "Step 380300, training accuracy 1.0\n",
      "Step 380400, training accuracy 1.0\n",
      "Step 380500, training accuracy 1.0\n",
      "Step 380600, training accuracy 0.999999940395\n",
      "Step 380700, training accuracy 0.999999940395\n",
      "Step 380800, training accuracy 0.999999940395\n",
      "Step 380900, training accuracy 1.0\n",
      "Step 381000, training accuracy 0.999999940395\n",
      "Step 381100, training accuracy 0.999999940395\n",
      "Step 381200, training accuracy 1.0\n",
      "Step 381300, training accuracy 1.0\n",
      "Step 381400, training accuracy 1.0\n",
      "Step 381500, training accuracy 1.0\n",
      "Step 381600, training accuracy 1.0\n",
      "Step 381700, training accuracy 0.999999940395\n",
      "Step 381800, training accuracy 0.999999940395\n",
      "Step 381900, training accuracy 0.999999940395\n",
      "Step 382000, training accuracy 0.999999940395\n",
      "Step 382100, training accuracy 1.0\n",
      "Step 382200, training accuracy 1.0\n",
      "Step 382300, training accuracy 0.990000009537\n",
      "Step 382400, training accuracy 1.0\n",
      "Step 382500, training accuracy 0.999999940395\n",
      "Step 382600, training accuracy 1.0\n",
      "Step 382700, training accuracy 1.0\n",
      "Step 382800, training accuracy 0.999999940395\n",
      "Step 382900, training accuracy 0.999999940395\n",
      "Step 383000, training accuracy 1.0\n",
      "Step 383100, training accuracy 0.990000009537\n",
      "Step 383200, training accuracy 1.0\n",
      "Step 383300, training accuracy 0.999999940395\n",
      "Step 383400, training accuracy 0.999999940395\n",
      "Step 383500, training accuracy 0.990000009537\n",
      "Step 383600, training accuracy 0.999999940395\n",
      "Step 383700, training accuracy 1.0\n",
      "Step 383800, training accuracy 0.999999940395\n",
      "Step 383900, training accuracy 1.0\n",
      "Step 384000, training accuracy 0.999999940395\n",
      "Step 384100, training accuracy 0.989999949932\n",
      "Step 384200, training accuracy 0.999999940395\n",
      "Step 384300, training accuracy 1.0\n",
      "Step 384400, training accuracy 1.0\n",
      "Step 384500, training accuracy 1.0\n",
      "Step 384600, training accuracy 0.999999940395\n",
      "Step 384700, training accuracy 0.990000009537\n",
      "Step 384800, training accuracy 1.0\n",
      "Step 384900, training accuracy 0.999999940395\n",
      "Step 385000, training accuracy 0.999999940395\n",
      "Step 385100, training accuracy 1.0\n",
      "Step 385200, training accuracy 0.999999940395\n",
      "Step 385300, training accuracy 0.999999940395\n",
      "Step 385400, training accuracy 1.0\n",
      "Step 385500, training accuracy 0.989999949932\n",
      "Step 385600, training accuracy 0.999999940395\n",
      "Step 385700, training accuracy 0.989999949932\n",
      "Step 385800, training accuracy 1.0\n",
      "Step 385900, training accuracy 1.0\n",
      "Step 386000, training accuracy 1.0\n",
      "Step 386100, training accuracy 1.0\n",
      "Step 386200, training accuracy 0.999999940395\n",
      "Step 386300, training accuracy 0.999999940395\n",
      "Step 386400, training accuracy 1.0\n",
      "Step 386500, training accuracy 1.0\n",
      "Step 386600, training accuracy 0.990000009537\n",
      "Step 386700, training accuracy 0.999999940395\n",
      "Step 386800, training accuracy 0.989999949932\n",
      "Step 386900, training accuracy 1.0\n",
      "Step 387000, training accuracy 0.999999940395\n",
      "Step 387100, training accuracy 1.0\n",
      "Step 387200, training accuracy 0.999999940395\n",
      "Step 387300, training accuracy 1.0\n",
      "Step 387400, training accuracy 1.0\n",
      "Step 387500, training accuracy 0.999999940395\n",
      "Step 387600, training accuracy 1.0\n",
      "Step 387700, training accuracy 0.999999940395\n",
      "Step 387800, training accuracy 1.0\n",
      "Step 387900, training accuracy 1.0\n",
      "Step 388000, training accuracy 0.999999940395\n",
      "Step 388100, training accuracy 1.0\n",
      "Step 388200, training accuracy 0.999999940395\n",
      "Step 388300, training accuracy 0.999999940395\n",
      "Step 388400, training accuracy 0.999999940395\n",
      "Step 388500, training accuracy 1.0\n",
      "Step 388600, training accuracy 1.0\n",
      "Step 388700, training accuracy 0.999999940395\n",
      "Step 388800, training accuracy 1.0\n",
      "Step 388900, training accuracy 1.0\n",
      "Step 389000, training accuracy 0.999999940395\n",
      "Step 389100, training accuracy 0.999999940395\n",
      "Step 389200, training accuracy 1.0\n",
      "Step 389300, training accuracy 0.999999940395\n",
      "Step 389400, training accuracy 0.999999940395\n",
      "Step 389500, training accuracy 0.999999940395\n",
      "Step 389600, training accuracy 0.999999940395\n",
      "Step 389700, training accuracy 0.999999940395\n",
      "Step 389800, training accuracy 0.999999940395\n",
      "Step 389900, training accuracy 1.0\n",
      "Step 390000, training accuracy 1.0\n",
      "Step 390100, training accuracy 1.0\n",
      "Step 390200, training accuracy 0.999999940395\n",
      "Step 390300, training accuracy 1.0\n",
      "Step 390400, training accuracy 1.0\n",
      "Step 390500, training accuracy 1.0\n",
      "Step 390600, training accuracy 1.0\n",
      "Step 390700, training accuracy 0.999999940395\n",
      "Step 390800, training accuracy 0.999999940395\n",
      "Step 390900, training accuracy 1.0\n",
      "Step 391000, training accuracy 1.0\n",
      "Step 391100, training accuracy 0.990000009537\n",
      "Step 391200, training accuracy 0.999999940395\n",
      "Step 391300, training accuracy 0.990000009537\n",
      "Step 391400, training accuracy 1.0\n",
      "Step 391500, training accuracy 1.0\n",
      "Step 391600, training accuracy 0.999999940395\n",
      "Step 391700, training accuracy 0.990000009537\n",
      "Step 391800, training accuracy 1.0\n",
      "Step 391900, training accuracy 0.999999940395\n",
      "Step 392000, training accuracy 1.0\n",
      "Step 392100, training accuracy 0.999999940395\n",
      "Step 392200, training accuracy 1.0\n",
      "Step 392300, training accuracy 0.999999940395\n",
      "Step 392400, training accuracy 1.0\n",
      "Step 392500, training accuracy 0.999999940395\n",
      "Step 392600, training accuracy 1.0\n",
      "Step 392700, training accuracy 0.999999940395\n",
      "Step 392800, training accuracy 0.999999940395\n",
      "Step 392900, training accuracy 0.989999949932\n",
      "Step 393000, training accuracy 0.999999940395\n",
      "Step 393100, training accuracy 1.0\n",
      "Step 393200, training accuracy 0.999999940395\n",
      "Step 393300, training accuracy 1.0\n",
      "Step 393400, training accuracy 0.999999940395\n",
      "Step 393500, training accuracy 1.0\n",
      "Step 393600, training accuracy 0.999999940395\n",
      "Step 393700, training accuracy 0.989999949932\n",
      "Step 393800, training accuracy 1.0\n",
      "Step 393900, training accuracy 1.0\n",
      "Step 394000, training accuracy 1.0\n",
      "Step 394100, training accuracy 1.0\n",
      "Step 394200, training accuracy 1.0\n",
      "Step 394300, training accuracy 0.999999940395\n",
      "Step 394400, training accuracy 0.999999940395\n",
      "Step 394500, training accuracy 1.0\n",
      "Step 394600, training accuracy 1.0\n",
      "Step 394700, training accuracy 1.0\n",
      "Step 394800, training accuracy 1.0\n",
      "Step 394900, training accuracy 1.0\n",
      "Step 395000, training accuracy 0.999999940395\n",
      "Step 395100, training accuracy 1.0\n",
      "Step 395200, training accuracy 0.999999940395\n",
      "Step 395300, training accuracy 1.0\n",
      "Step 395400, training accuracy 1.0\n",
      "Step 395500, training accuracy 1.0\n",
      "Step 395600, training accuracy 0.990000009537\n",
      "Step 395700, training accuracy 1.0\n",
      "Step 395800, training accuracy 1.0\n",
      "Step 395900, training accuracy 1.0\n",
      "Step 396000, training accuracy 0.999999940395\n",
      "Step 396100, training accuracy 0.999999940395\n",
      "Step 396200, training accuracy 0.999999940395\n",
      "Step 396300, training accuracy 0.999999940395\n",
      "Step 396400, training accuracy 1.0\n",
      "Step 396500, training accuracy 0.990000009537\n",
      "Step 396600, training accuracy 0.999999940395\n",
      "Step 396700, training accuracy 0.989999949932\n",
      "Step 396800, training accuracy 1.0\n",
      "Step 396900, training accuracy 0.999999940395\n",
      "Step 397000, training accuracy 1.0\n",
      "Step 397100, training accuracy 0.989999949932\n",
      "Step 397200, training accuracy 1.0\n",
      "Step 397300, training accuracy 1.0\n",
      "Step 397400, training accuracy 0.990000009537\n",
      "Step 397500, training accuracy 0.999999940395\n",
      "Step 397600, training accuracy 0.999999940395\n",
      "Step 397700, training accuracy 1.0\n",
      "Step 397800, training accuracy 0.999999940395\n",
      "Step 397900, training accuracy 0.999999940395\n",
      "Step 398000, training accuracy 1.0\n",
      "Step 398100, training accuracy 0.989999949932\n",
      "Step 398200, training accuracy 1.0\n",
      "Step 398300, training accuracy 0.999999940395\n",
      "Step 398400, training accuracy 0.999999940395\n",
      "Step 398500, training accuracy 1.0\n",
      "Step 398600, training accuracy 1.0\n",
      "Step 398700, training accuracy 0.999999940395\n",
      "Step 398800, training accuracy 0.999999940395\n",
      "Step 398900, training accuracy 0.999999940395\n",
      "Step 399000, training accuracy 0.989999949932\n",
      "Step 399100, training accuracy 0.989999949932\n",
      "Step 399200, training accuracy 0.999999940395\n",
      "Step 399300, training accuracy 1.0\n",
      "Step 399400, training accuracy 0.999999940395\n",
      "Step 399500, training accuracy 1.0\n",
      "Step 399600, training accuracy 1.0\n",
      "Step 399700, training accuracy 1.0\n",
      "Step 399800, training accuracy 1.0\n",
      "Step 399900, training accuracy 1.0\n",
      "Step 400000, training accuracy 0.990000009537\n",
      "Step 400100, training accuracy 0.999999940395\n",
      "Step 400200, training accuracy 0.999999940395\n",
      "Step 400300, training accuracy 1.0\n",
      "Step 400400, training accuracy 1.0\n",
      "Step 400500, training accuracy 1.0\n",
      "Step 400600, training accuracy 0.999999940395\n",
      "Step 400700, training accuracy 0.999999940395\n",
      "Step 400800, training accuracy 0.999999940395\n",
      "Step 400900, training accuracy 0.999999940395\n",
      "Step 401000, training accuracy 1.0\n",
      "Step 401100, training accuracy 0.999999940395\n",
      "Step 401200, training accuracy 1.0\n",
      "Step 401300, training accuracy 0.999999940395\n",
      "Step 401400, training accuracy 0.990000009537\n",
      "Step 401500, training accuracy 1.0\n",
      "Step 401600, training accuracy 0.999999940395\n",
      "Step 401700, training accuracy 1.0\n",
      "Step 401800, training accuracy 1.0\n",
      "Step 401900, training accuracy 0.990000009537\n",
      "Step 402000, training accuracy 1.0\n",
      "Step 402100, training accuracy 0.999999940395\n",
      "Step 402200, training accuracy 1.0\n",
      "Step 402300, training accuracy 0.999999940395\n",
      "Step 402400, training accuracy 0.990000009537\n",
      "Step 402500, training accuracy 1.0\n",
      "Step 402600, training accuracy 1.0\n",
      "Step 402700, training accuracy 1.0\n",
      "Step 402800, training accuracy 0.999999940395\n",
      "Step 402900, training accuracy 1.0\n",
      "Step 403000, training accuracy 1.0\n",
      "Step 403100, training accuracy 1.0\n",
      "Step 403200, training accuracy 0.999999940395\n",
      "Step 403300, training accuracy 0.989999949932\n",
      "Step 403400, training accuracy 0.989999949932\n",
      "Step 403500, training accuracy 0.999999940395\n",
      "Step 403600, training accuracy 1.0\n",
      "Step 403700, training accuracy 0.989999949932\n",
      "Step 403800, training accuracy 1.0\n",
      "Step 403900, training accuracy 0.999999940395\n",
      "Step 404000, training accuracy 0.999999940395\n",
      "Step 404100, training accuracy 1.0\n",
      "Step 404200, training accuracy 1.0\n",
      "Step 404300, training accuracy 0.999999940395\n",
      "Step 404400, training accuracy 0.999999940395\n",
      "Step 404500, training accuracy 1.0\n",
      "Step 404600, training accuracy 1.0\n",
      "Step 404700, training accuracy 0.999999940395\n",
      "Step 404800, training accuracy 1.0\n",
      "Step 404900, training accuracy 1.0\n",
      "Step 405000, training accuracy 1.0\n",
      "Step 405100, training accuracy 0.999999940395\n",
      "Step 405200, training accuracy 1.0\n",
      "Step 405300, training accuracy 1.0\n",
      "Step 405400, training accuracy 0.989999949932\n",
      "Step 405500, training accuracy 1.0\n",
      "Step 405600, training accuracy 1.0\n",
      "Step 405700, training accuracy 0.999999940395\n",
      "Step 405800, training accuracy 0.999999940395\n",
      "Step 405900, training accuracy 0.999999940395\n",
      "Step 406000, training accuracy 1.0\n",
      "Step 406100, training accuracy 0.999999940395\n",
      "Step 406200, training accuracy 0.999999940395\n",
      "Step 406300, training accuracy 0.989999949932\n",
      "Step 406400, training accuracy 0.999999940395\n",
      "Step 406500, training accuracy 0.999999940395\n",
      "Step 406600, training accuracy 1.0\n",
      "Step 406700, training accuracy 1.0\n",
      "Step 406800, training accuracy 1.0\n",
      "Step 406900, training accuracy 0.999999940395\n",
      "Step 407000, training accuracy 0.999999940395\n",
      "Step 407100, training accuracy 1.0\n",
      "Step 407200, training accuracy 1.0\n",
      "Step 407300, training accuracy 0.999999940395\n",
      "Step 407400, training accuracy 1.0\n",
      "Step 407500, training accuracy 0.999999940395\n",
      "Step 407600, training accuracy 1.0\n",
      "Step 407700, training accuracy 0.999999940395\n",
      "Step 407800, training accuracy 0.989999949932\n",
      "Step 407900, training accuracy 1.0\n",
      "Step 408000, training accuracy 0.999999940395\n",
      "Step 408100, training accuracy 0.999999940395\n",
      "Step 408200, training accuracy 1.0\n",
      "Step 408300, training accuracy 1.0\n",
      "Step 408400, training accuracy 0.999999940395\n",
      "Step 408500, training accuracy 0.999999940395\n",
      "Step 408600, training accuracy 1.0\n",
      "Step 408700, training accuracy 0.989999949932\n",
      "Step 408800, training accuracy 1.0\n",
      "Step 408900, training accuracy 1.0\n",
      "Step 409000, training accuracy 1.0\n",
      "Step 409100, training accuracy 0.989999949932\n",
      "Step 409200, training accuracy 1.0\n",
      "Step 409300, training accuracy 1.0\n",
      "Step 409400, training accuracy 0.999999940395\n",
      "Step 409500, training accuracy 1.0\n",
      "Step 409600, training accuracy 1.0\n",
      "Step 409700, training accuracy 1.0\n",
      "Step 409800, training accuracy 0.999999940395\n",
      "Step 409900, training accuracy 0.989999949932\n",
      "Step 410000, training accuracy 1.0\n",
      "Step 410100, training accuracy 1.0\n",
      "Step 410200, training accuracy 0.999999940395\n",
      "Step 410300, training accuracy 1.0\n",
      "Step 410400, training accuracy 1.0\n",
      "Step 410500, training accuracy 1.0\n",
      "Step 410600, training accuracy 0.990000009537\n",
      "Step 410700, training accuracy 0.999999940395\n",
      "Step 410800, training accuracy 0.999999940395\n",
      "Step 410900, training accuracy 1.0\n",
      "Step 411000, training accuracy 0.990000009537\n",
      "Step 411100, training accuracy 0.999999940395\n",
      "Step 411200, training accuracy 0.999999940395\n",
      "Step 411300, training accuracy 1.0\n",
      "Step 411400, training accuracy 1.0\n",
      "Step 411500, training accuracy 0.990000009537\n",
      "Step 411600, training accuracy 0.999999940395\n",
      "Step 411700, training accuracy 1.0\n",
      "Step 411800, training accuracy 0.999999940395\n",
      "Step 411900, training accuracy 1.0\n",
      "Step 412000, training accuracy 0.999999940395\n",
      "Step 412100, training accuracy 0.999999940395\n",
      "Step 412200, training accuracy 0.999999940395\n",
      "Step 412300, training accuracy 1.0\n",
      "Step 412400, training accuracy 0.999999940395\n",
      "Step 412500, training accuracy 0.990000009537\n",
      "Step 412600, training accuracy 0.989999949932\n",
      "Step 412700, training accuracy 0.999999940395\n",
      "Step 412800, training accuracy 1.0\n",
      "Step 412900, training accuracy 1.0\n",
      "Step 413000, training accuracy 0.999999940395\n",
      "Step 413100, training accuracy 0.989999949932\n",
      "Step 413200, training accuracy 0.999999940395\n",
      "Step 413300, training accuracy 0.990000009537\n",
      "Step 413400, training accuracy 0.999999940395\n",
      "Step 413500, training accuracy 0.999999940395\n",
      "Step 413600, training accuracy 1.0\n",
      "Step 413700, training accuracy 0.999999940395\n",
      "Step 413800, training accuracy 1.0\n",
      "Step 413900, training accuracy 1.0\n",
      "Step 414000, training accuracy 0.999999940395\n",
      "Step 414100, training accuracy 0.999999940395\n",
      "Step 414200, training accuracy 1.0\n",
      "Step 414300, training accuracy 0.999999940395\n",
      "Step 414400, training accuracy 1.0\n",
      "Step 414500, training accuracy 0.999999940395\n",
      "Step 414600, training accuracy 0.999999940395\n",
      "Step 414700, training accuracy 0.999999940395\n",
      "Step 414800, training accuracy 1.0\n",
      "Step 414900, training accuracy 1.0\n",
      "Step 415000, training accuracy 1.0\n",
      "Step 415100, training accuracy 0.989999949932\n",
      "Step 415200, training accuracy 1.0\n",
      "Step 415300, training accuracy 1.0\n",
      "Step 415400, training accuracy 1.0\n",
      "Step 415500, training accuracy 1.0\n",
      "Step 415600, training accuracy 0.999999940395\n",
      "Step 415700, training accuracy 1.0\n",
      "Step 415800, training accuracy 1.0\n",
      "Step 415900, training accuracy 0.999999940395\n",
      "Step 416000, training accuracy 0.999999940395\n",
      "Step 416100, training accuracy 0.999999940395\n",
      "Step 416200, training accuracy 0.999999940395\n",
      "Step 416300, training accuracy 1.0\n",
      "Step 416400, training accuracy 1.0\n",
      "Step 416500, training accuracy 0.999999940395\n",
      "Step 416600, training accuracy 0.999999940395\n",
      "Step 416700, training accuracy 1.0\n",
      "Step 416800, training accuracy 0.990000009537\n",
      "Step 416900, training accuracy 1.0\n",
      "Step 417000, training accuracy 0.980000019073\n",
      "Step 417100, training accuracy 0.999999940395\n",
      "Step 417200, training accuracy 0.999999940395\n",
      "Step 417300, training accuracy 0.999999940395\n",
      "Step 417400, training accuracy 0.999999940395\n",
      "Step 417500, training accuracy 0.999999940395\n",
      "Step 417600, training accuracy 0.999999940395\n",
      "Step 417700, training accuracy 0.999999940395\n",
      "Step 417800, training accuracy 1.0\n",
      "Step 417900, training accuracy 0.999999940395\n",
      "Step 418000, training accuracy 0.999999940395\n",
      "Step 418100, training accuracy 0.999999940395\n",
      "Step 418200, training accuracy 0.999999940395\n",
      "Step 418300, training accuracy 0.999999940395\n",
      "Step 418400, training accuracy 0.989999949932\n",
      "Step 418500, training accuracy 0.999999940395\n",
      "Step 418600, training accuracy 1.0\n",
      "Step 418700, training accuracy 0.999999940395\n",
      "Step 418800, training accuracy 1.0\n",
      "Step 418900, training accuracy 0.999999940395\n",
      "Step 419000, training accuracy 1.0\n",
      "Step 419100, training accuracy 0.999999940395\n",
      "Step 419200, training accuracy 1.0\n",
      "Step 419300, training accuracy 1.0\n",
      "Step 419400, training accuracy 0.999999940395\n",
      "Step 419500, training accuracy 1.0\n",
      "Step 419600, training accuracy 1.0\n",
      "Step 419700, training accuracy 0.969999969006\n",
      "Step 419800, training accuracy 1.0\n",
      "Step 419900, training accuracy 0.999999940395\n",
      "Step 420000, training accuracy 0.999999940395\n",
      "Step 420100, training accuracy 0.999999940395\n",
      "Step 420200, training accuracy 0.999999940395\n",
      "Step 420300, training accuracy 0.999999940395\n",
      "Step 420400, training accuracy 1.0\n",
      "Step 420500, training accuracy 0.999999940395\n",
      "Step 420600, training accuracy 1.0\n",
      "Step 420700, training accuracy 1.0\n",
      "Step 420800, training accuracy 0.999999940395\n",
      "Step 420900, training accuracy 0.989999949932\n",
      "Step 421000, training accuracy 0.999999940395\n",
      "Step 421100, training accuracy 0.999999940395\n",
      "Step 421200, training accuracy 1.0\n",
      "Step 421300, training accuracy 0.999999940395\n",
      "Step 421400, training accuracy 0.979999959469\n",
      "Step 421500, training accuracy 1.0\n",
      "Step 421600, training accuracy 0.999999940395\n",
      "Step 421700, training accuracy 0.999999940395\n",
      "Step 421800, training accuracy 0.999999940395\n",
      "Step 421900, training accuracy 0.999999940395\n",
      "Step 422000, training accuracy 0.999999940395\n",
      "Step 422100, training accuracy 0.999999940395\n",
      "Step 422200, training accuracy 1.0\n",
      "Step 422300, training accuracy 0.999999940395\n",
      "Step 422400, training accuracy 0.999999940395\n",
      "Step 422500, training accuracy 0.999999940395\n",
      "Step 422600, training accuracy 0.999999940395\n",
      "Step 422700, training accuracy 0.999999940395\n",
      "Step 422800, training accuracy 1.0\n",
      "Step 422900, training accuracy 0.999999940395\n",
      "Step 423000, training accuracy 0.989999949932\n",
      "Step 423100, training accuracy 1.0\n",
      "Step 423200, training accuracy 0.999999940395\n",
      "Step 423300, training accuracy 0.999999940395\n",
      "Step 423400, training accuracy 0.990000009537\n",
      "Step 423500, training accuracy 0.999999940395\n",
      "Step 423600, training accuracy 1.0\n",
      "Step 423700, training accuracy 0.999999940395\n",
      "Step 423800, training accuracy 0.999999940395\n",
      "Step 423900, training accuracy 0.999999940395\n",
      "Step 424000, training accuracy 0.999999940395\n",
      "Step 424100, training accuracy 0.999999940395\n",
      "Step 424200, training accuracy 1.0\n",
      "Step 424300, training accuracy 0.999999940395\n",
      "Step 424400, training accuracy 0.999999940395\n",
      "Step 424500, training accuracy 1.0\n",
      "Step 424600, training accuracy 0.999999940395\n",
      "Step 424700, training accuracy 0.980000019073\n",
      "Step 424800, training accuracy 0.989999949932\n",
      "Step 424900, training accuracy 0.989999949932\n",
      "Step 425000, training accuracy 0.990000009537\n",
      "Step 425100, training accuracy 1.0\n",
      "Step 425200, training accuracy 0.989999949932\n",
      "Step 425300, training accuracy 1.0\n",
      "Step 425400, training accuracy 1.0\n",
      "Step 425500, training accuracy 1.0\n",
      "Step 425600, training accuracy 0.980000019073\n",
      "Step 425700, training accuracy 0.999999940395\n",
      "Step 425800, training accuracy 1.0\n",
      "Step 425900, training accuracy 0.999999940395\n",
      "Step 426000, training accuracy 0.999999940395\n",
      "Step 426100, training accuracy 1.0\n",
      "Step 426200, training accuracy 1.0\n",
      "Step 426300, training accuracy 0.999999940395\n",
      "Step 426400, training accuracy 1.0\n",
      "Step 426500, training accuracy 0.980000019073\n",
      "Step 426600, training accuracy 0.999999940395\n",
      "Step 426700, training accuracy 0.999999940395\n",
      "Step 426800, training accuracy 1.0\n",
      "Step 426900, training accuracy 0.999999940395\n",
      "Step 427000, training accuracy 1.0\n",
      "Step 427100, training accuracy 1.0\n",
      "Step 427200, training accuracy 1.0\n",
      "Step 427300, training accuracy 0.989999949932\n",
      "Step 427400, training accuracy 0.990000009537\n",
      "Step 427500, training accuracy 0.999999940395\n",
      "Step 427600, training accuracy 1.0\n",
      "Step 427700, training accuracy 0.999999940395\n",
      "Step 427800, training accuracy 0.999999940395\n",
      "Step 427900, training accuracy 0.999999940395\n",
      "Step 428000, training accuracy 1.0\n",
      "Step 428100, training accuracy 0.999999940395\n",
      "Step 428200, training accuracy 0.999999940395\n",
      "Step 428300, training accuracy 1.0\n",
      "Step 428400, training accuracy 1.0\n",
      "Step 428500, training accuracy 1.0\n",
      "Step 428600, training accuracy 0.999999940395\n",
      "Step 428700, training accuracy 1.0\n",
      "Step 428800, training accuracy 1.0\n",
      "Step 428900, training accuracy 1.0\n",
      "Step 429000, training accuracy 0.999999940395\n",
      "Step 429100, training accuracy 0.999999940395\n",
      "Step 429200, training accuracy 0.999999940395\n",
      "Step 429300, training accuracy 0.999999940395\n",
      "Step 429400, training accuracy 1.0\n",
      "Step 429500, training accuracy 0.999999940395\n",
      "Step 429600, training accuracy 0.999999940395\n",
      "Step 429700, training accuracy 1.0\n",
      "Step 429800, training accuracy 0.999999940395\n",
      "Step 429900, training accuracy 1.0\n",
      "Step 430000, training accuracy 0.989999949932\n",
      "Step 430100, training accuracy 0.999999940395\n",
      "Step 430200, training accuracy 1.0\n",
      "Step 430300, training accuracy 1.0\n",
      "Step 430400, training accuracy 0.990000009537\n",
      "Step 430500, training accuracy 1.0\n",
      "Step 430600, training accuracy 1.0\n",
      "Step 430700, training accuracy 0.999999940395\n",
      "Step 430800, training accuracy 0.999999940395\n",
      "Step 430900, training accuracy 1.0\n",
      "Step 431000, training accuracy 1.0\n",
      "Step 431100, training accuracy 0.999999940395\n",
      "Step 431200, training accuracy 1.0\n",
      "Step 431300, training accuracy 1.0\n",
      "Step 431400, training accuracy 0.999999940395\n",
      "Step 431500, training accuracy 1.0\n",
      "Step 431600, training accuracy 1.0\n",
      "Step 431700, training accuracy 1.0\n",
      "Step 431800, training accuracy 0.990000009537\n",
      "Step 431900, training accuracy 0.990000009537\n",
      "Step 432000, training accuracy 0.999999940395\n",
      "Step 432100, training accuracy 1.0\n",
      "Step 432200, training accuracy 1.0\n",
      "Step 432300, training accuracy 1.0\n",
      "Step 432400, training accuracy 1.0\n",
      "Step 432500, training accuracy 0.989999949932\n",
      "Step 432600, training accuracy 0.999999940395\n",
      "Step 432700, training accuracy 0.999999940395\n",
      "Step 432800, training accuracy 1.0\n",
      "Step 432900, training accuracy 0.999999940395\n",
      "Step 433000, training accuracy 1.0\n",
      "Step 433100, training accuracy 1.0\n",
      "Step 433200, training accuracy 0.999999940395\n",
      "Step 433300, training accuracy 0.999999940395\n",
      "Step 433400, training accuracy 0.999999940395\n",
      "Step 433500, training accuracy 1.0\n",
      "Step 433600, training accuracy 0.999999940395\n",
      "Step 433700, training accuracy 0.999999940395\n",
      "Step 433800, training accuracy 1.0\n",
      "Step 433900, training accuracy 1.0\n",
      "Step 434000, training accuracy 0.999999940395\n",
      "Step 434100, training accuracy 0.999999940395\n",
      "Step 434200, training accuracy 1.0\n",
      "Step 434300, training accuracy 0.999999940395\n",
      "Step 434400, training accuracy 1.0\n",
      "Step 434500, training accuracy 1.0\n",
      "Step 434600, training accuracy 0.999999940395\n",
      "Step 434700, training accuracy 1.0\n",
      "Step 434800, training accuracy 0.990000009537\n",
      "Step 434900, training accuracy 0.999999940395\n",
      "Step 435000, training accuracy 0.999999940395\n",
      "Step 435100, training accuracy 0.999999940395\n",
      "Step 435200, training accuracy 1.0\n",
      "Step 435300, training accuracy 0.999999940395\n",
      "Step 435400, training accuracy 0.999999940395\n",
      "Step 435500, training accuracy 0.999999940395\n",
      "Step 435600, training accuracy 1.0\n",
      "Step 435700, training accuracy 0.999999940395\n",
      "Step 435800, training accuracy 0.999999940395\n",
      "Step 435900, training accuracy 1.0\n",
      "Step 436000, training accuracy 1.0\n",
      "Step 436100, training accuracy 0.999999940395\n",
      "Step 436200, training accuracy 0.999999940395\n",
      "Step 436300, training accuracy 0.999999940395\n",
      "Step 436400, training accuracy 1.0\n",
      "Step 436500, training accuracy 1.0\n",
      "Step 436600, training accuracy 0.999999940395\n",
      "Step 436700, training accuracy 0.999999940395\n",
      "Step 436800, training accuracy 1.0\n",
      "Step 436900, training accuracy 1.0\n",
      "Step 437000, training accuracy 1.0\n",
      "Step 437100, training accuracy 1.0\n",
      "Step 437200, training accuracy 0.990000009537\n",
      "Step 437300, training accuracy 0.989999949932\n",
      "Step 437400, training accuracy 0.999999940395\n",
      "Step 437500, training accuracy 0.999999940395\n",
      "Step 437600, training accuracy 0.990000009537\n",
      "Step 437700, training accuracy 1.0\n",
      "Step 437800, training accuracy 1.0\n",
      "Step 437900, training accuracy 0.989999949932\n",
      "Step 438000, training accuracy 0.999999940395\n",
      "Step 438100, training accuracy 0.999999940395\n",
      "Step 438200, training accuracy 1.0\n",
      "Step 438300, training accuracy 1.0\n",
      "Step 438400, training accuracy 1.0\n",
      "Step 438500, training accuracy 1.0\n",
      "Step 438600, training accuracy 1.0\n",
      "Step 438700, training accuracy 1.0\n",
      "Step 438800, training accuracy 1.0\n",
      "Step 438900, training accuracy 0.999999940395\n",
      "Step 439000, training accuracy 0.990000009537\n",
      "Step 439100, training accuracy 1.0\n",
      "Step 439200, training accuracy 0.999999940395\n",
      "Step 439300, training accuracy 1.0\n",
      "Step 439400, training accuracy 1.0\n",
      "Step 439500, training accuracy 0.999999940395\n",
      "Step 439600, training accuracy 0.999999940395\n",
      "Step 439700, training accuracy 0.999999940395\n",
      "Step 439800, training accuracy 0.999999940395\n",
      "Step 439900, training accuracy 0.999999940395\n",
      "Step 440000, training accuracy 1.0\n",
      "Step 440100, training accuracy 0.999999940395\n",
      "Step 440200, training accuracy 1.0\n",
      "Step 440300, training accuracy 0.990000009537\n",
      "Step 440400, training accuracy 1.0\n",
      "Step 440500, training accuracy 0.999999940395\n",
      "Step 440600, training accuracy 0.999999940395\n",
      "Step 440700, training accuracy 1.0\n",
      "Step 440800, training accuracy 0.999999940395\n",
      "Step 440900, training accuracy 1.0\n",
      "Step 441000, training accuracy 0.999999940395\n",
      "Step 441100, training accuracy 0.999999940395\n",
      "Step 441200, training accuracy 1.0\n",
      "Step 441300, training accuracy 0.999999940395\n",
      "Step 441400, training accuracy 0.999999940395\n",
      "Step 441500, training accuracy 0.990000009537\n",
      "Step 441600, training accuracy 0.999999940395\n",
      "Step 441700, training accuracy 0.989999949932\n",
      "Step 441800, training accuracy 0.999999940395\n",
      "Step 441900, training accuracy 1.0\n",
      "Step 442000, training accuracy 0.999999940395\n",
      "Step 442100, training accuracy 0.999999940395\n",
      "Step 442200, training accuracy 0.999999940395\n",
      "Step 442300, training accuracy 1.0\n",
      "Step 442400, training accuracy 0.999999940395\n",
      "Step 442500, training accuracy 0.999999940395\n",
      "Step 442600, training accuracy 0.999999940395\n",
      "Step 442700, training accuracy 1.0\n",
      "Step 442800, training accuracy 0.999999940395\n",
      "Step 442900, training accuracy 0.990000009537\n",
      "Step 443000, training accuracy 0.999999940395\n",
      "Step 443100, training accuracy 0.989999949932\n",
      "Step 443200, training accuracy 1.0\n",
      "Step 443300, training accuracy 1.0\n",
      "Step 443400, training accuracy 0.999999940395\n",
      "Step 443500, training accuracy 1.0\n",
      "Step 443600, training accuracy 1.0\n",
      "Step 443700, training accuracy 1.0\n",
      "Step 443800, training accuracy 1.0\n",
      "Step 443900, training accuracy 0.989999949932\n",
      "Step 444000, training accuracy 1.0\n",
      "Step 444100, training accuracy 0.999999940395\n",
      "Step 444200, training accuracy 1.0\n",
      "Step 444300, training accuracy 0.999999940395\n",
      "Step 444400, training accuracy 1.0\n",
      "Step 444500, training accuracy 1.0\n",
      "Step 444600, training accuracy 1.0\n",
      "Step 444700, training accuracy 0.999999940395\n",
      "Step 444800, training accuracy 1.0\n",
      "Step 444900, training accuracy 0.999999940395\n",
      "Step 445000, training accuracy 0.990000009537\n",
      "Step 445100, training accuracy 1.0\n",
      "Step 445200, training accuracy 1.0\n",
      "Step 445300, training accuracy 1.0\n",
      "Step 445400, training accuracy 0.999999940395\n",
      "Step 445500, training accuracy 0.999999940395\n",
      "Step 445600, training accuracy 0.999999940395\n",
      "Step 445700, training accuracy 0.999999940395\n",
      "Step 445800, training accuracy 0.989999949932\n",
      "Step 445900, training accuracy 0.999999940395\n",
      "Step 446000, training accuracy 1.0\n",
      "Step 446100, training accuracy 0.999999940395\n",
      "Step 446200, training accuracy 0.990000009537\n",
      "Step 446300, training accuracy 1.0\n",
      "Step 446400, training accuracy 0.999999940395\n",
      "Step 446500, training accuracy 0.999999940395\n",
      "Step 446600, training accuracy 1.0\n",
      "Step 446700, training accuracy 1.0\n",
      "Step 446800, training accuracy 1.0\n",
      "Step 446900, training accuracy 0.999999940395\n",
      "Step 447000, training accuracy 1.0\n",
      "Step 447100, training accuracy 0.999999940395\n",
      "Step 447200, training accuracy 0.999999940395\n",
      "Step 447300, training accuracy 0.999999940395\n",
      "Step 447400, training accuracy 1.0\n",
      "Step 447500, training accuracy 0.999999940395\n",
      "Step 447600, training accuracy 1.0\n",
      "Step 447700, training accuracy 0.999999940395\n",
      "Step 447800, training accuracy 1.0\n",
      "Step 447900, training accuracy 1.0\n",
      "Step 448000, training accuracy 0.999999940395\n",
      "Step 448100, training accuracy 1.0\n",
      "Step 448200, training accuracy 1.0\n",
      "Step 448300, training accuracy 0.999999940395\n",
      "Step 448400, training accuracy 1.0\n",
      "Step 448500, training accuracy 0.999999940395\n",
      "Step 448600, training accuracy 1.0\n",
      "Step 448700, training accuracy 0.990000009537\n",
      "Step 448800, training accuracy 0.999999940395\n",
      "Step 448900, training accuracy 0.999999940395\n",
      "Step 449000, training accuracy 1.0\n",
      "Step 449100, training accuracy 1.0\n",
      "Step 449200, training accuracy 0.999999940395\n",
      "Step 449300, training accuracy 0.999999940395\n",
      "Step 449400, training accuracy 0.999999940395\n",
      "Step 449500, training accuracy 0.990000009537\n",
      "Step 449600, training accuracy 0.999999940395\n",
      "Step 449700, training accuracy 0.999999940395\n",
      "Step 449800, training accuracy 0.999999940395\n",
      "Step 449900, training accuracy 1.0\n",
      "Step 450000, training accuracy 1.0\n",
      "Step 450100, training accuracy 1.0\n",
      "Step 450200, training accuracy 1.0\n",
      "Step 450300, training accuracy 1.0\n",
      "Step 450400, training accuracy 1.0\n",
      "Step 450500, training accuracy 1.0\n",
      "Step 450600, training accuracy 0.999999940395\n",
      "Step 450700, training accuracy 1.0\n",
      "Step 450800, training accuracy 0.999999940395\n",
      "Step 450900, training accuracy 1.0\n",
      "Step 451000, training accuracy 1.0\n",
      "Step 451100, training accuracy 1.0\n",
      "Step 451200, training accuracy 0.999999940395\n",
      "Step 451300, training accuracy 0.999999940395\n",
      "Step 451400, training accuracy 1.0\n",
      "Step 451500, training accuracy 0.999999940395\n",
      "Step 451600, training accuracy 0.999999940395\n",
      "Step 451700, training accuracy 1.0\n",
      "Step 451800, training accuracy 1.0\n",
      "Step 451900, training accuracy 1.0\n",
      "Step 452000, training accuracy 1.0\n",
      "Step 452100, training accuracy 0.999999940395\n",
      "Step 452200, training accuracy 0.999999940395\n",
      "Step 452300, training accuracy 0.999999940395\n",
      "Step 452400, training accuracy 0.999999940395\n",
      "Step 452500, training accuracy 1.0\n",
      "Step 452600, training accuracy 1.0\n",
      "Step 452700, training accuracy 0.999999940395\n",
      "Step 452800, training accuracy 0.990000009537\n",
      "Step 452900, training accuracy 1.0\n",
      "Step 453000, training accuracy 0.999999940395\n",
      "Step 453100, training accuracy 0.999999940395\n",
      "Step 453200, training accuracy 0.990000009537\n",
      "Step 453300, training accuracy 1.0\n",
      "Step 453400, training accuracy 1.0\n",
      "Step 453500, training accuracy 0.999999940395\n",
      "Step 453600, training accuracy 0.999999940395\n",
      "Step 453700, training accuracy 0.999999940395\n",
      "Step 453800, training accuracy 1.0\n",
      "Step 453900, training accuracy 0.989999949932\n",
      "Step 454000, training accuracy 1.0\n",
      "Step 454100, training accuracy 0.989999949932\n",
      "Step 454200, training accuracy 0.999999940395\n",
      "Step 454300, training accuracy 0.999999940395\n",
      "Step 454400, training accuracy 1.0\n",
      "Step 454500, training accuracy 0.999999940395\n",
      "Step 454600, training accuracy 0.999999940395\n",
      "Step 454700, training accuracy 1.0\n",
      "Step 454800, training accuracy 0.999999940395\n",
      "Step 454900, training accuracy 0.999999940395\n",
      "Step 455000, training accuracy 0.999999940395\n",
      "Step 455100, training accuracy 0.999999940395\n",
      "Step 455200, training accuracy 1.0\n",
      "Step 455300, training accuracy 1.0\n",
      "Step 455400, training accuracy 1.0\n",
      "Step 455500, training accuracy 0.999999940395\n",
      "Step 455600, training accuracy 1.0\n",
      "Step 455700, training accuracy 1.0\n",
      "Step 455800, training accuracy 0.990000009537\n",
      "Step 455900, training accuracy 0.999999940395\n",
      "Step 456000, training accuracy 1.0\n",
      "Step 456100, training accuracy 0.999999940395\n",
      "Step 456200, training accuracy 1.0\n",
      "Step 456300, training accuracy 1.0\n",
      "Step 456400, training accuracy 0.999999940395\n",
      "Step 456500, training accuracy 0.999999940395\n",
      "Step 456600, training accuracy 0.999999940395\n",
      "Step 456700, training accuracy 1.0\n",
      "Step 456800, training accuracy 0.999999940395\n",
      "Step 456900, training accuracy 1.0\n",
      "Step 457000, training accuracy 0.999999940395\n",
      "Step 457100, training accuracy 1.0\n",
      "Step 457200, training accuracy 0.999999940395\n",
      "Step 457300, training accuracy 0.999999940395\n",
      "Step 457400, training accuracy 0.999999940395\n",
      "Step 457500, training accuracy 0.999999940395\n",
      "Step 457600, training accuracy 1.0\n",
      "Step 457700, training accuracy 1.0\n",
      "Step 457800, training accuracy 1.0\n",
      "Step 457900, training accuracy 1.0\n",
      "Step 458000, training accuracy 1.0\n",
      "Step 458100, training accuracy 0.999999940395\n",
      "Step 458200, training accuracy 0.990000009537\n",
      "Step 458300, training accuracy 1.0\n",
      "Step 458400, training accuracy 1.0\n",
      "Step 458500, training accuracy 1.0\n",
      "Step 458600, training accuracy 1.0\n",
      "Step 458700, training accuracy 0.999999940395\n",
      "Step 458800, training accuracy 1.0\n",
      "Step 458900, training accuracy 0.999999940395\n",
      "Step 459000, training accuracy 1.0\n",
      "Step 459100, training accuracy 0.989999949932\n",
      "Step 459200, training accuracy 1.0\n",
      "Step 459300, training accuracy 0.999999940395\n",
      "Step 459400, training accuracy 1.0\n",
      "Step 459500, training accuracy 1.0\n",
      "Step 459600, training accuracy 1.0\n",
      "Step 459700, training accuracy 0.999999940395\n",
      "Step 459800, training accuracy 1.0\n",
      "Step 459900, training accuracy 0.999999940395\n",
      "Step 460000, training accuracy 0.999999940395\n",
      "Step 460100, training accuracy 1.0\n",
      "Step 460200, training accuracy 1.0\n",
      "Step 460300, training accuracy 1.0\n",
      "Step 460400, training accuracy 0.990000009537\n",
      "Step 460500, training accuracy 0.999999940395\n",
      "Step 460600, training accuracy 1.0\n",
      "Step 460700, training accuracy 1.0\n",
      "Step 460800, training accuracy 1.0\n",
      "Step 460900, training accuracy 1.0\n",
      "Step 461000, training accuracy 0.999999940395\n",
      "Step 461100, training accuracy 0.999999940395\n",
      "Step 461200, training accuracy 1.0\n",
      "Step 461300, training accuracy 0.999999940395\n",
      "Step 461400, training accuracy 1.0\n",
      "Step 461500, training accuracy 1.0\n",
      "Step 461600, training accuracy 0.999999940395\n",
      "Step 461700, training accuracy 1.0\n",
      "Step 461800, training accuracy 1.0\n",
      "Step 461900, training accuracy 0.999999940395\n",
      "Step 462000, training accuracy 0.990000009537\n",
      "Step 462100, training accuracy 1.0\n",
      "Step 462200, training accuracy 0.999999940395\n",
      "Step 462300, training accuracy 1.0\n",
      "Step 462400, training accuracy 0.989999949932\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7fb77fe069b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmysvhn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kien/anaconda2/envs/tf2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 718\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    719\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kien/anaconda2/envs/tf2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 916\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    917\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kien/anaconda2/envs/tf2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 966\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    967\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/kien/anaconda2/envs/tf2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    971\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kien/anaconda2/envs/tf2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    953\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    954\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "for i in xrange(500000):\n",
    "    batch = mysvhn.get_next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x:batch[0], y_:batch[1], keep_prob:0.5})\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_:batch[1], keep_prob:1.0})\n",
    "        summary, acc = sess.run([merged, accuracy], feed_dict={x:batch[0], y_:batch[1], keep_prob:1.0})\n",
    "        writer.add_summary(summary, i)\n",
    "        print \"Step {}, training accuracy {}\".format(i, train_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    }
   ],
   "source": [
    "# save_path = saver.save(sess, \"variables/CNN_500000.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp accuracy 0.9\n",
      "temp accuracy 0.87\n",
      "temp accuracy 0.81\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.89\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.85\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.86\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.88\n",
      "temp accuracy 0.87\n",
      "temp accuracy 0.86\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.96\n",
      "temp accuracy 0.88\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.89\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.88\n",
      "temp accuracy 0.86\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.89\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.98\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.97\n",
      "temp accuracy 0.89\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.87\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.89\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.89\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.85\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.96\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.88\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.84\n",
      "temp accuracy 0.96\n",
      "temp accuracy 0.82\n",
      "temp accuracy 0.86\n",
      "temp accuracy 0.95\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.97\n",
      "temp accuracy 0.86\n",
      "temp accuracy 0.89\n",
      "temp accuracy 0.89\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.86\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.87\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.95\n",
      "temp accuracy 0.83\n",
      "temp accuracy 0.81\n",
      "temp accuracy 0.87\n",
      "temp accuracy 0.95\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.95\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.89\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.84\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.89\n",
      "temp accuracy 0.89\n",
      "temp accuracy 0.89\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.86\n",
      "temp accuracy 0.88\n",
      "temp accuracy 0.86\n",
      "temp accuracy 0.89\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.96\n",
      "temp accuracy 0.88\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.96\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.89\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.87\n",
      "temp accuracy 0.88\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.89\n",
      "temp accuracy 0.83\n",
      "temp accuracy 0.88\n",
      "temp accuracy 0.89\n",
      "temp accuracy 0.84\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.97\n",
      "temp accuracy 0.88\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.88\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.89\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.89\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.88\n",
      "temp accuracy 0.88\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.88\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.83\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.88\n",
      "temp accuracy 0.85\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.96\n",
      "temp accuracy 0.85\n",
      "temp accuracy 0.86\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.86\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.88\n",
      "temp accuracy 0.88\n",
      "temp accuracy 0.87\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.88\n",
      "temp accuracy 0.86\n",
      "temp accuracy 0.88\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.95\n",
      "temp accuracy 0.85\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.87\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.82\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.89\n",
      "temp accuracy 0.82\n",
      "temp accuracy 0.88\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.85\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.89\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.87\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.97\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.89\n",
      "temp accuracy 0.83\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.89\n",
      "temp accuracy 0.84\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.89\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.89\n",
      "temp accuracy 0.88\n",
      "temp accuracy 0.88\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.86\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.88\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.88\n",
      "temp accuracy 0.83\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.95\n",
      "temp accuracy 0.9\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.97\n",
      "temp accuracy 0.87\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.95\n",
      "temp accuracy 0.82\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.84\n",
      "temp accuracy 0.94\n",
      "temp accuracy 0.92\n",
      "temp accuracy 0.93\n",
      "temp accuracy 0.96\n",
      "temp accuracy 0.91\n",
      "temp accuracy 0.96875\n"
     ]
    }
   ],
   "source": [
    "# Test cell\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# test_img = mnist.test.images\n",
    "# test_label = mnist.test.labels\n",
    "# print test_img.shape\n",
    "\n",
    "# res = tf.pack(tf.argmax(y_h,1), tf.argmax(y_,1))\n",
    "confusion = np.zeros([10,10], int)\n",
    "saver.restore(sess, \"variables/CNN_500000.ckpt\")\n",
    "temp_accuracy = []\n",
    "predicted = tf.argmax(y_h,1)\n",
    "temp_result = []\n",
    "for i in xrange(0,test_processed.shape[0],100):\n",
    "    top = min(ytest.shape[0], i+100)\n",
    "    temp = accuracy.eval(feed_dict={x: test_processed[i:top,:], y_: ytest[i:top,:], \n",
    "                                    keep_prob: 1.0})\n",
    "    temp_accuracy.append(temp)\n",
    "    print(\"temp accuracy %g\"%temp)\n",
    "#     ans = res.eval(feed_dict={x: test_img[i:i+100,:], y_: test_label[i:i+100], \n",
    "#                                     keep_prob: 1.0})\n",
    "#     for p in ans.T:\n",
    "#         confusion[p[0], p[1]]+=1\n",
    "    temp_result.append(predicted.eval(feed_dict={x:test_processed[i:i+100,:], y_: ytest[i:i+100,:], \n",
    "                                    keep_prob: 1.0}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy 0.904324710369\n",
      "Confusion matrix \n",
      "[[ 94.86   0.82   0.71   1.06   0.18   0.16   1.27   0.27   0.12   0.55]\n",
      " [  1.01  93.25   1.88   0.7    0.65   0.1    1.42   0.39   0.41   0.19]\n",
      " [  3.09   2.29  86.26   0.49   2.6    0.66   0.66   1.25   2.46   0.24]\n",
      " [  3.33   1.59   0.75  92.07   0.36   0.36   0.24   0.36   0.59   0.36]\n",
      " [  1.01   0.84   3.78   0.63  89.3    1.76   0.38   0.84   1.22   0.25]\n",
      " [  1.37   0.51   1.47   1.42   2.23  88.01   0.56   1.97   0.51   1.97]\n",
      " [  5.15   1.83   0.99   0.2    0.59   0.15  90.49   0.1    0.25   0.25]\n",
      " [  1.2    0.9    3.01   0.84   1.81   5.42   0.42  81.93   3.25   1.2 ]\n",
      " [  1.07   3.32   1.32   0.82   1.69   0.25   0.75   1.07  87.96   1.76]\n",
      " [  1.66   1.61   1.26   0.29   0.23   2.41   0.52   0.52   1.89  89.62]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAasAAAGDCAYAAACV7j82AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3Xu8HVV5//HPNychEDWiYrgpoNwVBAmCFIFiUBQLQvlV\nwQsKhSoKUrSCKAgCWkq5BBSsVASFGhqwiLQIykUKyKUkGEQCiiSEWxLCJYlJIOSc5/fHmp3s7JzL\nnn3OPjP7zPf9es0r2XNbz76ceWatWbNGEYGZmVmZjSo6ADMzs4E4WZmZWek5WZmZWek5WZmZWek5\nWZmZWek5WZmZWek5WZmZWek5WZmZWek5WZmZWek5WZWApC0k/UrSS5K6JR0wxPvfVFKPpMOGcr8j\ngaTZkn5UQLmvkfRDSc9m3815LezjtGzbN7Yjxpyx7JXFsmeBMfRI+mbDvJ0l3SXpL9nf1rtqn1tR\ncVprRhcdQFlIejtwIrAPsBGwHPg9MBW4JCJebmPxPwE2Bb4OvATc34YyRvS4WpK2BT4GXBYRc3Js\n2kMxn803gMOA04HHgZl9rSjpJODhiLiuYVFQru+16FhW+zwkjQauAZYC/5j9+0S2jpNVh3GyAiTt\nB1wNvExKHA8BawHvA84G3gF8vk1ljwV2Bc6MiIvbUUZEPCFpHeDVduy/JN4BnArcBuRJVltTzIFr\nb+CeiDiziXW/Tvp9NiYrW906wIq615sDmwB/HxGX1WZKOgP452GOzQap8slK0mbAVcAs4P0RMb9u\n8fclnQJ8pI0hrA8IWNjGMoiI5e3cfwmIHGf2ktaOiJcjoqgEPgH4Q0Flj0i9/MbXz/5d2LBeD6nl\nZEhIWicilg3V/qwPEVHpCfg+0A3s2uT6XcApwGOkmtgs4ExgrYb1ZgO/AHYH7gWWAX8GPl23zqmk\ns/ru7N8e4PFs2eXArF7KPw3oaZj3AeAO4EVgMfAI8O265Ztm+z6sYbv3Z9v9Jdv258A2vZVHOku9\nPFvvJeBHwNpNfF6/AR4Ets/+vwT4E3Bwtnwv4B5SE80jwKSG7TcBLs6WLQUWkJpmN61b5zO9fI7d\nwJ4N38UHgf/Lvrcv1S37Ud2+bgXmA+vVzRtDahL+E7DOAO/3zcClwNzsO/9d/eeevd/eYt2kj/01\nrttTizf7/XQ3+90AnyI1MS8FngemAG9p8ne/Ufa+ns4+v8ez72V03fta+Zln894H/Cep6e1lUo33\nvMbYSEnlMuDJbL1nSL/FTerW2Rm4CXgui/9x4NJePqtvZv+/rJfP7ta+/oaa/XxY9XveCfhf0u/5\nvOE+blVxqnzNCvgbUoK4t8n1LyVda5gKnENqwvs6sC1wcN16AWxJar65lHQwOQK4TNL9ETET+Bnp\nADMZ+ClwAylx1LbvrabQ2C7/DuB60kHxFOAVYAvgr/p7E5L2ycr7M+mgtw7wJeBOSTvFqus+tbKm\nkg4QXyP9oR4JzANO6q+cbPs3ZjFele3naGCKpE9l7/1i4D+AE4CrJb01IpZk278HeC/pwPEUsBnw\nBeA2Se+IdC3xduBC4FjSicMj2ba160ABbEP6jH8AXAI82vD+ag4nJaZ/A/5fNu900ve7V/RzBi1p\nbdLBbHPgu6RE+HfA5ZJeHxHfBR4mHRQnkw7O52abP9fHbj9F+v3cm8UN6TtbWSxNfDeSvpG9j6uA\nfycl1S8Bt0t6d0Qs6ud9bUhK8uNJn9+jwMakz2cc0Ne2f5ctv5h08N+F9B1tDHy8br3/In2+F5IS\n2wTSCdgmwBxJbyYlqvmk5ruXSL+Dv+0rZtL39xTp2uAFWfzzsmVr/G3l+HwCWI/0t3MV6bLBPKz9\nis6WRU7A60hnXP/V5Prvytb/t4b5Z5PO4Paqmzcrm/dXdfPWI51tn103r1br+XLDPi8jq2U1zD8V\n6K57fVxWzhv6iXuNmhXwAPAs8Pq6eduT2vwvayivh9TJpH6fPwPmN/GZ3ZbF97G6eVtl+3wVeE/d\n/A/0EufYXva5S7beJ+vmHUzDmX0v38U+fSz7UcO8o7L9H0o6GXkVOKeJ91r7Lg6pm9cF3EVqinpN\nQ7m/aPJ3t7gxxjzfDemg/ypwYsN67yA1h31tgPJ/nG3/7n7W6a1m1dt3d2L2G3tL9vr1vf3+G7b5\naLbvPsvP1ltZs6qLqQf42wH+hpr+fOp+z0c28915Grqp6l3Xx2f/Lm5y/f1IZ1bnN8w/l3SG23ht\n6+GI+G3tRUQsIJ2Vvj1/qH16Kfv3IElqZgNJGwA7kJLSyvb8iPg98GvS+6wXpDPqencAb5L02iaK\n/EtETK0r549Z3DMj4v/q1qvVbt9et+4rdXGPzrppP06qke7URNk1syLi5mZWjIh/B34JfI905vwn\n0hn6QD4MzI2Iq+r21U2qMbyWdPAcas18NweTfp9XS3pTbSLVVP5E6uzRq+w39VFSYn0gV2Crf3fj\nsjLvJt0y8+5s0TJSQvhrSev2sauXsvgPyHr4DbW8n88rpJYSG0ZVT1a1qv3rmly/VkN5rH5mRMwj\n/UFt2rB+b73SXgTekCPGgfwn6cz934F5kqZI+rsBElctzj/2smwmsF7We7Be43t5Mfu3mffyVC/z\nFpKawVaKVU0tK/cpaW1Jp0uaQzpILCAdRNYlnZU3a1aOdSHVrsaRmlQPrz/w9mNT0sGt0UzSwbDx\n9zFUBvputiD9rT9Gam6sTfNJzaMT+tn3m0kndbk7g0h6q6TLJT1Pat5+jtRMGmTfXaROESeSEv08\nSbdL+qqkWucIIuJ2Uhf0bwILJP1c0mclrZU3pj7k/XyejogV2LCq9DWriFgs6RlS81czagmg2V5n\n3QPspz99ldG12krpms2ekvYm1ew+RLoecIukD0bWdtFC+Y0G81762raZfX6P1IHifFJHjIWkz+Y/\nyXeylbe31t7A2Kys7VlV6+tPK5/rUBjocxxFOsn6EL130/9LL/Ma95GLpFHAzaSTin8mtSgsIV2v\n+jF1311EXCDpF8CBwL6ka0cnSdo7ImZk63xM0i7A/tk6PwK+LOm9EbG0lRjr5P183POvAJVOVpn/\nBo6StGsM3MliNumHvSWrLtAjaQLpj/KJIYzrxWyfjTbrbeWIuI3Unv5P2U2kZ5IOuLf2svrs7N+t\ne1m2DbAgytMV92Dg8og4oTYjuzet8bNp9gRiQFmHggtJF/WXA+dKuikinux/S2bT+4nPttm/rf4+\nBvve/kxKOrMj4rGBVm4wn9QCsV3O7bYn/Z18OiL+ozYz69izhoiYRTohOV/S5sAM4Cukzky1de4D\n7gNOkXQoqVPOIaTENRiD+XxsmFS9GRBS54ilwA+zpLMaSZtL+lL28gbSj/ofG1b7CumA8j9DGNef\ngddLWnmQyA6iBzbE11sz3IwszrG97Tgi5pJ6D35GUu26HVlZH2Ro38dgdbPm7/RLNNQwSWftovcE\nn9cl2b6OAD5Huvh+aRPb3QBsIGllTzdJXaQecItJvRZbsYTBva//ItUYTu1tYX/DNWU1858D+0vK\nc42wVttr/O7+kdV7s66TnXzUm0X6vMZm6/T23mdk//b6G8+p5c/Hhk/la1YR8bikT5C6oc6UVD+C\nxV+Rut9elq37oKQfA/+QJYnbSb3FDiP1KGz1YNSbKcC/AD+XdCHwGtIoGo+yeseCb2bjsf0P6cx9\nfVLX8DnAnf3s/6ukg+s9ki4lXZ85hlSj+9YQvo/B+m/g05IWkbp97wZMIl27qvc70gHyxOzg9gpw\nS9appWmSDic1px4WEc9m874EXCnp6Ij4fj+bX0JKbpdL2plVXdd3A46LVd3x85oG7CPpeNI9SLOy\nWkZTst/4ycB3JL2NlHwWkzqyHEjqoNHf2IRfJ/XU/F9Jl5CuwW1E6rq+e921xvomw0dIJ1znSnoL\nqXZ2MGsm3a1ITdZTSd/vClKX9AmkvwFIJ1VfAK7N9vk60jXFhaTf8KAMwedjw6Ho7ohlmUj3xvwb\n6Y9hGanDxP+SDvxj6tYbBZzMqpuCZwNn1K+Trfc4cF0v5dxGOojWXm9KOsge38u6k0hnkMtIf8iH\nsma3278mnRk+ma33JHAFsHkvZTTeFLx39h5rNwVfC2zdsM6p2bZvbJj/Gfq5mbXh/c7oZX5fn083\ncEHd6/HAD0n3siwkJeUt6f2m0CNIHRyWs/pNwbN6K6sujkuz/29c+xx6We9npAPupgO83/Xq4q3d\nFPzpZt9/H/vcKvsc/5K9r8abgpv6bkgH3tuz97GI1GniAmCLJmJ4C+mkbS6pJeJP2bb93RS8Nakp\ndWH2eXyf1Jy48rdIugfvwiyWRcALwG+p624O7AhcmX2PS0m3XPychq7s2X5PqXtdi6m3rusrenmP\nA34+ff2ePbV/UvYFmJmZlZavWZmZWek5WZmZWek5WZmZWelVKllJ+qKkWZKWSbpH0nuKjqmdJJ0k\n6T5JiyTNk3StpK2Kjmu4ZZ9DS0/j7TSSNpJ0haQFkpZKmpGzy3nHkTRK0hmSHs/e82NZ7z4bQSqT\nrLJ7X84l9QR6N6mX3U2S1is0sPbagzT6966kJyCPAX7Vy1BKI1Z2QnIUq+7LGbGyLvt3kbrt70u6\nGfkrrBp+aaT6GumWgS+Qbmo/AThB0jGFRmVDqjK9ASXdA9wbEcdlr0Xq5n1hRJxdaHDDJEvM80nd\ni/u7B2tEyAZynUa6/eAU4IGI+HKxUbWPpLOA3SKiHQPmlpak60kDCB9VN+8aYGlEHNb3ltZJKlGz\nkjQGmAjcUpsXKUvfTLphsyrWJY0e8ELRgQyTi4DrI6K3IadGov2B+yVNzZp9p0s6suighsFvgUmS\ntgSQtAPpoaeDvmHYyqMqI1isRxqep/EhafPofXy8ESerSU4G7oyIh4uOp90kHUK6mXTnomMZRm8n\n1SLPBb5Nav69UNLLEXFloZG111mkm8cfkVQbnusbUfeoFut8VUlWfRFDOABqyV1Mepjc7kUH0m7Z\n8D6TgQ9ExKtFxzOMRgH3RcQp2esZkt5JSmAjOVl9HPgEaVDbh0knKRdIeiYirig0MhsyVUlWC0jD\nrqzfMH8CFXgktaTvkR6ouEdk492NcBNJz2GaVvdcry7So1SOIT3BdiSepDxLGrev3kz6f/z7SHA2\n8J2IuDp7/QdJmwEnkYYesxGgEtessrPraaSx9oCVzWKTSO3dI1aWqD4K7B0RvT0MciS6mfSIih1J\nT0TeAbifVLvYYYQmKkg9ARubtbdmaB9dU0bjWLOFpIeKHN+qoio1K0ijJv9Y0jTSM3GOJ/3ILy8y\nqHaSdDFp8NsDgCV1T19dGOmhjSNSpNHNV7suJ2kJ8HxENNY8RpLzgbuy55lNJV2zOpLUdX8kux74\nhqQnSYPP7kT6+/5hoVHZkKpM13WA7DEDJ5CaA38HHBsR9xcbVftI6qH3a3KHR8RPhjueIkm6Ffjd\nSO66DiBpP1KHgy1Io5SfGxGDfThhqUl6DenJBweRmvafAX4KnBF+/PyIUalkZWZmncltumZmVnpO\nVmZmVnpOVmZmVnpOVmZmVnpOVmZmVnpOVmZmVnodd1OwpDeRntUzGxixN7aaWaWsDWwG3BQRz7ej\nAEmbkAb1bsWCokfA6bhkRUpU/1F0EGZmbfBJ0g3NQ0rSJmPgiUGM6rxU0rZFJqxOTFazIY3M2eop\nwo3Ah1rc9hK+0OKWZXADaTzbVnQNZSA5vTLI7QfzjRftNYPY9jrSsJCtWjKIbYs02O+7iMPic8DV\nkB3f2mC9V2ntuLkA+K80NN16gJNVDi9D+tQ2bHEHaw9iW9io5S2Ltzatx1/kT2XZILcf3DderPGD\n2HZt4C2D2H7RILYt0mC/7zFDFUgr2nppYwPyHwHKkiTKEoeZmbXZaPKn4rIkibLEYWZmbdZF/oN+\nkRcA6jlZmZlVRCfXrCp5n9V2RQdQmO2LDqAgVf3G3110AAWp6vc9spUlaQ6rqh6y0wNzq6iq3/hO\nRQdQkKp+3wNzM6CZmZVeJzcDliUOMzNrs06uWZXmmpWkL0qaJWmZpHskvafomMzMRpJazSrP1Exy\nk/RaSZMlzZa0VNKdknZuWOd0Sc9ky38taYs8sZciWUn6OHAucCrpqvAM4CZJrQ5SYWZmDUa3ODXh\nUmASabio7YBfAzdL2hBA0onAMcDngF1Iw6PcJGmtZmMvRbICjgd+EBE/iYhHgM8DS4Ejig3LzMz6\nI2lt0khOX42IuyLi8Yj4FvAYcHS22nHAGRFxfUQ8BBxGGkzjwGbLKTxZSRoDTARuqc2LiABuBnYr\nKi4zs5GmTc2Ao0mXthoH8VwGvE/S20gjPdUf4xcB95LjGF94siIN89cFzGuYP4/0Bs3MbAi0I1lF\nxF+Au4FTJG0oaZSkT5ES0Yak43gwyGN8GZJVX0R6g2ZmNgRqvQHzTE32BvwU6Zj9NGkw3mNIjzrp\n7mebXMf4MnRdX0B6Q+s3zJ/Ampl4pRtJYyvX2w7fDmhmZTcD+H3DvOF5juxA91ndCtzWMK+ZB8VE\nxCxgb0nrAOMjYp6kq4BZwFxSYlqf1Y/pE4AH8sReqIh4VdI0Uk+SXwBIUvb6wr62+xCd+9AHM6uy\nHVhzNJlngIsLiGV178+men+Cpp/iFxHLgGWS3kB6UO4/RcQsSXNJx/QHASSNB3YFLmo2tsKTVeY8\n4MdZ0rqP1DtwHHB5kUGZmY0k7bopWNIHSbWnR4EtgbOBmaw6hk8GTpb0GOkBk2cAT5GeENqUUiSr\niJia3VN1Oqmq+Dtg34h4rtjIzMxGjjYOt/R64J+BjYEXgGuAkyOiGyAizpY0DvgBsC5wB/DhiFg+\nxHG0X0RcTBnqwWZmI1S7alYRcTVw9QDrnAaclrP4lUqTrMzMrL08kK2ZmZVejuGTVtumDMp8n5WZ\nmRlQnqRpZmZt5mZAMzMrvU5+npWTlZlZRbhmZWZmpedkZWZmpdfJzYDuDWhmZqXXsTWrSziWNLLH\n8LqArw17mTXHcUFhZcPiAsvO23AxlF4tsGwrRhHf+YphKWV0F4xRzm2C/h/0MUw6NlmZmVk+XV0w\nOmd7WlcPTlZmZjZ8Ro+CMTkvQpUlSZQlDjMza7PRo1NTYK5tcjYbtouTlZlZRYzugjE5j/plSRLu\nDWhmZqVXlqRpZmbtNor8N071tCOQ/JyszMyqopW7gp2szMxsWLXyQCsnKzMzG1at1KxKcI8VuIOF\nmZl1ANeszMyqopUOFiWp0jhZmZlVRQcPu16SnGlmZm03usWpH5JGSTpD0uOSlkp6TNLJvax3uqRn\nsnV+LWmLPKE7WZmZVUWtGTDPNHCW+BrwOeALwDbACcAJko6prSDpROCYbL1dgCXATZLWajZ0NwOa\nmVVFe5oBdwOui4gbs9dzJH2ClJRqjgPOiIjrASQdBswDDgSmNhOGa1ZmZjYYvwUmSdoSQNIOwO7A\nDdnrtwEbALfUNoiIRcC9pETXFNeszMyqopWbggde/yxgPPCIpG5SJegbEXFVtnwDIEg1qXrzsmVD\nFIaZmY0M7em6/nHgE8AhwMPAjsAFkp6JiCv62U6kJNYUJyszs6oY4JrVlPlpqrdwxYB7PRv4TkRc\nnb3+g6TNgJOAK4C5pMS0PqvXriYADzQXuJOVmVl1DJCsDt0oTfWmL4KJ/9fvXsexZg2ph6xOFhGz\nJM0FJgEPAkgaD+wKXNRs6E5WZmZV0Z5rVtcD35D0JPAHYCfgeOCHdetMBk6W9BgwGzgDeAq4bujC\nMDMz69sxpORzEalp7xng+9k8ACLibEnjgB8A6wJ3AB+OiOXNFuJkZWZWFW3oYBERS4AvZ1N/650G\nnJaz9JWcrMzMqqKDxwZ0sjIzqwonKzMzK73aeH95tykBJyszs6ro4JqVxwY0M7PSc83KzKwqOrhm\n5WRlZlYVvmZVhAnAxsNe6nFcPOxl1szlC4WVvQFnFlZ2+q6LMn/gVdpqWYFljy+w7NcVWPbTBZbd\nZq5ZmZlZ6XVwsnIHCzMzKz3XrMzMqqKDa1ZOVmZmVeEOFmZmVnquWZmZWek5WZmZWel1cDOgewOa\nmVnpuWZlZlYVbgY0M7PS6+BkVXgzoKSTJN0naZGkeZKulbRV0XGZmY04tWSVZ3KyWmkP4LvArsA+\nwBjgV5LWKTQqM7ORpqvFqQQKbwaMiP3qX0v6LGn00InAnUXEZGY2IrkZcEitCwTwQtGBmJlZOZQq\nWUkSMBm4MyIeLjoeM7MRpQ3XrCTNktTTy/TdbPlYSRdJWiBpsaRrJOV+7k+pkhVwMfAO4JCiAzEz\nG3Hac81qZ2CDuukDpNaxqdnyycBHgIOBPYGNgJ/lDb3wa1Y1kr4H7AfsERHPDrzFlcC4hnm7ZZOZ\nWVn9HnioYd7Lw1N0G65ZRcTz9a8l7Q/8OSLukDQeOAI4JCJuz5YfDsyUtEtE3NdsGKVIVlmi+iiw\nV0TMaW6rTwGbtS8oM7O22D6b6j0LXNL+otvcwULSGOCTwDnZrJ2zEm+prRMRj0qaQ6pZdE6yknQx\ncChwALBE0vrZooURMUynG2ZmFTCK/L378l0sOgh4PfDj7PX6wPKIWNSw3jxSk2HTCk9WwOdJ7Zu/\naZh/OPCTYY/GzKyiptwDU+5dfd7Cpbl2cQTwy4iYO8B6Ih33m1Z4soqIsnXyMDMbmWo9/Ppw6PvS\nVG/6bJh4ysC7lrQJaWCHA+tmzwXWkjS+oXY1gVS7apoThZlZVbR3uKUjSAnohrp504AVwKTajGw4\nvU2Au/OEXnjNyszMhkmbOlhk98h+Frg8Inpq8yNikaRLgfMkvQgsBi4E7srTExCcrMzMqqN9HSz2\nAd4KXNbLsuOBbuAaYCxwI/DFnFE4WZmZ2eBExK/pIw1GxCvAsdnUMicrM7OqGKCDRZ/blEBJwjAz\ns7br4FHXnazMzKqi/TcFt42TlZlZVbhmZWZmpedrVlXyamElb8CZhZV9GScXVvbhnFpY2dVW3G8d\nlhVYtpWRk5WZWVX4mpWZmZWer1mZmVnp+ZqVmZmVnmtWZmZWeh18zaokYZiZmfXNNSszs6pwM6CZ\nmZWeO1iYmVnpdfA1KycrM7OqcDOgmZmVXgcnq5JU8MzMzPrmmpWZWVW4g4WZmZVdjILI2awXJWl/\nc7IyM6uI7i7oznnU7/Y1KzMzG049WbLKM/U0kawkbSTpCkkLJC2VNEPSTg3rnC7pmWz5ryVtkSd2\nJyszM2uZpHWBu4BXgH2BbYGvAC/WrXMicAzwOWAXYAlwk6S1mi3HzYBmZhXR3SVWdCnnNgFEf6t8\nDZgTEUfWzXuiYZ3jgDMi4noASYcB84ADganNxOGalZlZRXR3ddE9enS+qWvAdsD9gfslTZU0T9J0\nSSsTl6S3ARsAt9TmRcQi4F5gt2Zjd83KzKwierq66O7KV0fp6RKwor9V3g4cDZwLfBvYFbhQ0ssR\ncSUpUQWpJlVvXrasKU5WZmYV0c0ounMOSdE98CqjgPsi4pTs9QxJ7yQlsCv72U4M0L5Yz8nKzKwi\nuuliRT/J6topy/n5lFdXm7do4YD55FlgZsO8mcDfZv+fS0pM67N67WoC8MCAQWecrMzMDICDDl2L\ngw5dvYPeg9O72XfiX/rb7C5g64Z5W5N1soiIWZLmApOABwEkjSc1F17UbGxOVmZmFdFDF905D/s9\nA69yPnCXpJNIPft2BY4EjqpbZzJwsqTHgNnAGcBTwHXNxuFkZWZWEa1ds+o/XUXE/ZIOAs4CTgFm\nAcdFxFV165wtaRzwA2Bd4A7gwxGxvNk4nKzMzCoi1azyJaueJupWEXEDcMMA65wGnJar8DpOVmZm\nFdHTQs2qp5n+gMPAycrMrCJWMKrf3oB9bVMG5YjCzMysH65ZmZlVRA+jW+gN6GbAQZoPjCk6iGGW\na0T9IXU4ZxZW9h2cXFjZe3BBYWUnLxRY9joFll3k3/arA6/SoVq7ZlWOBrgOTlZmZpZHa13XnazM\nzGwYDTTcUl/blIGTlZlZRbQ2gkU5klU56ndmZmb9cM3KzKwiulsYwcLNgGZmNqzcG9DMzErPvQHN\nzKz0Ork3YDlSppmZWT9cszIzqwh3XR9Ckk6S1CPpvKJjMTMbSWrXrPJN5UgTpapZSXoP6VHIM4qO\nxcxspGnt4YuuWa1G0muBK4EjgZcKDsfMbMTpzp5nlWcqS82qHFEkFwHXR8StRQdiZjYSdWfXrPJN\n5ahZlaIZUNIhwI7AzkXHYmZm5VN4spL0FmAy8IGIGLkPkjEzK1gnX7MqPFkBE4E3A9MkKZvXBewp\n6RhgbETEmpv9N7B2w7wdSBU0M7Oy+j3wUMO8l4el5MqNYCFpF+AfgM2BT0bEM1lT3uyIuCfn7m4G\ntm+YdzkwEzir90QF8DfAxjmLMjMr2vasech7Frik7SW3YwQLSacCpzbMfiQi3pEtHwucB3wcGAvc\nBHwhIubniSN3spJ0APCfwDXAbqyq3kwAPkXKIk2LiCXAww1lLAGej4iZeeMzM7PetfGm4IeASUCt\ndWxF3bLJwIeBg4FFpM50PwP2yBNHKzWrU4FjIuJSSQfWzb8TOKmF/fWmj9qUmZm1qo3NgCsi4rnG\nmZLGA0cAh0TE7dm8w4GZknaJiPuajaOVZLUNcEsv818C3tDC/tYQEe8fiv2Ymdmw2FLS06SLb3cD\nJ0XEk6Q+CaOpyxkR8aikOaSWubYmq/nA24DZDfN3A2a1sD8zMxsGbeoNeA/wWeBRYEPgNOB/JW0H\nbAAsj4hFDdvMy5Y1rZVkdRkwWdJhpOa6N0l6N3AOcHYL+zMzs2HQjocvRsRNdS8fknQf8ATwMfru\n5ihyXu5pJVmdCYwhVfXWJmXVFcCFEXF+C/szM7NhsGKA3oDTpjzG9CmPrTZv2cLlucqIiIWS/ghs\nQertvZak8Q21qwmk2lXTcieriOgBTpF0FrA18Frg9xHxYt59mZnZ8BmoN+COh27Djodus9q8p6Y/\nx/kTr266jGyc182BHwPTSJWZScC12fKtgE1IFZ6mtXxTcNblfHqr25uZ2fBqR29ASf8KXE9q+tsY\n+BYpQV0VEYskXQqcJ+lFYDFwIXBXnp6A0Np9Vjf0tzwi9su7TzMz61hvAX4KvAl4jnQb03sj4vls\n+fFAN+nXDrkdAAASGklEQVTe3LHAjcAX8xbSSs3qiYbXY0hjHG0BTGlhf2ZmNgza0RswIg4dYPkr\nwLHZ1LJWrlkd3dt8Sd9h1d3LZmZWMrXnWeXdpgyGMorLSE/5NTOzEvLzrJKdAD/iw8yspCr1iBBJ\nP22cRbpreXeG9abg0aTLZcNtWQFl1jxdYNnrFFbyHlxcWNkz+EJhZQPswJkFlj6+wLJfKLDs9Qso\n85UCyuwsrdSsGq9L9QC/A86LiF8MPiQzM2uHdoxgMVxyJStJXcD5wKMRsbA9IZmZWTtU5uGLEdEt\n6Q5gW8DJysysg7Tj4YvDpZVmwIeBtwKPD3EsZmbWRm18+GLbtVK/OwE4R9I+kt4gaa36aagDNDOz\noVFrBsw3dWAzYOamhn8blSMNm5nZiNFKsvrwkEdhZmZtV4n7rCR9Ezin4UFbZmbWIaoy3NKppGdX\nmZlZB8o/1NLo3B0y2iVPFB6k1sysg1XmpmAg2hKFmZm1XWVuCgb+KKnfhBURbxxEPGZmZmvIm6xO\nxSNXmJl1pEr0BsxcFRHz2xKJmZm1VSf3BsyTrHy9ysysg3W3MNxSJ44N6N6AZmYdrBLNgBFRjrqg\nmZlVTjnu9jIzs7br5K7r5YjCzMzarvY8qzxTnuQm6SRJPZLOq5s3VtJFkhZIWizpGkkT8sbuZGVm\nVhG151nlmZq9ZiXpPcBRwIyGRZOBjwAHA3sCGwE/yxu7k5WZWUW063lWkl4LXAkcCbxUN388cARw\nfETcHhEPAIcDu0vaJU/sTlZmZhXRkztRdTVbs7oIuD4ibm2YvzOpb8QttRkR8SgwB9gtT+zuYGFm\nZi2TdAiwIykxNVofWB4RixrmzwM2yFOOk5WZWUUM9QgWkt5Cuib1gYh4NcduRc6BJpyszMwqYqAR\nLBZMuYUFU1ZvyVuxcEl/u5wIvBmYJqk2cEQXsKekY4APAWMljW+oXU0g1a6a5mRlZlYRA41g8YZD\nP8gbDv3gavOWTP8jf5h4VF+b3Axs3zDvcmAmcBbwNPAqMAm4FkDSVsAmwN15YneyMjOriKF++GJE\nLAEerp8naQnwfETMzF5fCpwn6UVgMXAhcFdE3JcnDicrM7OK6B6gZtXXNjk1Xos6HugGrgHGAjcC\nX8y7UycrMzMbMhHx/obXrwDHZlPLnKzMzCqiKs+zKpktgC0LKHdmAWXWLHPZw2wHTi2sbIDrOLmw\nsj9a8HsvTq5OakPkhWEppSrPszIzsw5WiedZmZlZZxvq3oDDycnKzKwiVjCKrpzJakVJklU5ojAz\nM+uHa1ZmZhXRkz2jKu82ZVCOKMzMrO18zcrMzEqvm1GM8n1WZmZWZj09XXT35KxZ5Vy/XcqRMs3M\nzPpRimQlaSNJV0haIGmppBmSdio6LjOzkaS7exQrVnTlmrq7S5Emim8GlLQucBdwC7AvsIA0jtKL\nRcZlZjbSdK/oghU5h1taUY5mwMKTFfA1YE5EHFk374migjEzG6l6ursgZ/Lp6S5HsipD/W5/4H5J\nUyXNkzRd0pEDbmVmZrl0d4+ie0VXvsnNgCu9HTgaOBf4NrArcKGklyPiykIjMzMbQbpXdNHzar6a\nUrgZcKVRwH0RcUr2eoakd5ISmJOVmZmVIlk9y5oPiZoJ/G3/m/0b8JqGeXtnk5lZWf0eeKhh3svD\nUnL0dBHdOQ/7JbnPqgzJ6i5g64Z5WzNgJ4vPU8zDF83MBmP7bKr3LHBJ+4teMSp3BwtW+JpVzfnA\nXZJOAqaSrlkdCRxVaFRmZiNNC70BKUlvwMKTVUTcL+kg4CzgFGAWcFxEXFVsZGZmI0y3YIXyb1MC\nhScrgIi4Abih6DjMzEa0bmBFC9uUQDkaI83MrCNJ+nw2RN7CbPqtpA/VLR8r6aJsOL3Fkq6RNCFv\nOU5WZmZVUatZ5ZkGrlk9CZwITMymW4HrJG2bLZ8MfAQ4GNgT2Aj4Wd7QS9EMaGZmw6CWgPJu04+I\n+J+GWSdLOhp4r6SngSOAQyLidgBJhwMzJe0SEfc1G4aTlZlZVawAXm1hmyZJGgV8DBgH3E2qaY0m\nDVQOQEQ8KmkOsBvgZGVmZg16yN9homfgVSRtR0pOawOLgYMi4hFJ7waWR8Sihk3mARvkCcPJysys\nKgbqDXjzFLhlyurzlixsZs+PADsA65KuTf1E0p79rC8gmtlxjZOVmZkl+xyapnp/nA5HTex3s4hY\nATyevZwuaRfgONJAD2tJGt9Qu5pAql01zb0BzcyqIm9PwFY6ZCSjgLHAtGwPk2oLJG0FbEJqNmya\na1ZmZlXRhpuCJX0b+CWpC/vrgE8CewEfjIhFki4FzpP0Iul61oXAXXl6AoKTlZlZdbRnBIv1gZ8A\nGwILgQdJierWbPnx2V6uIdW2bgS+mDOKTk5Wj5CSdJWsX2DZuZqXh9g6BZb9rgLLho8WWHZs863C\nytYjVxRWNjxdQJljh6eYNiSriOj3ye4R8QpwbDa1zNeszMys9Dq4ZmVmZrl08EC2TlZmZlXR5hEs\n2snJysysKrrJX1NyzcrMzIaVmwHNzKz0OjhZuTegmZmVnmtWZmZV0cE1KycrM7OqaMPDF4eLk5WZ\nWVW4ZmVmZqXnZGVmZqXXwTcFuzegmZmVnmtWZmZV4REszMys9HzNyszMSs/JyszMSs/JyszMSs+9\nAc3MzNrHNSszs6pwb0AzMyu9Dr5m5WZAM7OqqCWrPNMAyUrSSZLuk7RI0jxJ10raqmGdsZIukrRA\n0mJJ10iakCd0Jyszs6qodbDIMw1cE9sD+C6wK7APMAb4laR16taZDHwEOBjYE9gI+Fme0N0MaGZm\nLYuI/epfS/osMB+YCNwpaTxwBHBIRNyerXM4MFPSLhFxXzPluGZlZlYV3S1O+awLBPBC9noiqWJ0\nS22FiHgUmAPs1uxOXbMyM6uKNnewkCRSk9+dEfFwNnsDYHlELGpYfV62rClOVmZmVdH+3oAXA+8A\n3tfEuiLVwJriZGVmVhUDjWAxZwo8OWX1ea8ubGrXkr4H7AfsERHP1C2aC6wlaXxD7WoCqXbVFCcr\nM7Oq6KH/mtLGh6ap3kvT4baJ/e42S1QfBfaKiDkNi6eR0uQk4Nps/a2ATYC7mw3dycrMzFom6WLg\nUOAAYImk9bNFCyPi5YhYJOlS4DxJLwKLgQuBu5rtCQhOVi3YuMCy5xdYdklGsxx2vym4/DGFlaxH\nziqs7Bl8urCyd+CCAkodOzzF1G70zbtN/z5Puvb0m4b5hwM/yf5/PKlOdw3pzd4IfDFPGE5WZmZV\n0YYOFhEx4C1QEfEKcGw2tcTJysysKjr4ESFOVmZmVTFQB4u+tikBJyszs6rwqOtmZmbt45qVmVlV\ntKc34LBwsjIzqwp3sDAzs9JzBwszMys9d7BonaRRks6Q9LikpZIek3Ry0XGZmY04eR9p38o1rjYp\nQ83qa8DngMOAh4GdgcslvRQR3ys0MjMzK4UyJKvdgOsi4sbs9RxJnwB2KTAmM7ORp4M7WBTeDAj8\nFpgkaUsASTsAuwM3FBqVmdlIU+tgkWdyB4uVzgLGA49I6iYl0G9ExFXFhmVmNsJ0cAeLMiSrjwOf\nAA4hXbPaEbhA0jMRcUWhkZmZjSROVoNyNvCdiLg6e/0HSZsBJwH9JKv/BtZumLcDKdeZmZXVNGB6\nw7xlRQTSUcqQrMaRHtxVr4cBr6f9DcU+CNHMrBUTs6nek8A57S+6lc4SJelgUYZkdT3wDUlPAn8A\ndiI9VfKHhUZlZjbSdANqYZsSKEOyOgY4A7gImAA8A3w/m2dmZkOllcTjZJVExBLgy9lkZmbt0s2a\nF10G4q7rZmY2rFaQvxkwb3JrkzLcFGxmZtYv16zMzKqilQ4WrlmZmdmwi5zTACTtIekXkp6W1CPp\ngF7WOV3SM9mTNX4taYu8YTtZmZnZYLwG+B3wRXpJb5JOJPX6/hxpgPIlwE2S1spTiJsBzcysZdkT\nM24EkNRbI+NxwBkRcX22zmHAPOBAYGqz5bhmZWZmbSHpbcAGwC21eRGxCLiX9HiopjlZmZlZu2xA\nahqc1zB/XrasaW4GNDOrjNI8fVHk7GfoZGVmVhkr6D/5TGXNy0gLB1PgXFJiWp/Va1cTgAfy7KiD\nk9VYYJ0Cyn2hgDLLIO/Z2FAq8jMvemT/+QWWXdxw2ztwQWFl38Zxw17mH0ld5dpvoJrVQdlU73fA\nXi2VFhGzJM0FJgEPAkgaD+xKGg+2aR2crMzMLJ+hf/qipNcAW7DqduO3S9oBeCEingQmAydLegyY\nTRqk/CngujxROFmZmVVGW65Z7QzcxqrbiM/N5v8YOCIizpY0DvgBsC5wB/DhiFieJwonKzMza1lE\n3M4APcsj4jTgtMGU42RlZlYZpekNmJuTlZlZZQz9Navh4mRlZlYZrlmZmVnpdW7NysMtmZlZ6blm\nZWZWGW4GNDOz0htouKW+timek5WZWWW4ZmVmZqXXuR0snKzMzCqjc2tW7g1oZmal55qVmVlluBnQ\nzMxKr3ObAZ2szMwqwzUrMzMrPdeszMys9Do3Wbk3oJmZlZ5rVmZmleHhlszMrPQ6txnQycrMrDLc\nG9DMzEqvc2tWFe1gMa3oAAoyvegACvL7ogMoyIyiAyhIVf++m1GrWeWZylGzqmiyqupB+4GiAyjI\nQ0UHUJCqJumq/n2PbG4GNDOrjM5tBnSyMjOrDHewMDOz0nPNajitnf6ZN4hdLAOeHIpYhtlgz3Be\nBp5qcdslgyy7SC8Dz7a4bdF/qC8OYtuXgWeGKpBhNm4Q2w7u7/uPgyi5VXNW/Xft9pY0l/y/6QXt\nCCQ3RUTRMeQi6RPAfxQdh5lZG3wyIn461DuVtAkwk9bPApYC20bEnAHXbJNOTFZvAvYFZpNOHc3M\nOt3awGbATRHxfDsKyBLWei1uvqDIRAUdmKzMzKx6KnqflZmZdRInKzMzKz0nKzMzKz0nKzMzKz0n\nK7OMpE0l9Uh6V/Z6L0ndksYXEMttks4b7nLNysrJykpP0mVZEumW9IqkP0k6WVI7fr/13WPvAjaM\niEVNxukEY9YmnTiChVXTL4HPku5H+TBwMWncmH+pXylLYBGt35Oh2n8iYgUwv8X9mNkQcs3KOsUr\nEfFcRDwZEZcAtwAHSPqMpBcl7S/pD6Qbxd8KIOlISQ9LWpb9e3T9DiXtIml6tvw+4N3U1ayyZsCe\n+mZASbtnNaglkl6Q9EtJr5d0GbAXcFxdLXCTbJvtJN0gabGkuZJ+kt3cXtvnuGzeYklPS/py+z5G\ns87kZGWdahmwVvb/ccAJwN8D7wTmS/okcBpwErAN8HXgdEmfhpQggOtJD7vaKVv3nF7KqU9eOwI3\nZ9u8F9g920cXcBxwN/DvwPrAhsCTkl5PSqzTsnL2BSYAU+vKOAfYA9gf+CDw18DE/B+J2cjlZkDr\nOJL2IR30L8hmjQaOjoiH6tY5DfhKRFyXzXpC0juBzwFXAJ8iNfkdGRHLgZmS3kpqXuzLV4H/i4hj\n6+bNrCtzObA0Ip6rm3cMMD0iTqmbdyQwR9IWpBF2jwA+ERG/yZZ/htZHHDYbkZysrFPsL2kxMIaU\nZH4KfAv4GLC8IVGNAzYHLpX0w7p9jGbVMObbAA9miarm7gFi2JHVa0TN2AF4fxZ7vchiHEd6T/et\nXBDxoqRHc5ZjNqI5WVmnuBX4PKlTxTMR0QMgCVKTYL3XZv8eSV0SyNSesyJW7/nXjMZymvFa4Bek\nZko1LHsW2Cr7vwfpNOuHr1lZp1gSEbMi4qlaoupLRMwHngY2j4jHG6YnstUeBnaQtFbdprsNEMOD\nwKR+li8nXb+qN510He2JXmJZBjxGesDQe2sbSHoDq5KYmeFkZSPXacBJko6VtGXWI++zko7Plv+U\nVJv5oaRtJe0HfKWX/dTXhv4ZeI+kiyRtL2kbSZ+X9MZs+Wxg1+zm4lpvv4uANwJXSdpZ0tsl7Svp\nR5IUEUuAS4F/lbS3pO2AyyjLs8TNSsLJykakiLiU1Ax4OKlG9BvgM8Dj2fIlpN5325FqP2eQmurW\n2FXdPv9E6q33LuBe0k3DB7Dq0avnkJLMw6QeiZtExLOkXoOjgJuyWM4DXqy7F+yrwB2k5sJfZf+f\nNsiPwGxE8fOszMys9FyzMjOz0nOyMjOz0nOyMjOz0nOyMjOz0nOyMjOz0nOyMjOz0nOyMjOz0nOy\nMjOz0nOyMjOz0nOyMjOz0nOyMjOz0nOyMjOz0vv/yI6wZKnvjpQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc86c39a250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "ytest = test['y']\n",
    "ytest = np.ravel(ytest)\n",
    "b = np.hstack(temp_result) + 1\n",
    "\n",
    "# mnist_ = input_data.read_data_sets('MNIST_data', one_hot=False)\n",
    "# test_label = mnist_.test.labels\n",
    "# print test_label\n",
    "\n",
    "# print \"Confusion matrix \\n{}\".format(metrics.confusion_matrix(test_label, b))\n",
    "names=['1','2','3','4','5','6','7','8','9','10']\n",
    "names1=[1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "print \"Classification report \\n{}\".format(classification_report())\n",
    "\n",
    "temp_accuracy_ = np.array(temp_accuracy)\n",
    "print \"Overall accuracy {}\".format(np.mean(temp_accuracy_))\n",
    "conf_mat = metrics.confusion_matrix(ytest, b)\n",
    "conf_mat1 = conf_mat/conf_mat.sum(axis=1)[:,None]*100\n",
    "print \"Confusion matrix \\n{}\".format(conf_mat1)\n",
    "# print \"{}\".format(conf_mat)\n",
    "# print np.min(b)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(conf_mat1)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "# ax.set_xticklabels(names1)\n",
    "# ax.set_yticklabels(names1)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "fig.savefig('foo.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[5099 4149 2882 2523 2384 1977 2019 1660 1595 1744]\n"
     ]
    }
   ],
   "source": [
    "print np.sum(conf_mat1, axis=1)\n",
    "print tot\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf2]",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
